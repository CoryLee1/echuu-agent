{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# echuu v2 - AI VTuber ç›´æ’­å¼•æ“ï¼ˆå¸¦å®Œæ•´å‰§æœ¬+è®°å¿†ç³»ç»Ÿï¼‰\n",
    "\n",
    "## æ ¸å¿ƒæ¶æ„\n",
    "\n",
    "```\n",
    "æ ‡æ³¨æ•°æ® â†’ Pattern Analyzer\n",
    "               â†“\n",
    "ç”¨æˆ·è¾“å…¥ (è§’è‰²è®¾å®š + è¯é¢˜)\n",
    "               â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Phase 1: é¢„ç”Ÿæˆå®Œæ•´å‰§æœ¬ (100s)                       â”‚\n",
    "â”‚  â€¢ 10-15å¥å®Œæ•´å°è¯ï¼Œæœ‰èµ·æ‰¿è½¬åˆ                        â”‚\n",
    "â”‚  â€¢ æ¯å¥æ ‡æ³¨ key_infoï¼ˆå…³é”®ä¿¡æ¯ç‚¹ï¼‰                   â”‚\n",
    "â”‚  â€¢ è®¾ç½® interruption_cost                            â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Phase 2: å®æ—¶è¡¨æ¼” + è®°å¿†ç³»ç»Ÿ                         â”‚\n",
    "â”‚                                                       â”‚\n",
    "â”‚  ğŸ§  è®°å¿†ç³»ç»Ÿ                                          â”‚\n",
    "â”‚  â”œâ”€ å‰§æœ¬è¿›åº¦ï¼ˆè¯´åˆ°ç¬¬å‡ å¥ï¼‰                            â”‚\n",
    "â”‚  â”œâ”€ å·²æåˆ°ä¿¡æ¯ï¼ˆé¿å…é‡å¤ï¼‰                            â”‚\n",
    "â”‚  â”œâ”€ å¼¹å¹•è®°å¿†ï¼ˆå·²å›åº”/å¾…å›ç­”ï¼‰                         â”‚\n",
    "â”‚  â””â”€ æ‰¿è¯ºè¿½è¸ªï¼ˆè¯´äº†\"ç­‰ä¼šå‘Šè¯‰ä½ \"è¦å…‘ç°ï¼‰                â”‚\n",
    "â”‚                                                       â”‚\n",
    "â”‚  âš¡ ç»Ÿä¸€å¼¹å¹•å¤„ç†                                      â”‚\n",
    "â”‚  priority = base + relevance_bonus + sc_bonus        â”‚\n",
    "â”‚  â€¢ ç›¸å…³æ€§æ˜¯æœ€é‡è¦å› ç´                                  â”‚\n",
    "â”‚  â€¢ é«˜ç›¸å…³é—®é¢˜ > ä½ç›¸å…³SC                              â”‚\n",
    "â”‚                                                       â”‚\n",
    "â”‚  ğŸ” ç­”æ¡ˆæŸ¥æ‰¾æœºåˆ¶                                      â”‚\n",
    "â”‚  åœ¨ key_info ä¸­åŒ¹é…é—®é¢˜ â†’ å†³å®šå™äº‹ç­–ç•¥                â”‚\n",
    "â”‚  â€¢ ç­”æ¡ˆè¿˜æ²¡è¯´ï¼šåŠèƒƒå£ + è®°å½•æ‰¿è¯º                      â”‚\n",
    "â”‚  â€¢ ç­”æ¡ˆåœ¨1-3å¥åï¼šå¯è·³è·ƒï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰                  â”‚\n",
    "â”‚  â€¢ ç­”æ¡ˆå·²è¯´è¿‡ï¼šæé†’è§‚ä¼—                               â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â†“\n",
    "     è¾“å‡º: å°è¯ + ğŸ”Š è¯­éŸ³ + è®°å¿†çŠ¶æ€å¯è§†åŒ–\n",
    "```\n",
    "\n",
    "## æ ¸å¿ƒåˆ›æ–°\n",
    "\n",
    "1. **å®Œæ•´å‰§æœ¬é¢„ç”Ÿæˆ** - 100så®Œæ•´æ•…äº‹ï¼Œé¿å…è½¦è½±è¾˜è¯\n",
    "2. **key_info æ ‡æ³¨** - æ¯å¥è¯çš„å…³é”®ä¿¡æ¯ï¼Œç”¨äºåŒ¹é…å¼¹å¹•é—®é¢˜\n",
    "3. **è®°å¿†ç³»ç»Ÿ** - è¿½è¸ªå·²è¯´å†…å®¹ã€å¼¹å¹•ã€æ‰¿è¯º\n",
    "4. **ç»Ÿä¸€å¼¹å¹•å¤„ç†** - ç›¸å…³æ€§ä¸ºç‹çš„ä¼˜å…ˆçº§ç³»ç»Ÿ\n",
    "5. **æ‰¿è¯ºè¿½è¸ª** - è¯´äº†\"ç­‰ä¼šå‘Šè¯‰ä½ \"å¿…é¡»å…‘ç°\n",
    "6. **ç­”æ¡ˆæŸ¥æ‰¾** - åœ¨å‰§æœ¬ä¸­å®šä½é—®é¢˜ç­”æ¡ˆï¼Œå†³å®šå™äº‹ç­–ç•¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…ä¾èµ–\n",
    "!pip install anthropic dashscope python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple, Callable\n",
    "from enum import Enum\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "from IPython.display import display, HTML, Markdown, Audio\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# è‡ªåŠ¨æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "while PROJECT_ROOT.name != 'echuu-agent' and PROJECT_ROOT.parent != PROJECT_ROOT:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "load_dotenv(PROJECT_ROOT / '.env')\n",
    "\n",
    "print(f\"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}\")\n",
    "print(f\"ğŸ”‘ ANTHROPIC_API_KEY: {'âœ… å·²é…ç½®' if os.getenv('ANTHROPIC_API_KEY') else 'âŒ æœªé…ç½®'}\")\n",
    "print(f\"ğŸ”‘ DASHSCOPE_API_KEY: {'âœ… å·²é…ç½®' if os.getenv('DASHSCOPE_API_KEY') else 'âŒ æœªé…ç½®'}\")\n",
    "print(f\"\\nâœ… å¯¼å…¥å®Œæˆï¼ˆå·²æ·»åŠ  re, random ç­‰V2æ‰€éœ€æ¨¡å—ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: æ•°æ®ç»“æ„å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== æ ¸å¿ƒæ•°æ®ç»“æ„ ====================\n",
    "\n",
    "@dataclass\n",
    "class ScriptLine:\n",
    "    \"\"\"å‰§æœ¬å°è¯ï¼ˆå¸¦key_infoæ ‡æ³¨ï¼‰\"\"\"\n",
    "    id: str                          # å”¯ä¸€ID\n",
    "    text: str                        # å°è¯å†…å®¹\n",
    "    stage: str                       # Hook/Build-up/Climax/Resolution\n",
    "    interruption_cost: float         # 0.0-1.0\n",
    "    key_info: List[str] = field(default_factory=list)  # ğŸ”‘ å…³é”®ä¿¡æ¯ç‚¹ï¼ˆç”¨äºåŒ¹é…å¼¹å¹•ï¼‰\n",
    "    \n",
    "    def __repr__(self):\n",
    "        info_str = \", \".join(self.key_info[:2])\n",
    "        return f\"[{self.stage}] {self.text[:30]}... (keys: {info_str})\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Danmaku:\n",
    "    \"\"\"å¼¹å¹•ï¼ˆå¸¦ä¼˜å…ˆçº§è®¡ç®—ï¼‰\"\"\"\n",
    "    text: str\n",
    "    user: str = \"è§‚ä¼—\"\n",
    "    is_sc: bool = False\n",
    "    amount: int = 0              # SCé‡‘é¢\n",
    "    \n",
    "    # è®¡ç®—å¾—å‡ºçš„å±æ€§\n",
    "    relevance: float = 0.0       # ä¸å½“å‰è¯é¢˜çš„ç›¸å…³æ€§ 0.0-1.0\n",
    "    priority: float = 0.0        # æœ€ç»ˆä¼˜å…ˆçº§\n",
    "    \n",
    "    @classmethod\n",
    "    def from_text(cls, text: str) -> \"Danmaku\":\n",
    "        \"\"\"è§£æå¼¹å¹•\"\"\"\n",
    "        is_sc = False\n",
    "        amount = 0\n",
    "        \n",
    "        # æ£€æµ‹SC\n",
    "        if \"SC\" in text or \"Â¥\" in text or \"$\" in text:\n",
    "            is_sc = True\n",
    "            # ç®€å•æå–é‡‘é¢\n",
    "            import re\n",
    "            match = re.search(r'[Â¥$]?\\s*(\\d+)', text)\n",
    "            if match:\n",
    "                amount = int(match.group(1))\n",
    "        \n",
    "        return cls(text=text, is_sc=is_sc, amount=amount)\n",
    "    \n",
    "    def is_question(self) -> bool:\n",
    "        \"\"\"åˆ¤æ–­æ˜¯å¦æ˜¯é—®é¢˜\"\"\"\n",
    "        return \"?\" in self.text or \"ï¼Ÿ\" in self.text\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PerformerMemory:\n",
    "    \"\"\"\n",
    "    è®°å¿†ç³»ç»Ÿ - å¯è§†åŒ–å±•ç¤ºAIè®°ä½äº†ä»€ä¹ˆ\n",
    "    \"\"\"\n",
    "    \n",
    "    # ğŸ“– å‰§æœ¬è¿›åº¦\n",
    "    script_progress: Dict = field(default_factory=lambda: {\n",
    "        \"current_line\": 0,\n",
    "        \"total_lines\": 0,\n",
    "        \"completed_stages\": [],\n",
    "        \"current_stage\": \"Hook\",\n",
    "    })\n",
    "    \n",
    "    # ğŸ’¬ å¼¹å¹•è®°å¿†\n",
    "    danmaku_memory: Dict = field(default_factory=lambda: {\n",
    "        \"received\": [],          # æ”¶åˆ°çš„æ‰€æœ‰å¼¹å¹•\n",
    "        \"responded\": [],         # å·²å›åº”çš„\n",
    "        \"ignored\": [],           # è¢«å¿½ç•¥çš„\n",
    "        \"pending_questions\": [], # å¾…å›ç­”çš„é—®é¢˜\n",
    "    })\n",
    "    \n",
    "    # ğŸ¤ æ‰¿è¯ºè¿½è¸ª\n",
    "    promises: List[Dict] = field(default_factory=list)\n",
    "    # ä¾‹å¦‚: {\"content\": \"å®¤å‹ç”Ÿä¸ç”Ÿæ°”\", \"made_at_step\": 3, \"fulfilled\": False, \"answer_at_line\": 9}\n",
    "    \n",
    "    # ğŸ­ æ•…äº‹è¦ç‚¹\n",
    "    story_points: Dict = field(default_factory=lambda: {\n",
    "        \"mentioned\": [],         # å·²ç»æåˆ°çš„ä¿¡æ¯\n",
    "        \"upcoming\": [],          # å³å°†è¦è¯´çš„å…³é”®ç‚¹\n",
    "        \"revealed\": [],          # å·²æ­ç¤ºçš„\"ç­”æ¡ˆ\"\n",
    "    })\n",
    "    \n",
    "    # ğŸ˜Š æƒ…ç»ªè½¨è¿¹\n",
    "    emotion_track: List[Dict] = field(default_factory=list)\n",
    "    \n",
    "    def to_display(self) -> str:\n",
    "        \"\"\"ç”Ÿæˆç”¨æˆ·å¯è§çš„è®°å¿†çŠ¶æ€\"\"\"\n",
    "        lines = []\n",
    "        lines.append(\"â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "        lines.append(\"â”‚ ğŸ§  AIè®°å¿†çŠ¶æ€                               â”‚\")\n",
    "        lines.append(\"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\")\n",
    "        \n",
    "        # å‰§æœ¬è¿›åº¦\n",
    "        prog = self.script_progress\n",
    "        current = prog.get(\"current_line\", 0)\n",
    "        total = prog.get(\"total_lines\", 0)\n",
    "        if total > 0:\n",
    "            percent = int(current / total * 10)\n",
    "            bar = \"â–ˆ\" * percent + \"â–‘\" * (10 - percent)\n",
    "            lines.append(f\"â”‚ ğŸ“– å‰§æœ¬: [{bar}] {current}/{total} ({prog.get('current_stage', '?')})  â”‚\")\n",
    "        \n",
    "        # å¼¹å¹•è®°å¿†\n",
    "        dm = self.danmaku_memory\n",
    "        responded = len(dm.get(\"responded\", []))\n",
    "        pending = len(dm.get(\"pending_questions\", []))\n",
    "        lines.append(f\"â”‚ ğŸ’¬ å¼¹å¹•: å·²å›åº”{responded}æ¡, å¾…å›ç­”{pending}ä¸ªé—®é¢˜         â”‚\")\n",
    "        \n",
    "        # æ‰¿è¯º\n",
    "        unfulfilled = [p for p in self.promises if not p.get(\"fulfilled\", False)]\n",
    "        if unfulfilled:\n",
    "            lines.append(\"â”‚ ğŸ¤ å¾…å…‘ç°æ‰¿è¯º:                              â”‚\")\n",
    "            for p in unfulfilled[:2]:\n",
    "                content = p.get(\"content\", \"\")[:20]\n",
    "                lines.append(f\"â”‚    â€¢ {content}...                         â”‚\")\n",
    "        \n",
    "        # å·²æåˆ°è¦ç‚¹\n",
    "        mentioned = self.story_points.get(\"mentioned\", [])\n",
    "        if mentioned:\n",
    "            lines.append(\"â”‚ ğŸ­ å·²æåˆ°:                                  â”‚\")\n",
    "            for point in mentioned[-3:]:\n",
    "                lines.append(f\"â”‚    âœ“ {point[:20]}...                      â”‚\")\n",
    "        \n",
    "        lines.append(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def to_context(self) -> str:\n",
    "        \"\"\"ç”Ÿæˆç»™LLMçš„ä¸Šä¸‹æ–‡æ‘˜è¦\"\"\"\n",
    "        parts = []\n",
    "        \n",
    "        # å‰§æœ¬è¿›åº¦\n",
    "        prog = self.script_progress\n",
    "        parts.append(f\"å‰§æœ¬è¿›åº¦: {prog.get('current_line')}/{prog.get('total_lines')} ({prog.get('current_stage')})\")\n",
    "        \n",
    "        # å·²æåˆ°çš„ä¿¡æ¯\n",
    "        mentioned = self.story_points.get(\"mentioned\", [])\n",
    "        if mentioned:\n",
    "            parts.append(f\"å·²æåˆ°: {', '.join(mentioned[-5:])}\")\n",
    "        \n",
    "        # å¾…å›ç­”é—®é¢˜\n",
    "        pending = self.danmaku_memory.get(\"pending_questions\", [])\n",
    "        if pending:\n",
    "            parts.append(f\"å¾…å›ç­”: {', '.join(q[:20] for q in pending[:3])}\")\n",
    "        \n",
    "        # æœªå…‘ç°æ‰¿è¯º\n",
    "        unfulfilled = [p for p in self.promises if not p.get(\"fulfilled\", False)]\n",
    "        if unfulfilled:\n",
    "            parts.append(f\"å¾…å…‘ç°æ‰¿è¯º: {', '.join(p['content'][:15] for p in unfulfilled[:2])}\")\n",
    "        \n",
    "        return \" | \".join(parts)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PerformanceState:\n",
    "    \"\"\"è¡¨æ¼”çŠ¶æ€\"\"\"\n",
    "    name: str\n",
    "    persona: str\n",
    "    background: str\n",
    "    topic: str\n",
    "    \n",
    "    # å®Œæ•´å‰§æœ¬ï¼ˆé¢„ç”Ÿæˆï¼‰\n",
    "    script_lines: List[ScriptLine] = field(default_factory=list)\n",
    "    current_line_idx: int = 0\n",
    "    current_step: int = 0\n",
    "    \n",
    "    # è®°å¿†ç³»ç»Ÿ\n",
    "    memory: PerformerMemory = field(default_factory=PerformerMemory)\n",
    "    \n",
    "    # å¼¹å¹•é˜Ÿåˆ—\n",
    "    danmaku_queue: List[Danmaku] = field(default_factory=list)\n",
    "    \n",
    "    # å£ç™–\n",
    "    catchphrases: List[str] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.5: å¼¹å¹•å¤„ç†æ ¸å¿ƒï¼ˆç»Ÿä¸€ä¼˜å…ˆçº§ç³»ç»Ÿï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== å·¥å…·å‡½æ•° ====================\n",
    "\n",
    "def extract_keywords(text: str) -> List[str]:\n",
    "    \"\"\"æå–å…³é”®è¯ï¼ˆç®€å•ç‰ˆï¼‰\"\"\"\n",
    "    import re\n",
    "    # ç§»é™¤æ ‡ç‚¹\n",
    "    text = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼šï¼›\"\"''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹â€¦~]', ' ', text)\n",
    "    # åˆ†è¯ï¼ˆç®€å•æŒ‰ç©ºæ ¼ï¼‰\n",
    "    words = text.split()\n",
    "    # è¿‡æ»¤åœç”¨è¯\n",
    "    stopwords = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'ä»¬', \n",
    "                 'è¿™', 'é‚£', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'ä¹Ÿ', 'éƒ½', 'è¯´', 'å¾ˆ',\n",
    "                 'å—', 'å§', 'å‘¢', 'å•Š', 'å“¦', 'å—¯', 'å“ˆ', 'å‘€'}\n",
    "    keywords = [w for w in words if len(w) >= 2 and w not in stopwords]\n",
    "    return keywords[:5]  # æœ€å¤š5ä¸ª\n",
    "\n",
    "\n",
    "# ==================== å¼¹å¹•å¤„ç†å™¨ ====================\n",
    "\n",
    "class DanmakuEvaluator:\n",
    "    \"\"\"\n",
    "    å¼¹å¹•è¯„ä¼°å™¨ - è®¡ç®—ä¼˜å…ˆçº§\n",
    "    \n",
    "    ä¼˜å…ˆçº§å…¬å¼:\n",
    "    priority = base_score + relevance_bonus + sc_bonus\n",
    "    \"\"\"\n",
    "    \n",
    "    def evaluate(self, danmaku: Danmaku, state: PerformanceState) -> Danmaku:\n",
    "        \"\"\"è¯„ä¼°å•æ¡å¼¹å¹•\"\"\"\n",
    "        \n",
    "        # 1. åŸºç¡€åˆ†\n",
    "        if danmaku.is_question():\n",
    "            base = 0.3  # é—®é¢˜ç±»\n",
    "        elif any(kw in danmaku.text for kw in [\"å“ˆå“ˆ\", \"ç¬‘æ­»\", \"çœŸçš„å‡çš„\", \"ï¼\", \"ç‰›\"]):\n",
    "            base = 0.15  # æƒ…ç»ªåé¦ˆç±»\n",
    "        else:\n",
    "            base = 0.1  # æ™®é€šè¯„è®º\n",
    "        \n",
    "        # 2. ç›¸å…³æ€§è¯„ä¼°\n",
    "        relevance = self._calc_relevance(danmaku.text, state)\n",
    "        danmaku.relevance = relevance\n",
    "        \n",
    "        if relevance > 0.7:\n",
    "            relevance_bonus = 0.4  # é«˜ç›¸å…³\n",
    "        elif relevance > 0.4:\n",
    "            relevance_bonus = 0.2  # ä¸­ç›¸å…³\n",
    "        else:\n",
    "            relevance_bonus = 0.0  # ä½ç›¸å…³\n",
    "        \n",
    "        # 3. SCåŠ æˆ\n",
    "        if danmaku.is_sc:\n",
    "            if danmaku.amount >= 200:\n",
    "                sc_bonus = 0.7\n",
    "            elif danmaku.amount >= 100:\n",
    "                sc_bonus = 0.5\n",
    "            elif danmaku.amount >= 50:\n",
    "                sc_bonus = 0.3\n",
    "            else:\n",
    "                sc_bonus = 0.2\n",
    "        else:\n",
    "            sc_bonus = 0.0\n",
    "        \n",
    "        danmaku.priority = base + relevance_bonus + sc_bonus\n",
    "        \n",
    "        return danmaku\n",
    "    \n",
    "    def _calc_relevance(self, text: str, state: PerformanceState) -> float:\n",
    "        \"\"\"è®¡ç®—å¼¹å¹•ä¸å½“å‰ä¸Šä¸‹æ–‡çš„ç›¸å…³æ€§\"\"\"\n",
    "        # æå–å½“å‰æ•…äº‹çš„å…³é”®è¯\n",
    "        story_keywords = set()\n",
    "        for info in state.memory.story_points.get(\"mentioned\", []):\n",
    "            story_keywords.update(extract_keywords(info))\n",
    "        for info in state.memory.story_points.get(\"upcoming\", []):\n",
    "            story_keywords.update(extract_keywords(info))\n",
    "        \n",
    "        # å¦‚æœæ²¡æœ‰æ•…äº‹å…³é”®è¯ï¼Œæ£€æŸ¥è¯é¢˜\n",
    "        if not story_keywords:\n",
    "            story_keywords.update(extract_keywords(state.topic))\n",
    "        \n",
    "        # æå–å¼¹å¹•å…³é”®è¯\n",
    "        danmaku_keywords = set(extract_keywords(text))\n",
    "        \n",
    "        # è®¡ç®—é‡å åº¦\n",
    "        if not story_keywords:\n",
    "            return 0.0\n",
    "        overlap = len(danmaku_keywords & story_keywords)\n",
    "        return min(overlap / 2, 1.0)  # 2ä¸ªå…³é”®è¯é‡å å°±ç®—é«˜ç›¸å…³\n",
    "\n",
    "\n",
    "class DanmakuHandler:\n",
    "    \"\"\"\n",
    "    ç»Ÿä¸€å¼¹å¹•å¤„ç†å™¨\n",
    "    \n",
    "    æ‰€æœ‰å¼¹å¹•èµ°åŒä¸€æµç¨‹ï¼Œæ ¹æ®ä¼˜å…ˆçº§å†³å®šï¼š\n",
    "    1. æ˜¯å¦æ‰“æ–­\n",
    "    2. æ˜¯å¦å¤è¯»\n",
    "    3. å¦‚ä½•å›åº”\n",
    "    4. æ˜¯å¦æ”¹å˜å™äº‹\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, evaluator: DanmakuEvaluator):\n",
    "        self.evaluator = evaluator\n",
    "    \n",
    "    def handle(self, danmaku: Danmaku, state: PerformanceState) -> Dict:\n",
    "        \"\"\"\n",
    "        å¤„ç†å¼¹å¹•\n",
    "        \n",
    "        Returns:\n",
    "            {\n",
    "                \"should_interrupt\": bool,\n",
    "                \"echo\": str,\n",
    "                \"response\": str,\n",
    "                \"action\": str,  # continue/jump/tease/improvise\n",
    "            }\n",
    "        \"\"\"\n",
    "        \n",
    "        # è¯„ä¼°ä¼˜å…ˆçº§\n",
    "        danmaku = self.evaluator.evaluate(danmaku, state)\n",
    "        \n",
    "        # è·å–å½“å‰cost\n",
    "        if state.current_line_idx >= len(state.script_lines):\n",
    "            current_cost = 0.2  # ç»“å°¾é˜¶æ®µ\n",
    "        else:\n",
    "            current_line = state.script_lines[state.current_line_idx]\n",
    "            current_cost = current_line.interruption_cost\n",
    "        \n",
    "        # å†³ç­–ï¼šæ˜¯å¦æ‰“æ–­\n",
    "        should_interrupt = danmaku.priority > current_cost\n",
    "        \n",
    "        if not should_interrupt:\n",
    "            return {\n",
    "                \"should_interrupt\": False,\n",
    "                \"action\": \"ignore\",\n",
    "                \"priority\": danmaku.priority,\n",
    "                \"cost\": current_cost\n",
    "            }\n",
    "        \n",
    "        # å†³å®šæ˜¯å¦å¤è¯»\n",
    "        echo = self._maybe_echo(danmaku)\n",
    "        \n",
    "        # æŸ¥æ‰¾ç­”æ¡ˆä½ç½®\n",
    "        answer_loc = self._find_answer(danmaku.text, state)\n",
    "        \n",
    "        # ç”Ÿæˆå›åº”ç­–ç•¥\n",
    "        action = self._decide_action(danmaku, answer_loc, state)\n",
    "        \n",
    "        return {\n",
    "            \"should_interrupt\": True,\n",
    "            \"echo\": echo,\n",
    "            \"action\": action,\n",
    "            \"answer_loc\": answer_loc,\n",
    "            \"priority\": danmaku.priority,\n",
    "            \"cost\": current_cost,\n",
    "            \"relevance\": danmaku.relevance\n",
    "        }\n",
    "    \n",
    "    def _maybe_echo(self, danmaku: Danmaku) -> str:\n",
    "        \"\"\"å†³å®šæ˜¯å¦å¤è¯»å¼¹å¹•\"\"\"\n",
    "        if danmaku.is_sc:\n",
    "            return f\"è¯¶æœ‰SCï¼æœ‰äººè¯´ï¼š{danmaku.text}\"\n",
    "        elif danmaku.priority > 0.5:\n",
    "            return f\"æœ‰äººè¯´{danmaku.text}ï¼Œ\"\n",
    "        elif danmaku.is_question():\n",
    "            return f\"æœ‰äººé—®{danmaku.text}ï¼Œ\"\n",
    "        else:\n",
    "            return \"\"  # ä¸å¤è¯»\n",
    "    \n",
    "    def _find_answer(self, question: str, state: PerformanceState) -> Dict:\n",
    "        \"\"\"åœ¨å‰§æœ¬ä¸­æŸ¥æ‰¾é—®é¢˜çš„ç­”æ¡ˆä½ç½®\"\"\"\n",
    "        keywords = extract_keywords(question)\n",
    "        current_idx = state.current_line_idx\n",
    "        \n",
    "        for i, line in enumerate(state.script_lines):\n",
    "            if i < current_idx:\n",
    "                continue  # è·³è¿‡å·²ç»è¯´è¿‡çš„\n",
    "            \n",
    "            for info in line.key_info:\n",
    "                if any(kw in info for kw in keywords):\n",
    "                    return {\n",
    "                        \"found\": True,\n",
    "                        \"line_idx\": i,\n",
    "                        \"distance\": i - current_idx,\n",
    "                        \"answer_hint\": info,\n",
    "                    }\n",
    "        \n",
    "        return {\"found\": False}\n",
    "    \n",
    "    def _decide_action(self, danmaku: Danmaku, answer_loc: Dict, \n",
    "                       state: PerformanceState) -> str:\n",
    "        \"\"\"\n",
    "        å†³å®šå™äº‹åŠ¨ä½œ\n",
    "        \n",
    "        - continue: å›åº”åç»§ç»­å½“å‰å‰§æœ¬\n",
    "        - jump: è·³è·ƒåˆ°ç­”æ¡ˆä½ç½®\n",
    "        - reveal: ç›´æ¥æ­æ™“ç­”æ¡ˆ\n",
    "        - tease: åŠèƒƒå£\n",
    "        - improvise: å³å…´å›ç­”\n",
    "        \"\"\"\n",
    "        \n",
    "        if not answer_loc.get(\"found\", False):\n",
    "            return \"improvise\"\n",
    "        \n",
    "        distance = answer_loc.get(\"distance\", 0)\n",
    "        \n",
    "        # æ ¹æ®ä¼˜å…ˆçº§å’Œè·ç¦»å†³å®šç­–ç•¥\n",
    "        if danmaku.priority > 0.8:\n",
    "            # é«˜ä¼˜å…ˆçº§ï¼ˆå¤§é¢SCæˆ–é«˜ç›¸å…³é—®é¢˜ï¼‰\n",
    "            if distance <= 3:\n",
    "                return \"jump\"\n",
    "            else:\n",
    "                return \"tease\"\n",
    "        elif danmaku.priority > 0.5:\n",
    "            # ä¸­ä¼˜å…ˆçº§\n",
    "            if distance <= 2:\n",
    "                return \"continue\"\n",
    "            else:\n",
    "                return \"tease\"\n",
    "        else:\n",
    "            # ä½ä¼˜å…ˆçº§\n",
    "            return \"continue\"\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–\n",
    "evaluator = DanmakuEvaluator()\n",
    "danmaku_handler = DanmakuHandler(evaluator)\n",
    "\n",
    "print(\"âœ… å¼¹å¹•å¤„ç†å™¨å·²åˆå§‹åŒ–\")\n",
    "print(\"  â€¢ ä¼˜å…ˆçº§å…¬å¼: priority = base + relevance_bonus + sc_bonus\")\n",
    "print(\"  â€¢ ç›¸å…³æ€§æ˜¯æœ€é‡è¦å› ç´ \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.6: å‰§æœ¬ç”Ÿæˆå™¨ï¼ˆé¢„ç”Ÿæˆå®Œæ•´å°è¯ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScriptGeneratorV2:\n",
    "    \"\"\"\n",
    "    å‰§æœ¬ç”Ÿæˆå™¨ V2 - é¢„ç”Ÿæˆå®Œæ•´å°è¯ï¼ˆå¸¦ key_info æ ‡æ³¨ï¼‰\n",
    "    \"\"\"\n",
    "    \n",
    "    SYSTEM_PROMPT = \"\"\"ä½ æ˜¯VTuberå‰§æœ¬ç¼–å‰§ã€‚ç”Ÿæˆ**åœºæ™¯åŒ–å°è¯**ï¼Œç»„æˆå®Œæ•´æ•…äº‹ã€‚\n",
    "\n",
    "âš ï¸ **æ•°é‡è¦æ±‚ï¼šå¿…é¡»ç”Ÿæˆ15-18å¥å°è¯**ï¼ˆå‚è€ƒclip_005æ ‡å‡†ï¼š403ç§’/15-18ä¸ªå™äº‹å•å…ƒï¼‰\n",
    "\n",
    "## ğŸ”¥ å…³é”®ï¼šå¿…é¡»æ˜¯åœºæ™¯åŒ–å™äº‹ï¼Œä¸è¦æ€»ç»“å¼ï¼\n",
    "\n",
    "### âŒ é”™è¯¯ç¤ºèŒƒï¼ˆæ€»ç»“å¼ï¼Œå¤ªå¹²ç˜ªï¼‰\n",
    "```\n",
    "\"é‚£æ—¶å€™æˆ‘åˆšåˆ°æ—¥æœ¬ï¼Œç©·å¾—å®å½“å“\"\n",
    "\"å®¤å‹æ˜¯å¯ŒäºŒä»£ï¼Œæœ‰å¾ˆå¤šé›¶é£Ÿ\"\n",
    "\"æˆ‘å·åƒäº†å®¤å‹çš„è…°æœï¼Œå¾ˆç´§å¼ \"\n",
    "\"åæ¥å¦ç™½äº†ï¼Œå®¤å‹å¾ˆå®½å®¹\"\n",
    "```\n",
    "â†‘ è¿™ç§åƒåœ¨åšæ‘˜è¦ï¼Œç¼ºä¹ç»†èŠ‚å’Œå†…å¿ƒæˆï¼Œ**ç»å¯¹ä¸è¦è¿™æ ·å†™ï¼**\n",
    "\n",
    "### âœ… æ­£ç¡®ç¤ºèŒƒï¼ˆåœºæ™¯åŒ–ï¼Œæœ‰è´¨æ„Ÿï¼‰\n",
    "```\n",
    "\"æˆ‘é‚£ä¸ªæ—¶å€™ä¸€ä¸ªæœˆç»™è‡ªå·±è®¢çš„ï¼Œä¸€ä¸ªæœˆå–ä¸‰ç“¶å¯ä¹ï¼Œå› ä¸ºæˆ‘ç‰¹åˆ«çˆ±å–å¯ä¹ï¼Œä½†æ˜¯å½“æ—¶æ²¡é’±\"\n",
    "  â†’ å…·ä½“æ•°å­—ã€ç”Ÿæ´»ç»†èŠ‚ã€å£è¯­åŒ–\n",
    "\n",
    "\"æˆ‘çœ‹ç€é‚£ä¸ªå†°ç®±é‡Œçš„ï¼Œä»–çš„é‚£ä¸ªæµ·è‹”ç‚’è…°æœï¼Œæˆ‘å¥½é¦‹å‘€ã€‚æˆ‘æƒ³ç€æˆ‘åƒä¸€ä¸ªè…°æœï¼Œä»–å›æ¥ä»–åˆä¸æ•°ï¼Œä»–åº”è¯¥ä¸çŸ¥é“å§\"\n",
    "  â†’ å†…å¿ƒç‹¬ç™½ã€çŠ¹è±«è¿‡ç¨‹ã€åœºæ™¯æå†™\n",
    "\n",
    "\"ç¬¬äºŒå¤©åˆæƒ³ç€ï¼Œè¦ä¸æˆ‘å†å·åƒä¸€ä¸ªå§ã€‚ç»“æœæˆ‘åƒç€åƒç€ï¼Œä»–è¿˜æ²¡å›æ¥ï¼Œæˆ‘å·²ç»æŠŠé‡Œé¢çš„è…°æœåƒå®Œäº†\"\n",
    "  â†’ æ—¶é—´æ¨è¿›ã€è¡ŒåŠ¨å‡çº§ã€è‡ªç„¶æ¨è¿›\n",
    "\n",
    "\"æŠŠæˆ‘ç´§å¼ çš„éƒ½ç¡ä¸ç€è§‰äº†ï¼Œæ¯å¤©æ™šä¸Šæˆ‘éƒ½æ²¡ç¡ç€ï¼Œå› ä¸ºå½“æˆ‘æ„è¯†åˆ°ï¼Œæˆ‘åœ¨é‡Œå¤´ä¸€ç¿»è…¾ï¼Œå‘ç°è…°æœæ²¡äº†\"\n",
    "  â†’ æƒ…ç»ªæå†™ã€å…·ä½“åŠ¨ä½œã€å¿ƒç†è´Ÿæ‹…\n",
    "\n",
    "\"ä»–è¯´'ä½ æƒ³åƒå°±åƒå‘€éšä¾¿åƒå‘€'ã€‚æˆ‘è¯´çœŸçš„å—ï¼Ÿæˆ‘ä¸€æƒ³å“‡ï¼Œè¿™ä¹ˆæ…·æ…¨æˆ‘çœŸçš„å¯ä»¥éšä¾¿åƒå—ï¼Ÿä»–è¯´'å¯¹å‘€ï¼Œä½ æƒ³åƒæˆ‘å†ç»™ä½ æ‹¿ä¸€ç›’æ¥å•Š'\"\n",
    "  â†’ å®Œæ•´å¯¹è¯ã€å†…å¿ƒååº”ã€æƒ…ç»ªé‡Šæ”¾\n",
    "```\n",
    "\n",
    "## å†™ä½œæŠ€å·§æ¸…å•ï¼ˆæ¯å¥å¿…å¤‡ï¼‰\n",
    "\n",
    "âœ… **å¿…é¡»åŒ…å«çš„å…ƒç´ **ï¼š\n",
    "1. **å…·ä½“æ•°å­—/ç»†èŠ‚** - \"ä¸€ä¸ªæœˆä¸‰ç“¶å¯ä¹\" ä¸è¦ \"å¾ˆå°‘\"\n",
    "2. **å†…å¿ƒç‹¬ç™½** - \"æˆ‘å¿ƒæƒ³\"ã€\"æˆ‘æƒ³ç€\"ã€\"å“å‘€\"ã€\"æˆ‘ä¸€æƒ³\"\n",
    "3. **æƒ…ç»ªæå†™** - \"ç´§å¼ çš„ç¡ä¸ç€\"ã€\"å¿ƒç†è´Ÿæ‹…å¯é‡äº†\"ã€\"æˆ‘å¥½é¦‹å‘€\"\n",
    "4. **ç”Ÿæ´»è´¨æ„Ÿ** - é…±æ²¹æ‹Œé¥­ã€å†°ç®±ã€æ±‡ç‡ã€æˆ¿é—´ã€ä¸œè¥¿çš„åå­—\n",
    "5. **å¯¹è¯åœºæ™¯** - å†™å®Œæ•´å¯¹è¯ï¼Œä¸è¦è½¬è¿°\"ä»–è¯´äº†...\"\n",
    "6. **æ—¶é—´æ¨è¿›** - \"ç¬¬äºŒå¤©\"ã€\"ç»“æœ\"ã€\"åæ¥\"ã€\"é‚£ä¸ªæ—¶å€™\"\n",
    "7. **å¿ƒè·¯å†ç¨‹** - çŠ¹è±«â†’è¡ŒåŠ¨â†’åæ‚”â†’é‡Šç„¶ï¼Œå±•ç¤ºå˜åŒ–è¿‡ç¨‹\n",
    "\n",
    "âœ… **è¯­è¨€é£æ ¼**ï¼š\n",
    "- å£è¯­åŒ–ã€æœ‰åœé¡¿ã€è‡ªæˆ‘ä¿®æ­£ï¼ˆ\"ä¸‰ç“¶è¿˜æ˜¯å››ç“¶\"ã€\"å¯¹å§\"ã€\"å°±æ˜¯è¯´\"ï¼‰\n",
    "- å…è®¸é‡å¤å¼ºè°ƒï¼ˆ\"çœŸçš„å—ï¼ŸçœŸçš„å—ï¼Ÿ\"ã€\"å¤©å“ª\"ï¼‰\n",
    "- ç”¨\"ç„¶å\"ã€\"ç»“æœ\"ã€\"åæ¥\"è¿æ¥ï¼Œåƒåœ¨èŠå¤©\n",
    "- å±•ç¤ºæ€è€ƒè¿‡ç¨‹ï¼Œä¸è¦ç›´æ¥ç»™ç»“è®º\n",
    "\n",
    "âœ… **å™äº‹èŠ‚å¥**ï¼š\n",
    "- ä¸è¦è·³è¿‡è¿‡ç¨‹ï¼è¦å±•ç¤ºå¿ƒè·¯å†ç¨‹\n",
    "- é“ºå«è¦å……åˆ†ï¼ˆå…ˆè¯´ç©·â†’å¯ä¹é™é‡â†’å®¤å‹å¯Œâ†’çœ‹åˆ°è…°æœâ†’èµ·è´ªå¿µï¼‰\n",
    "- é«˜æ½®è¦æœ‰å¼ åŠ›ï¼ˆç¬¬ä¸€æ¬¡å·åƒâ†’ç¬¬äºŒå¤©åˆåƒâ†’å‘ç°åƒå®Œâ†’å¤±çœ â†’å¦ç™½â†’é‡Šç„¶ï¼‰\n",
    "- ç”¨å†…å¿ƒæˆæ‹‰é•¿æ—¶é—´æ„Ÿ\n",
    "\n",
    "## å™äº‹ç»“æ„\n",
    "- Hook (2-3å¥): æ‚¬å¿µ/é—®é¢˜å¼€åœºï¼Œ0.2-0.4 cost\n",
    "- Build-up (4-5å¥): é“ºå«èƒŒæ™¯ï¼Œç§¯ç´¯æƒ…ç»ªï¼Œ0.5-0.7 cost\n",
    "- Climax (3-4å¥): é«˜æ½®è½¬æŠ˜ï¼Œæ­æ™“ç­”æ¡ˆï¼Œ0.8-0.9 cost\n",
    "- Resolution (2-3å¥): æ€»ç»“å‡åï¼Œ0.3-0.5 cost\n",
    "\n",
    "## key_info æ ‡æ³¨ï¼ˆç”¨äºåŒ¹é…å¼¹å¹•é—®é¢˜ï¼‰\n",
    "\n",
    "\"æˆ‘é‚£ä¸ªæ—¶å€™ä¸€ä¸ªæœˆç»™è‡ªå·±è®¢çš„ï¼Œä¸€ä¸ªæœˆå–ä¸‰ç“¶å¯ä¹\"\n",
    "key_info: [\"ç•™å­¦ç©·å›°\", \"å¯ä¹é™é‡\", \"èŠ‚çº¦ç”Ÿæ´»\"]\n",
    "\n",
    "\"æˆ‘æƒ³æˆ‘åƒä¸€ä¸ªè…°æœï¼Œä»–å›æ¥ä»–åˆä¸æ•°ï¼Œä»–åº”è¯¥ä¸çŸ¥é“å§\"\n",
    "key_info: [\"ç¬¬ä¸€æ¬¡å·åƒ\", \"ä¾¥å¹¸å¿ƒç†\", \"å†…å¿ƒæŒ£æ‰\"]\n",
    "\n",
    "\"ä»–è¯´ä½ æƒ³åƒå°±åƒå‘€éšä¾¿åƒå‘€\"\n",
    "key_info: [\"å®¤å‹ååº”\", \"å®¤å‹å®½å®¹\", \"æ²¡ç”Ÿæ°”\", \"å±æœºè§£é™¤\"]  â† è¿™æ˜¯\"å®¤å‹ç”Ÿæ°”å—\"çš„ç­”æ¡ˆï¼\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: LLMClient, analyzer: PatternAnalyzer = None):\n",
    "        self.llm = llm\n",
    "        self.analyzer = analyzer\n",
    "    \n",
    "    def generate(self, name: str, persona: str, background: str, \n",
    "                 topic: str, language: str = \"zh\") -> List[ScriptLine]:\n",
    "        \"\"\"ç”Ÿæˆå®Œæ•´å‰§æœ¬\"\"\"\n",
    "        \n",
    "        # è·å–å‚è€ƒæ•°æ®\n",
    "        catchphrases = \"\"\n",
    "        example_hooks = \"\"\n",
    "        \n",
    "        if self.analyzer:\n",
    "            cps = self.analyzer.extract_catchphrases(language)[:5]\n",
    "            catchphrases = \", \".join(f'\"{c}\"' for c, _ in cps)\n",
    "            \n",
    "            hooks = self.analyzer.extract_hooks(language)[:2]\n",
    "            example_hooks = \"\\n\".join(f'- \"{h[:50]}...\"' for h in hooks)\n",
    "        \n",
    "        prompt = f\"\"\"ä¸º {name} ç”Ÿæˆå…³äº\"{topic}\"çš„åœºæ™¯åŒ–æ•…äº‹å‰§æœ¬ã€‚\n",
    "\n",
    "## è§’è‰²ä¿¡æ¯\n",
    "- åå­—: {name}\n",
    "- äººè®¾: {persona}\n",
    "- èƒŒæ™¯: {background}\n",
    "- è¯é¢˜: {topic}\n",
    "- å£ç™–: {catchphrases or \"è‡ªç„¶å³å¯\"}\n",
    "\n",
    "## å¼€åœºå‚è€ƒ\n",
    "{example_hooks or \"ï¼ˆæ— ï¼‰\"}\n",
    "\n",
    "## âš ï¸ æ•°é‡è¦æ±‚ï¼ˆä¸¥æ ¼éµå®ˆï¼ï¼‰\n",
    "\n",
    "**å¿…é¡»ç”Ÿæˆ 15-18 å¥å°è¯**ï¼ˆå‚è€ƒ clip_005 æ ‡å‡†ï¼‰\n",
    "\n",
    "ç»“æ„åˆ†é…ï¼š\n",
    "- **Hookï¼ˆå¼€åœºï¼‰**: 3å¥ - æ‚¬å¿µ/é—®é¢˜å¼€åœºï¼Œå¸å¼•æ³¨æ„\n",
    "- **Build-upï¼ˆé“ºå«ï¼‰**: 6-7å¥ - è¯¦ç»†é“ºå«èƒŒæ™¯ï¼Œå¤§é‡ç”Ÿæ´»ç»†èŠ‚å’Œå†…å¿ƒæˆ\n",
    "- **Climaxï¼ˆé«˜æ½®ï¼‰**: 4-5å¥ - è½¬æŠ˜ã€æƒ…ç»ªçˆ†å‘ã€æ­æ™“ç­”æ¡ˆ\n",
    "- **Resolutionï¼ˆæ”¶å°¾ï¼‰**: 2-3å¥ - æƒ…ç»ªé‡Šæ”¾ã€æ€»ç»“å‡å\n",
    "\n",
    "âš ï¸ **å°‘äº15å¥ä¼šå¯¼è‡´å™äº‹ä¸å¤Ÿä¸°å¯Œã€ç»†èŠ‚ä¸è¶³ï¼è¯·ä¸¥æ ¼ç”Ÿæˆ15-18å¥ï¼**\n",
    "\n",
    "## å†™ä½œè¦æ±‚ï¼ˆæ¯å¥å¿…å¤‡ï¼‰\n",
    "\n",
    "1. **å…·ä½“æ•°å­—/ç»†èŠ‚** - \"ä¸€ä¸ªæœˆä¸‰ç“¶å¯ä¹\" ä¸è¦ \"å¾ˆå°‘\"\n",
    "2. **å†…å¿ƒç‹¬ç™½** - \"æˆ‘å¿ƒæƒ³\"ã€\"æˆ‘æƒ³ç€\"ã€\"å“å‘€\"\n",
    "3. **æƒ…ç»ªæå†™** - \"ç´§å¼ çš„ç¡ä¸ç€\"ã€\"å¿ƒç†è´Ÿæ‹…å¯é‡äº†\"\n",
    "4. **ç”Ÿæ´»è´¨æ„Ÿ** - é…±æ²¹æ‹Œé¥­ã€å†°ç®±ã€æ±‡ç‡ã€ç‰©å“å\n",
    "5. **å®Œæ•´å¯¹è¯** - å†™å‡ºæ¥ï¼Œä¸è¦è½¬è¿°\n",
    "6. **æ—¶é—´æ¨è¿›** - \"ç¬¬äºŒå¤©\"ã€\"ç»“æœ\"ã€\"åæ¥\"\n",
    "\n",
    "### ä¸è¦å†™æ€»ç»“å¼ï¼ˆâŒï¼‰\n",
    "âŒ \"é‚£æ—¶å€™æˆ‘å¾ˆç©·\" \n",
    "âœ… \"æˆ‘é‚£ä¸ªæ—¶å€™ä¸€ä¸ªæœˆç»™è‡ªå·±è®¢çš„ï¼Œä¸€ä¸ªæœˆå–ä¸‰ç“¶å¯ä¹ï¼Œä¸‰ç“¶è¿˜æ˜¯å››ç“¶ï¼Œå› ä¸ºæˆ‘ç‰¹åˆ«çˆ±å–ï¼Œä½†æ˜¯å½“æ—¶æ²¡é’±\"\n",
    "\n",
    "## è¾“å‡ºæ ¼å¼\n",
    "\n",
    "JSONæ•°ç»„ï¼š\n",
    "[\n",
    "  {{\"text\": \"å°è¯ï¼ˆè¦é•¿ï¼æœ‰ç»†èŠ‚ï¼æœ‰å†…å¿ƒæˆï¼ï¼‰\", \"stage\": \"Hook\", \"cost\": 0.3, \"key_info\": [\"ä¿¡æ¯1\", \"ä¿¡æ¯2\"]}},\n",
    "  ...è‡³å°‘12ä¸ªå…ƒç´ ...\n",
    "]\n",
    "\n",
    "è¦æ±‚ï¼š\n",
    "- **ä¸¥æ ¼ç”Ÿæˆ15-18å¥ï¼ˆå‚è€ƒclip_005å¯†åº¦ï¼‰**\n",
    "- æ¯å¥æ¨è¿›æ–°ä¿¡æ¯ï¼Œä¸é‡å¤\n",
    "- key_infoå‡†ç¡®ï¼ˆç”¨äºåŒ¹é…å¼¹å¹•ï¼‰\n",
    "- ç¬¦åˆ{name}äººè®¾å’Œå£ç™–\n",
    "- å°è¯è¦é•¿ï¼Œæœ‰åœºæ™¯æ„Ÿï¼Œæœ‰ç»†èŠ‚\n",
    "\n",
    "âš ï¸ å¦‚æœç”Ÿæˆå°‘äº15å¥ï¼Œè¯´æ˜ç»†èŠ‚ä¸å¤Ÿä¸°å¯Œï¼Œè¯·é‡æ–°ç”Ÿæˆï¼\n",
    "\n",
    "åªè¾“å‡ºJSONæ•°ç»„ã€‚\"\"\"\n",
    "        \n",
    "        response = self.llm.call(prompt, system=self.SYSTEM_PROMPT, max_tokens=4500)\n",
    "        \n",
    "        try:\n",
    "            # è§£æJSON\n",
    "            if \"```\" in response:\n",
    "                json_str = response.split(\"```\")[1]\n",
    "                if json_str.startswith(\"json\"):\n",
    "                    json_str = json_str[4:]\n",
    "            else:\n",
    "                json_str = response\n",
    "            \n",
    "            lines_data = json.loads(json_str.strip())\n",
    "            \n",
    "            # è½¬æ¢ä¸º ScriptLine\n",
    "            script_lines = []\n",
    "            for i, line_data in enumerate(lines_data):\n",
    "                script_lines.append(ScriptLine(\n",
    "                    id=f\"line_{i}\",\n",
    "                    text=line_data.get(\"text\", \"\"),\n",
    "                    stage=line_data.get(\"stage\", \"Unknown\"),\n",
    "                    interruption_cost=line_data.get(\"cost\", 0.5),\n",
    "                    key_info=line_data.get(\"key_info\", [])\n",
    "                ))\n",
    "            \n",
    "            print(f\"âœ… ç”Ÿæˆäº† {len(script_lines)} å¥å°è¯\")\n",
    "            return script_lines\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[Script] è§£æå¤±è´¥: {e}\")\n",
    "            print(f\"å“åº”å†…å®¹: {response[:200]}...\")\n",
    "            return self._fallback_script(name, topic)\n",
    "    \n",
    "    def _fallback_script(self, name: str, topic: str) -> List[ScriptLine]:\n",
    "        \"\"\"åå¤‡å‰§æœ¬ï¼ˆ15å¥æ ‡å‡†ï¼‰\"\"\"\n",
    "        return [\n",
    "            # Hook (3å¥)\n",
    "            ScriptLine(\"line_0\", f\"å¤§å®¶å¥½ï¼Œä»Šå¤©æˆ‘æƒ³å’Œä½ ä»¬èŠèŠ{topic}\", \"Hook\", 0.3, [topic]),\n",
    "            ScriptLine(\"line_1\", \"è¿™æ˜¯ä¸€ä¸ªå¾ˆæœ‰æ„æ€çš„æ•…äº‹ï¼Œä½ ä»¬è‚¯å®šæƒ³ä¸åˆ°ä¼šå‘ç”Ÿä»€ä¹ˆ\", \"Hook\", 0.3, [\"å¼€åœºæ‚¬å¿µ\"]),\n",
    "            ScriptLine(\"line_2\", \"è®©æˆ‘æ…¢æ…¢è®²ç»™ä½ ä»¬å¬ï¼Œå…ˆä»èƒŒæ™¯è¯´èµ·\", \"Hook\", 0.4, [\"å¼•å…¥\"]),\n",
    "            # Build-up (6å¥)\n",
    "            ScriptLine(\"line_3\", \"æ•…äº‹æ˜¯è¿™æ ·çš„ï¼Œé‚£ä¸ªæ—¶å€™æˆ‘è¿˜...\", \"Build-up\", 0.5, [\"èƒŒæ™¯\"]),\n",
    "            ScriptLine(\"line_4\", \"æˆ‘è®°å¾—ç‰¹åˆ«æ¸…æ¥šï¼Œå½“æ—¶çš„æƒ…å†µæ˜¯è¿™æ ·çš„\", \"Build-up\", 0.6, [\"é“ºå«\"]),\n",
    "            ScriptLine(\"line_5\", \"æœ‰ä¸€ä¸ªå¾ˆé‡è¦çš„ç»†èŠ‚ï¼Œæˆ‘å¾—å‘Šè¯‰ä½ ä»¬\", \"Build-up\", 0.6, [\"ç»†èŠ‚\"]),\n",
    "            ScriptLine(\"line_6\", \"ç„¶åå‘¢ï¼Œäº‹æƒ…å¼€å§‹å˜å¾—æœ‰ç‚¹ä¸ä¸€æ ·äº†\", \"Build-up\", 0.7, [\"è½¬æŠ˜å‰å…†\"]),\n",
    "            ScriptLine(\"line_7\", \"æˆ‘å½“æ—¶å¿ƒé‡Œæƒ³ï¼Œè¿™äº‹å„¿å¯èƒ½è¦ä¸å¤ªå¦™\", \"Build-up\", 0.7, [\"å†…å¿ƒæˆ\"]),\n",
    "            ScriptLine(\"line_8\", \"ç»“æœæœç„¶ï¼Œæ¥ä¸‹æ¥å‘ç”Ÿäº†ä¸€ä»¶äº‹\", \"Build-up\", 0.7, [\"å³å°†é«˜æ½®\"]),\n",
    "            # Climax (4å¥)\n",
    "            ScriptLine(\"line_9\", \"å½“æ—¶æˆ‘æ•´ä¸ªäººéƒ½å‚»äº†ï¼Œä½ ä»¬çŒœå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ\", \"Climax\", 0.8, [\"é«˜æ½®å¼€å§‹\"]),\n",
    "            ScriptLine(\"line_10\", \"å°±åœ¨é‚£ä¸€ç¬é—´ï¼Œå…³é”®çš„è½¬æŠ˜æ¥äº†\", \"Climax\", 0.9, [\"è½¬æŠ˜\"]),\n",
    "            ScriptLine(\"line_11\", \"æˆ‘å‘Šè¯‰ä½ ä»¬ï¼Œç»“æœå®Œå…¨å‡ºä¹æ„æ–™\", \"Climax\", 0.8, [\"æ­æ™“\"]),\n",
    "            ScriptLine(\"line_12\", \"æ²¡æƒ³åˆ°æœ€åç«Ÿç„¶æ˜¯è¿™æ ·ï¼Œå“ˆå“ˆå“ˆ\", \"Climax\", 0.7, [\"ååº”\"]),\n",
    "            # Resolution (3å¥)\n",
    "            ScriptLine(\"line_13\", \"ç°åœ¨æƒ³èµ·æ¥è¿˜æ˜¯å¾ˆæ„Ÿæ…¨ï¼Œé‚£æ¬¡ç»å†çœŸçš„å¾ˆç‰¹åˆ«\", \"Resolution\", 0.4, [\"æ„Ÿæ‚Ÿ\"]),\n",
    "            ScriptLine(\"line_14\", \"åæ¥æˆ‘å°±æ˜ç™½äº†ä¸€ä¸ªé“ç†\", \"Resolution\", 0.3, [\"å‡å\"]),\n",
    "            ScriptLine(\"line_15\", \"ä½ ä»¬æœ‰ç±»ä¼¼ç»å†å—ï¼Ÿå¯ä»¥åœ¨å¼¹å¹•å‘Šè¯‰æˆ‘~\", \"Resolution\", 0.3, [\"äº’åŠ¨\"]),\n",
    "        ]\n",
    "\n",
    "\n",
    "print(\"âœ… å‰§æœ¬ç”Ÿæˆå™¨ V2 å·²å®šä¹‰ï¼ˆé¢„ç”Ÿæˆå®Œæ•´å°è¯æ¨¡å¼ï¼‰\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.7: è¡¨æ¼”å¼•æ“ V2ï¼ˆå¸¦è®°å¿†ç³»ç»Ÿï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformerV2:\n",
    "    \"\"\"\n",
    "    è¡¨æ¼”å¼•æ“ V2 - å¸¦è®°å¿†ç³»ç»Ÿå’Œç»Ÿä¸€å¼¹å¹•å¤„ç†\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm: LLMClient, tts: TTSClient, danmaku_handler: DanmakuHandler):\n",
    "        self.llm = llm\n",
    "        self.tts = tts\n",
    "        self.danmaku_handler = danmaku_handler\n",
    "    \n",
    "    def step(self, state: PerformanceState, new_danmaku: List[Danmaku] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        æ‰§è¡Œä¸€æ­¥è¡¨æ¼”\n",
    "        \n",
    "        æµç¨‹ï¼š\n",
    "        1. è¯„ä¼°å¼¹å¹•ä¼˜å…ˆçº§\n",
    "        2. å†³å®šæ˜¯å¦æ‰“æ–­å½“å‰å°è¯\n",
    "        3. å¦‚æœæ‰“æ–­ï¼šç”Ÿæˆå›åº” + æ‰¿æ¥å›å‰§æœ¬\n",
    "        4. å¦‚æœä¸æ‰“æ–­ï¼šè¯´å½“å‰å°è¯\n",
    "        5. æ›´æ–°è®°å¿†\n",
    "        6. æ£€æŸ¥æ‰¿è¯ºæ˜¯å¦è¯¥å…‘ç°\n",
    "        \"\"\"\n",
    "        \n",
    "        if new_danmaku:\n",
    "            state.danmaku_queue.extend(new_danmaku)\n",
    "            # è®°å½•åˆ°è®°å¿†\n",
    "            for d in new_danmaku:\n",
    "                state.memory.danmaku_memory[\"received\"].append(d.text)\n",
    "        \n",
    "        # æ£€æŸ¥ç»“æŸ\n",
    "        if state.current_line_idx >= len(state.script_lines):\n",
    "            return self._generate_ending(state)\n",
    "        \n",
    "        current_line = state.script_lines[state.current_line_idx]\n",
    "        \n",
    "        # å¤„ç†å¼¹å¹•\n",
    "        best_danmaku = None\n",
    "        handle_result = None\n",
    "        \n",
    "        if state.danmaku_queue:\n",
    "            # æ‰¾åˆ°æœ€é«˜ä¼˜å…ˆçº§çš„å¼¹å¹•\n",
    "            for danmaku in state.danmaku_queue:\n",
    "                result = self.danmaku_handler.handle(danmaku, state)\n",
    "                if result.get(\"should_interrupt\"):\n",
    "                    if best_danmaku is None or result.get(\"priority\", 0) > handle_result.get(\"priority\", 0):\n",
    "                        best_danmaku = danmaku\n",
    "                        handle_result = result\n",
    "        \n",
    "        # å†³ç­–\n",
    "        if best_danmaku and handle_result:\n",
    "            # æ‰“æ–­ï¼å›åº”å¼¹å¹•\n",
    "            output = self._handle_danmaku_response(best_danmaku, handle_result, current_line, state)\n",
    "            \n",
    "            # ä»é˜Ÿåˆ—ç§»é™¤\n",
    "            state.danmaku_queue = [d for d in state.danmaku_queue if d != best_danmaku]\n",
    "            \n",
    "            # è®°å½•åˆ°è®°å¿†\n",
    "            state.memory.danmaku_memory[\"responded\"].append(best_danmaku.text)\n",
    "            if best_danmaku.is_question():\n",
    "                # å¦‚æœæ˜¯é—®é¢˜ï¼Œæ£€æŸ¥æ˜¯å¦è®°å½•æ‰¿è¯º\n",
    "                if handle_result.get(\"action\") == \"tease\":\n",
    "                    answer_loc = handle_result.get(\"answer_loc\", {})\n",
    "                    if answer_loc.get(\"found\"):\n",
    "                        state.memory.promises.append({\n",
    "                            \"content\": best_danmaku.text,\n",
    "                            \"made_at_step\": state.current_step,\n",
    "                            \"fulfilled\": False,\n",
    "                            \"answer_at_line\": answer_loc.get(\"line_idx\")\n",
    "                        })\n",
    "        else:\n",
    "            # ç»§ç»­å½“å‰å°è¯\n",
    "            output = {\n",
    "                \"speech\": current_line.text,\n",
    "                \"action\": \"continue\",\n",
    "                \"priority\": 0.0,\n",
    "                \"cost\": current_line.interruption_cost\n",
    "            }\n",
    "        \n",
    "        # æ›´æ–°å‰§æœ¬è¿›åº¦\n",
    "        state.current_line_idx += 1\n",
    "        state.current_step += 1\n",
    "        \n",
    "        # æ›´æ–°è®°å¿†ï¼šè®°å½•å·²æåˆ°çš„ä¿¡æ¯\n",
    "        for info in current_line.key_info:\n",
    "            if info not in state.memory.story_points[\"mentioned\"]:\n",
    "                state.memory.story_points[\"mentioned\"].append(info)\n",
    "        \n",
    "        # æ›´æ–°å‰§æœ¬è¿›åº¦è®°å¿†\n",
    "        state.memory.script_progress[\"current_line\"] = state.current_line_idx\n",
    "        state.memory.script_progress[\"total_lines\"] = len(state.script_lines)\n",
    "        state.memory.script_progress[\"current_stage\"] = current_line.stage\n",
    "        \n",
    "        # æ£€æŸ¥æ‰¿è¯ºæ˜¯å¦å…‘ç°\n",
    "        self._check_promises(current_line, state)\n",
    "        \n",
    "        # ç”Ÿæˆè¯­éŸ³\n",
    "        speech = output.get(\"speech\", \"\")\n",
    "        audio = None\n",
    "        if speech and self.tts.enabled:\n",
    "            audio = self.tts.synthesize(speech)\n",
    "        \n",
    "        output[\"audio\"] = audio\n",
    "        output[\"line_idx\"] = state.current_line_idx - 1\n",
    "        output[\"stage\"] = current_line.stage\n",
    "        output[\"step\"] = state.current_step\n",
    "        output[\"memory_display\"] = state.memory.to_display()\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def _handle_danmaku_response(self, danmaku: Danmaku, handle_result: Dict,\n",
    "                                  current_line: ScriptLine, state: PerformanceState) -> Dict:\n",
    "        \"\"\"å¤„ç†å¼¹å¹•å›åº”\"\"\"\n",
    "        \n",
    "        echo = handle_result.get(\"echo\", \"\")\n",
    "        action = handle_result.get(\"action\", \"continue\")\n",
    "        answer_loc = handle_result.get(\"answer_loc\", {})\n",
    "        \n",
    "        # ç”Ÿæˆå›åº”å†…å®¹\n",
    "        response_part = \"\"\n",
    "        \n",
    "        if action == \"improvise\":\n",
    "            # å³å…´å›ç­”ï¼ˆå‰§æœ¬é‡Œæ²¡æœ‰ï¼‰\n",
    "            response_part = \"å“ˆå“ˆè¿™ä¸ªé—®é¢˜é—®å¾—å¥½ï¼è™½ç„¶ä¸åœ¨ä»Šå¤©çš„è¯é¢˜é‡Œï¼Œä½†è®©æˆ‘æƒ³æƒ³...\"\n",
    "        elif action == \"jump\":\n",
    "            # è·³è·ƒåˆ°ç­”æ¡ˆï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰\n",
    "            response_part = f\"æ—¢ç„¶ä½ é—®äº†ï¼Œæˆ‘ç›´æ¥å‘Šè¯‰ä½ ï¼\"\n",
    "            # TODO: å¯ä»¥è€ƒè™‘è·³è·ƒåˆ°ç­”æ¡ˆè¡Œ\n",
    "        elif action == \"tease\":\n",
    "            # åŠèƒƒå£\n",
    "            distance = answer_loc.get(\"distance\", 0)\n",
    "            if distance <= 2:\n",
    "                response_part = \"è¯¶ä½ åˆ«æ€¥ï¼Œé©¬ä¸Šå°±è¦è¯´åˆ°äº†~\"\n",
    "            else:\n",
    "                response_part = \"è¿™ä¸ªé—®é¢˜å¤ªå¥½äº†ï¼å…ˆå–ä¸ªå…³å­ï¼Œä½ ä»¬ç»§ç»­å¬å°±çŸ¥é“äº†ï¼Œç»å¯¹å‡ºä¹æ„æ–™~\"\n",
    "        else:  # continue\n",
    "            response_part = \"è¯´å¾—å¯¹ï¼\"\n",
    "        \n",
    "        # æ‰¿æ¥å›å‰§æœ¬\n",
    "        transition = self._generate_transition(current_line)\n",
    "        \n",
    "        speech = f\"{echo}{response_part} {transition}{current_line.text}\"\n",
    "        \n",
    "        return {\n",
    "            \"speech\": speech,\n",
    "            \"action\": action,\n",
    "            \"danmaku\": danmaku.text,\n",
    "            \"priority\": handle_result.get(\"priority\", 0),\n",
    "            \"cost\": handle_result.get(\"cost\", 0),\n",
    "            \"relevance\": handle_result.get(\"relevance\", 0)\n",
    "        }\n",
    "    \n",
    "    def _generate_transition(self, next_line: ScriptLine) -> str:\n",
    "        \"\"\"ç”Ÿæˆæ‰¿æ¥è¯­\"\"\"\n",
    "        transitions = [\n",
    "            \"å¥½ï¼Œé‚£åˆšæ‰è¯´åˆ°ï¼Œ\",\n",
    "            \"å›åˆ°æˆ‘ä»¬çš„æ•…äº‹ï¼Œ\",\n",
    "            \"ç»§ç»­è¯´ï¼Œ\",\n",
    "            \"å¯¹äº†ï¼Œ\",\n",
    "            \"\"  # æœ‰æ—¶å€™ä¸éœ€è¦è¿‡æ¸¡\n",
    "        ]\n",
    "        import random\n",
    "        return random.choice(transitions)\n",
    "    \n",
    "    def _check_promises(self, current_line: ScriptLine, state: PerformanceState):\n",
    "        \"\"\"æ£€æŸ¥å½“å‰å°è¯æ˜¯å¦å…‘ç°äº†æ‰¿è¯º\"\"\"\n",
    "        for promise in state.memory.promises:\n",
    "            if promise.get(\"fulfilled\", False):\n",
    "                continue\n",
    "            \n",
    "            # æ£€æŸ¥å½“å‰è¡Œæ˜¯ä¸æ˜¯ç­”æ¡ˆè¡Œ\n",
    "            if promise.get(\"answer_at_line\") == state.current_line_idx - 1:\n",
    "                promise[\"fulfilled\"] = True\n",
    "                # å¯ä»¥åœ¨å°è¯ä¸­åŠ å…¥æé†’ï¼š\"è¯¶å¯¹äº†ï¼Œåˆšæ‰æœ‰äººé—®XXXï¼Œç­”æ¡ˆæ¥äº†ï¼\"\n",
    "    \n",
    "    def _generate_ending(self, state: PerformanceState) -> Dict:\n",
    "        \"\"\"ç”Ÿæˆç»“å°¾\"\"\"\n",
    "        speech = f\"å¥½å•¦ï¼Œä»Šå¤©å…³äº{state.topic}å°±èŠåˆ°è¿™é‡Œï¼Œè°¢è°¢å¤§å®¶ï¼\"\n",
    "        audio = self.tts.synthesize(speech) if self.tts.enabled else None\n",
    "        \n",
    "        return {\n",
    "            \"speech\": speech,\n",
    "            \"action\": \"end\",\n",
    "            \"step\": state.current_step,\n",
    "            \"audio\": audio,\n",
    "            \"memory_display\": state.memory.to_display()\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"âœ… è¡¨æ¼”å¼•æ“ V2 å·²å®šä¹‰ï¼ˆå¸¦è®°å¿†ç³»ç»Ÿå’Œç»Ÿä¸€å¼¹å¹•å¤„ç†ï¼‰\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.8: å®Œæ•´å¼•æ“ V2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EchuuEngineV2:\n",
    "    \"\"\"\n",
    "    echuu å¼•æ“ V2 - å®Œæ•´æµç¨‹\n",
    "    \n",
    "    Phase 1: é¢„ç”Ÿæˆå®Œæ•´å‰§æœ¬\n",
    "    Phase 2: å®æ—¶è¡¨æ¼” + è®°å¿†ç³»ç»Ÿ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm: LLMClient, tts: TTSClient, analyzer: PatternAnalyzer):\n",
    "        self.llm = llm\n",
    "        self.tts = tts\n",
    "        self.analyzer = analyzer\n",
    "        self.script_gen = ScriptGeneratorV2(llm, analyzer)\n",
    "        self.performer = PerformerV2(llm, tts, danmaku_handler)\n",
    "    \n",
    "    def create_performance(self, name: str, persona: str, background: str,\n",
    "                          topic: str, language: str = \"zh\") -> PerformanceState:\n",
    "        \"\"\"\n",
    "        Phase 1: åˆ›å»ºè¡¨æ¼”ï¼ˆé¢„ç”Ÿæˆå®Œæ•´å‰§æœ¬ï¼‰\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ğŸ¬ echuu v2 - é¢„ç”Ÿæˆå®Œæ•´å‰§æœ¬\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        print(f\"è§’è‰²: {name}\")\n",
    "        print(f\"è¯é¢˜: {topic}\\n\")\n",
    "        \n",
    "        print(\"â³ æ­£åœ¨ç”Ÿæˆ100ç§’å®Œæ•´å‰§æœ¬...\")\n",
    "        script_lines = self.script_gen.generate(name, persona, background, topic, language)\n",
    "        \n",
    "        # æ˜¾ç¤ºå‰§æœ¬\n",
    "        print(f\"\\nğŸ“– ç”Ÿæˆçš„å‰§æœ¬ï¼š\")\n",
    "        print(f\"{'='*60}\")\n",
    "        for i, line in enumerate(script_lines):\n",
    "            cost_bar = \"â–ˆ\" * int(line.interruption_cost * 5) + \"â–‘\" * (5 - int(line.interruption_cost * 5))\n",
    "            print(f\"\\n[{i}] {line.stage} {cost_bar} cost={line.interruption_cost:.1f}\")\n",
    "            print(f\"    {line.text[:80]}{'...' if len(line.text) > 80 else ''}\")\n",
    "            print(f\"    ğŸ”‘ key_info: {', '.join(line.key_info)}\")\n",
    "        print(f\"\\n{'='*60}\\n\")\n",
    "        \n",
    "        # æå–å£ç™–\n",
    "        catchphrases = [cp for cp, _ in self.analyzer.extract_catchphrases(language)[:5]]\n",
    "        \n",
    "        # åˆå§‹åŒ–è®°å¿†\n",
    "        memory = PerformerMemory()\n",
    "        memory.script_progress[\"total_lines\"] = len(script_lines)\n",
    "        memory.script_progress[\"current_stage\"] = script_lines[0].stage if script_lines else \"Unknown\"\n",
    "        \n",
    "        # æå–å³å°†è¦è¯´çš„å…³é”®ç‚¹\n",
    "        for line in script_lines:\n",
    "            memory.story_points[\"upcoming\"].extend(line.key_info)\n",
    "        \n",
    "        return PerformanceState(\n",
    "            name=name,\n",
    "            persona=persona,\n",
    "            background=background,\n",
    "            topic=topic,\n",
    "            script_lines=script_lines,\n",
    "            memory=memory,\n",
    "            catchphrases=catchphrases\n",
    "        )\n",
    "    \n",
    "    def run(self, state: PerformanceState, danmaku_sim: List[Dict] = None,\n",
    "            play_audio: bool = True) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Phase 2: è¿è¡Œè¡¨æ¼”ï¼ˆå®æ—¶æ¨¡å¼ï¼‰\n",
    "        \"\"\"\n",
    "        \n",
    "        results = []\n",
    "        danmaku_by_step = defaultdict(list)\n",
    "        \n",
    "        if danmaku_sim:\n",
    "            for d in danmaku_sim:\n",
    "                step = d.get(\"step\", 0)\n",
    "                danmaku_by_step[step].append(Danmaku.from_text(d.get(\"text\", \"\")))\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ğŸ­ å¼€å§‹å®æ—¶è¡¨æ¼”\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        for step in range(len(state.script_lines)):\n",
    "            # è·å–æ–°å¼¹å¹•\n",
    "            new_danmaku = danmaku_by_step.get(step, [])\n",
    "            \n",
    "            # æ‰§è¡Œä¸€æ­¥\n",
    "            result = self.performer.step(state, new_danmaku)\n",
    "            results.append(result)\n",
    "            \n",
    "            # æ˜¾ç¤º\n",
    "            step_num = result.get(\"step\", 0)\n",
    "            stage = result.get(\"stage\", \"?\")\n",
    "            action = result.get(\"action\", \"continue\")\n",
    "            speech = result.get(\"speech\", \"\")\n",
    "            \n",
    "            action_icons = {\n",
    "                \"continue\": \"ğŸ“–\",\n",
    "                \"tease\": \"ğŸ£\",\n",
    "                \"jump\": \"âš¡\",\n",
    "                \"improvise\": \"ğŸ²\",\n",
    "                \"end\": \"ğŸ­\"\n",
    "            }\n",
    "            icon = action_icons.get(action, \"ğŸ“–\")\n",
    "            \n",
    "            print(f\"[Step {step_num}] {stage} {icon} {action.upper()}\")\n",
    "            print(f\"  ğŸ“¢ {speech[:100]}{'...' if len(speech) > 100 else ''}\")\n",
    "            \n",
    "            if result.get(\"danmaku\"):\n",
    "                print(f\"  ğŸ’¬ å›åº”å¼¹å¹•: {result['danmaku']}\")\n",
    "                print(f\"  ğŸ“Š priority={result.get('priority', 0):.2f}, cost={result.get('cost', 0):.2f}, relevance={result.get('relevance', 0):.2f}\")\n",
    "            \n",
    "            # æ˜¾ç¤ºè®°å¿†ï¼ˆæ¯3æ­¥æ˜¾ç¤ºä¸€æ¬¡ï¼‰\n",
    "            if step_num % 3 == 0:\n",
    "                print(f\"\\n{result.get('memory_display', '')}\")\n",
    "            \n",
    "            # æ’­æ”¾éŸ³é¢‘\n",
    "            if play_audio and result.get('audio'):\n",
    "                print(f\"  ğŸ”Š æ’­æ”¾è¯­éŸ³...\")\n",
    "                display(Audio(result['audio'], autoplay=True))\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            if action == \"end\":\n",
    "                break\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"âœ… è¡¨æ¼”ç»“æŸï¼\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # æœ€ç»ˆè®°å¿†çŠ¶æ€\n",
    "        print(\"ğŸ§  æœ€ç»ˆè®°å¿†çŠ¶æ€ï¼š\")\n",
    "        print(state.memory.to_display())\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–å¼•æ“\n",
    "engine_v2 = EchuuEngineV2(llm, tts, analyzer)\n",
    "print(\"\\nâœ… echuu å¼•æ“ V2 åˆå§‹åŒ–å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: ğŸš€ æµ‹è¯• echuu V2ï¼ˆå®Œæ•´å‰§æœ¬+è®°å¿†ç³»ç»Ÿï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ç”¨ä¾‹ï¼šç»å…¸çš„å®¤å‹è…°æœæ•…äº‹\n",
    "\n",
    "test_case_v2 = {\n",
    "    \"name\": \"å…­èº\",\n",
    "    \"persona\": \"25å²ä¸»æ’­ï¼Œæ´»æ³¼è‡ªå˜²ï¼Œå–œæ¬¢åˆ†äº«ç”Ÿæ´»ç»å†ï¼Œå£ç™–ï¼šæˆ‘è§‰å¾—ã€å¯¹å§ã€å°±æ˜¯è¯´\",\n",
    "    \"background\": \"åšè¿‡å¾ˆå¤šå·¥ä½œï¼Œç°åœ¨æ˜¯å…¨èŒä¸»æ’­ï¼Œç•™å­¦æ—¥æœ¬å¤šå¹´\",\n",
    "    \"topic\": \"ç•™å­¦æ—¶å·åƒå®¤å‹è…°æœçš„æ•…äº‹\",\n",
    "    \"danmaku\": [\n",
    "        {\"step\": 1, \"text\": \"å“ˆå“ˆå“ˆ\"},\n",
    "        {\"step\": 2, \"text\": \"æˆ‘ä¹Ÿæœ‰ç±»ä¼¼ç»å†\"},\n",
    "        {\"step\": 4, \"text\": \"å®¤å‹çŸ¥é“å—ï¼Ÿ\"},  # é«˜ç›¸å…³é—®é¢˜\n",
    "        {\"step\": 6, \"text\": \"[SC Â¥50] åæ¥å®¤å‹ç”Ÿæ°”äº†å—\"},  # SC + é«˜ç›¸å…³\n",
    "        {\"step\": 8, \"text\": \"ç¬‘æ­»\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Phase 1: é¢„ç”Ÿæˆå®Œæ•´å‰§æœ¬\n",
    "state_v2 = engine_v2.create_performance(\n",
    "    name=test_case_v2[\"name\"],\n",
    "    persona=test_case_v2[\"persona\"],\n",
    "    background=test_case_v2[\"background\"],\n",
    "    topic=test_case_v2[\"topic\"],\n",
    "    language=\"zh\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: è¿è¡Œå®æ—¶è¡¨æ¼”ï¼ˆå¸¦å¼¹å¹•äº’åŠ¨ï¼‰\n",
    "\n",
    "results_v2 = engine_v2.run(\n",
    "    state_v2, \n",
    "    danmaku_sim=test_case_v2[\"danmaku\"],\n",
    "    play_audio=True  # è®¾ä¸º False å¯ä»¥ç¦ç”¨è‡ªåŠ¨æ’­æ”¾\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š V2 ç‰ˆæœ¬æ ¸å¿ƒæ”¹è¿›\n",
    "\n",
    "### é—®é¢˜è§£å†³å¯¹æ¯”\n",
    "\n",
    "| é—®é¢˜ | V1ï¼ˆæ—§ç‰ˆï¼‰ | V2ï¼ˆæ–°ç‰ˆï¼‰ |\n",
    "|------|-----------|-----------|\n",
    "| **è½¦è½±è¾˜è¯** | å®æ—¶ç”Ÿæˆï¼Œå®¹æ˜“é‡å¤ | âœ… é¢„ç”Ÿæˆå®Œæ•´å‰§æœ¬ï¼Œæ¯å¥æ¨è¿›æ–°ä¿¡æ¯ |\n",
    "| **å™äº‹å»¶å±•æ€§** | èŠ‚ç‚¹éª¨æ¶ï¼Œå†…å®¹æ¨¡ç³Š | âœ… 10-15å¥å®Œæ•´å°è¯ï¼Œæœ‰èµ·æ‰¿è½¬åˆ |\n",
    "| **å¼¹å¹•æ‰¿æ¥** | ç®€å• urgency åˆ¤æ–­ | âœ… ä¼˜å…ˆçº§å…¬å¼ï¼ˆç›¸å…³æ€§ä¸ºç‹ï¼‰ |\n",
    "| **é—®é¢˜åŒ¹é…** | æ— æ³•å®šä½ç­”æ¡ˆ | âœ… key_info åŒ¹é…ç­”æ¡ˆä½ç½® |\n",
    "| **æ‰¿è¯ºè¿½è¸ª** | è¯´äº†\"ç­‰ä¼š\"å°±å¿˜äº† | âœ… è®°å¿†ç³»ç»Ÿè¿½è¸ªå¹¶å…‘ç°æ‰¿è¯º |\n",
    "| **é‡å¤å›ç­”** | ä¸çŸ¥é“è¯´è¿‡ä»€ä¹ˆ | âœ… è®°å¿†è®°å½•å·²æåˆ°ä¿¡æ¯ |\n",
    "\n",
    "### æ ¸å¿ƒåˆ›æ–°\n",
    "\n",
    "1. **å®Œæ•´å‰§æœ¬é¢„ç”Ÿæˆ**\n",
    "   - 100ç§’å®Œæ•´æ•…äº‹ï¼Œé¿å…è½¦è½±è¾˜è¯\n",
    "   - æ¯å¥å¸¦ `key_info` æ ‡æ³¨å…³é”®ä¿¡æ¯\n",
    "\n",
    "2. **ç»Ÿä¸€å¼¹å¹•å¤„ç†**\n",
    "   ```\n",
    "   priority = base + relevance_bonus + sc_bonus\n",
    "   ```\n",
    "   - é«˜ç›¸å…³é—®é¢˜ (0.7) > ä½ç›¸å…³SCÂ¥50 (0.4)\n",
    "   - ç›¸å…³æ€§æ˜¯æœ€é‡è¦å› ç´ \n",
    "\n",
    "3. **è®°å¿†ç³»ç»Ÿ**\n",
    "   - ğŸ“– å‰§æœ¬è¿›åº¦\n",
    "   - ğŸ’¬ å¼¹å¹•è®°å¿†ï¼ˆå·²å›åº”/å¾…å›ç­”ï¼‰\n",
    "   - ğŸ¤ æ‰¿è¯ºè¿½è¸ª\n",
    "   - ğŸ­ æ•…äº‹è¦ç‚¹ï¼ˆå·²æåˆ°/å³å°†æ­æ™“ï¼‰\n",
    "\n",
    "4. **ç­”æ¡ˆæŸ¥æ‰¾æœºåˆ¶**\n",
    "   - åœ¨ `key_info` ä¸­åŒ¹é…é—®é¢˜å…³é”®è¯\n",
    "   - æ ¹æ®è·ç¦»å†³å®šç­–ç•¥ï¼š\n",
    "     - 1-3å¥å â†’ è·³è·ƒï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰\n",
    "     - 4+å¥å â†’ åŠèƒƒå£ + æ‰¿è¯º\n",
    "     - å·²è¯´è¿‡ â†’ æé†’è§‚ä¼—\n",
    "\n",
    "### ä¼˜å…ˆçº§çŸ©é˜µç¤ºä¾‹\n",
    "\n",
    "**åœºæ™¯**: æ­£åœ¨è®² \"å®¤å‹æ˜¯å¯ŒäºŒä»£ï¼Œé›¶é£Ÿå¾ˆå¤š\"ï¼ˆBuild-up, cost=0.5ï¼‰\n",
    "\n",
    "| å¼¹å¹• | base | relevance | SC | priority | ç»“æœ |\n",
    "|------|------|-----------|----|---------| -----|\n",
    "| \"å“ˆå“ˆå“ˆ\" | 0.15 | 0.0 | 0.0 | 0.15 | âŒ ä¸æ‰“æ–­(0.15 < 0.5) |\n",
    "| \"å®¤å‹çŸ¥é“å—\" | 0.3 | 0.4 (é«˜ç›¸å…³) | 0.0 | **0.7** | âœ… æ‰“æ–­ï¼æŸ¥æ‰¾ç­”æ¡ˆ |\n",
    "| \"[SCÂ¥50] å®¤å‹ç”Ÿæ°”å—\" | 0.3 | 0.4 | 0.3 | **0.9** | âœ… æ‰“æ–­ï¼åŠèƒƒå£+æ‰¿è¯º |\n",
    "| \"ä¸»æ’­å¤šå¤§\" | 0.3 | 0.0 | 0.0 | 0.3 | âŒ ä¸æ‰“æ–­(ä½ç›¸å…³) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ è‡ªå®šä¹‰æµ‹è¯•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¨ è‡ªå®šä¹‰ä½ çš„è§’è‰²å’Œè¯é¢˜ï¼\n",
    "\n",
    "my_test = {\n",
    "    \"name\": \"å°æ¢…\",  # ğŸ‘ˆ ä¿®æ”¹åå­—\n",
    "    \"persona\": \"æ¸©æŸ”çš„çŒ«å¨˜ä¸»æ’­ï¼Œè¯´è¯å¸¦å–µ~ï¼Œå–œæ¬¢åˆ†äº«æ¸©æš–çš„æ•…äº‹\",  # ğŸ‘ˆ ä¿®æ”¹äººè®¾\n",
    "    \"background\": \"å¤§å­¦æ¯•ä¸šï¼Œç°åœ¨æ˜¯å…¨èŒä¸»æ’­\",  # ğŸ‘ˆ ä¿®æ”¹èƒŒæ™¯\n",
    "    \"topic\": \"ç¬¬ä¸€æ¬¡å…»çŒ«çš„ç»å†\",  # ğŸ‘ˆ ä¿®æ”¹è¯é¢˜\n",
    "    \"danmaku\": [\n",
    "        {\"step\": 1, \"text\": \"å¥½å¯çˆ±~\"},\n",
    "        {\"step\": 3, \"text\": \"çŒ«å’ªå«ä»€ä¹ˆåå­—ï¼Ÿ\"},  # é«˜ç›¸å…³é—®é¢˜\n",
    "        {\"step\": 5, \"text\": \"[SC Â¥100] çŒ«å’ªç°åœ¨å¤šå¤§äº†\"},  # å¤§é¢SC\n",
    "        {\"step\": 7, \"text\": \"æˆ‘ä¹Ÿæƒ³å…»çŒ«\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Phase 1: ç”Ÿæˆå‰§æœ¬\n",
    "my_state = engine_v2.create_performance(\n",
    "    name=my_test[\"name\"],\n",
    "    persona=my_test[\"persona\"],\n",
    "    background=my_test[\"background\"],\n",
    "    topic=my_test[\"topic\"],\n",
    "    language=\"zh\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: è¿è¡Œè¡¨æ¼”\n",
    "my_results = engine_v2.run(\n",
    "    my_state,\n",
    "    danmaku_sim=my_test[\"danmaku\"],\n",
    "    play_audio=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š ä½¿ç”¨æŒ‡å—\n",
    "\n",
    "### å¿«é€Ÿå¼€å§‹\n",
    "\n",
    "```python\n",
    "# 1. åˆ›å»ºè¡¨æ¼”ï¼ˆé¢„ç”Ÿæˆå‰§æœ¬ï¼‰\n",
    "state = engine_v2.create_performance(\n",
    "    name=\"è§’è‰²å\",\n",
    "    persona=\"äººè®¾æè¿°\",\n",
    "    background=\"èƒŒæ™¯\",\n",
    "    topic=\"è¯é¢˜\",\n",
    "    language=\"zh\"\n",
    ")\n",
    "\n",
    "# 2. è¿è¡Œè¡¨æ¼”ï¼ˆå¸¦å¼¹å¹•ï¼‰\n",
    "results = engine_v2.run(\n",
    "    state,\n",
    "    danmaku_sim=[\n",
    "        {\"step\": 1, \"text\": \"å¼¹å¹•å†…å®¹\"},\n",
    "        {\"step\": 3, \"text\": \"[SC Â¥50] é—®é¢˜\"},\n",
    "    ],\n",
    "    play_audio=True\n",
    ")\n",
    "```\n",
    "\n",
    "### æ ¸å¿ƒæœºåˆ¶\n",
    "\n",
    "#### 1. ä¼˜å…ˆçº§å…¬å¼\n",
    "```python\n",
    "priority = base_score + relevance_bonus + sc_bonus\n",
    "\n",
    "# base_score\n",
    "é—®é¢˜ç±»: 0.3\n",
    "æƒ…ç»ªåé¦ˆ: 0.15\n",
    "æ™®é€šè¯„è®º: 0.1\n",
    "\n",
    "# relevance_bonusï¼ˆæœ€é‡è¦ï¼ï¼‰\n",
    "é«˜ç›¸å…³ (0.7+): +0.4\n",
    "ä¸­ç›¸å…³ (0.4-0.7): +0.2\n",
    "ä½ç›¸å…³ (0.0-0.4): +0.0\n",
    "\n",
    "# sc_bonus\n",
    "Â¥200+: +0.7\n",
    "Â¥100+: +0.5\n",
    "Â¥50+: +0.3\n",
    "å…¶ä»–: +0.2\n",
    "```\n",
    "\n",
    "#### 2. å†³ç­–è§„åˆ™\n",
    "```python\n",
    "if priority > current_line.interruption_cost:\n",
    "    # æ‰“æ–­ï¼å›åº”å¼¹å¹•\n",
    "    if é—®é¢˜ç­”æ¡ˆåœ¨å‰§æœ¬ä¸­:\n",
    "        if è·ç¦» <= 3å¥:\n",
    "            action = \"jump\"  # è·³è·ƒï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰\n",
    "        else:\n",
    "            action = \"tease\"  # åŠèƒƒå£ + è®°å½•æ‰¿è¯º\n",
    "    else:\n",
    "        action = \"improvise\"  # å³å…´å›ç­”\n",
    "else:\n",
    "    # ç»§ç»­å½“å‰å°è¯\n",
    "    action = \"continue\"\n",
    "```\n",
    "\n",
    "#### 3. è®°å¿†æ›´æ–°æ—¶æœº\n",
    "- âœ… è¯´å®Œæ¯å¥å°è¯ â†’ è®°å½• `key_info` åˆ° `story_points.mentioned`\n",
    "- âœ… å›åº”å¼¹å¹• â†’ è®°å½•åˆ° `danmaku_memory.responded`\n",
    "- âœ… åŠèƒƒå£ â†’ è®°å½•æ‰¿è¯ºåˆ° `promises`\n",
    "- âœ… åˆ°è¾¾ç­”æ¡ˆè¡Œ â†’ æ ‡è®°æ‰¿è¯ºä¸º `fulfilled`\n",
    "\n",
    "### å…³é”®ç‰¹æ€§\n",
    "\n",
    "| ç‰¹æ€§ | è¯´æ˜ | è§£å†³çš„é—®é¢˜ |\n",
    "|------|------|-----------|\n",
    "| ğŸ¬ **å®Œæ•´å‰§æœ¬é¢„ç”Ÿæˆ** | 10-15å¥å®Œæ•´å°è¯ | è½¦è½±è¾˜è¯ã€å™äº‹ä¸å»¶å±• |\n",
    "| ğŸ”‘ **key_info æ ‡æ³¨** | æ¯å¥æ ‡æ³¨å…³é”®ä¿¡æ¯ | æ— æ³•åŒ¹é…é—®é¢˜å’Œç­”æ¡ˆ |\n",
    "| ğŸ§  **è®°å¿†ç³»ç»Ÿ** | è¿½è¸ªå·²è¯´å†…å®¹ã€å¼¹å¹•ã€æ‰¿è¯º | é‡å¤ã€é—å¿˜æ‰¿è¯º |\n",
    "| âš¡ **ç›¸å…³æ€§ä¸ºç‹** | é«˜ç›¸å…³ > ä½ç›¸å…³SC | å¼¹å¹•ä¸èƒ½å¼•å¯¼è¯é¢˜ |\n",
    "| ğŸ£ **åŠèƒƒå£+æ‰¿è¯º** | ç­”æ¡ˆè¿˜æ²¡è¯´å°±æ‰¿è¯ºç¨åæ­æ™“ | æ‰“æ–­å™äº‹èŠ‚å¥ |\n",
    "| ğŸ”Š **å®æ—¶è¯­éŸ³** | CosyVoice TTS | å®Œæ•´çš„ç›´æ’­ä½“éªŒ |\n",
    "\n",
    "### è°ƒè¯•æŠ€å·§\n",
    "\n",
    "```python\n",
    "# æŸ¥çœ‹ç”Ÿæˆçš„å‰§æœ¬\n",
    "for i, line in enumerate(state.script_lines):\n",
    "    print(f\"[{i}] {line.text}\")\n",
    "    print(f\"    key_info: {line.key_info}\")\n",
    "\n",
    "# æŸ¥çœ‹è®°å¿†çŠ¶æ€\n",
    "print(state.memory.to_display())\n",
    "\n",
    "# æŸ¥çœ‹å¼¹å¹•ä¼˜å…ˆçº§\n",
    "danmaku = Danmaku.from_text(\"å®¤å‹ç”Ÿæ°”äº†å—ï¼Ÿ\")\n",
    "evaluated = evaluator.evaluate(danmaku, state)\n",
    "print(f\"priority={evaluated.priority}, relevance={evaluated.relevance}\")\n",
    "```\n",
    "\n",
    "### éŸ³è‰²åˆ‡æ¢\n",
    "\n",
    "```python\n",
    "# åˆ‡æ¢éŸ³è‰²\n",
    "tts.change_voice(\"longyingjing_v3\")  # æ¸©æŸ”å¥³å£°\n",
    "tts.change_voice(\"longxiaochun_v2\")  # æ´»æ³¼å¥³å£°\n",
    "tts.change_voice(\"longanyang\")       # è‡ªç„¶ç”·å£°\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ä¸‹ä¸€æ­¥ä¼˜åŒ–æ–¹å‘\n",
    "\n",
    "1. **LLM è¾…åŠ©å›åº”ç”Ÿæˆ**ï¼šç›®å‰å›åº”æ˜¯æ¨¡æ¿åŒ–çš„ï¼Œå¯ä»¥è®© LLM æ ¹æ®äººè®¾ç”Ÿæˆæ›´è‡ªç„¶çš„å›åº”\n",
    "2. **è·³è·ƒå®ç°**ï¼šé«˜ä¼˜å…ˆçº§å¼¹å¹•å¯ä»¥çœŸæ­£è·³è·ƒåˆ°ç­”æ¡ˆè¡Œ\n",
    "3. **æ‰¿è¯ºå…‘ç°æé†’**ï¼šåˆ°è¾¾ç­”æ¡ˆè¡Œæ—¶ä¸»åŠ¨æé†’\"åˆšæ‰æœ‰äººé—®...\"\n",
    "4. **æƒ…ç»ªè¿½è¸ª**ï¼šæ ¹æ®å‰§æœ¬å†…å®¹å’Œå¼¹å¹•è¿½è¸ªæƒ…ç»ªå˜åŒ–\n",
    "5. **WebSocket å®æ—¶å¼¹å¹•**ï¼šæ¥å…¥çœŸå®ç›´æ’­å¹³å°çš„å¼¹å¹•æµ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âš¡ å¿«é€Ÿè¿è¡Œæµç¨‹\n",
    "\n",
    "### ç¬¬ä¸€æ¬¡ä½¿ç”¨\n",
    "\n",
    "1. **è¿è¡Œæ‰€æœ‰ cellï¼ˆæŒ‰é¡ºåºï¼‰**ï¼š\n",
    "   - Part 1: ç¯å¢ƒå‡†å¤‡ âœ“\n",
    "   - Part 2: æ•°æ®ç»“æ„å®šä¹‰ âœ“\n",
    "   - Part 2.5-2.8: æ ¸å¿ƒç»„ä»¶ï¼ˆå¼¹å¹•å¤„ç†ã€å‰§æœ¬ç”Ÿæˆã€è¡¨æ¼”å¼•æ“ï¼‰âœ“\n",
    "   - Part 3-8: Pattern Analyzerã€TTSã€LLM åˆå§‹åŒ– âœ“\n",
    "   - Part 9: æµ‹è¯• V2 å¼•æ“ â† **ä»è¿™é‡Œå¼€å§‹**\n",
    "\n",
    "2. **æµ‹è¯•é¢„è®¾æ¡ˆä¾‹**ï¼ˆPart 9ï¼‰ï¼š\n",
    "   ```python\n",
    "   # è¿è¡Œ cell 15: ç”Ÿæˆå‰§æœ¬\n",
    "   state_v2 = engine_v2.create_performance(...)\n",
    "   \n",
    "   # è¿è¡Œ cell 16: å®æ—¶è¡¨æ¼”\n",
    "   results_v2 = engine_v2.run(state_v2, ...)\n",
    "   ```\n",
    "\n",
    "3. **è‡ªå®šä¹‰æµ‹è¯•**ï¼ˆPart 10ï¼‰ï¼š\n",
    "   ```python\n",
    "   # ä¿®æ”¹ my_test å­—å…¸ä¸­çš„å†…å®¹\n",
    "   # è¿è¡Œ cell 19: ç”Ÿæˆå‰§æœ¬\n",
    "   # è¿è¡Œ cell 20: å®æ—¶è¡¨æ¼”\n",
    "   ```\n",
    "\n",
    "### è°ƒæ•´å‚æ•°\n",
    "\n",
    "```python\n",
    "# ç¦ç”¨è‡ªåŠ¨æ’­æ”¾\n",
    "results = engine_v2.run(state, danmaku_sim=..., play_audio=False)\n",
    "\n",
    "# ä¿®æ”¹éŸ³è‰²\n",
    "tts.change_voice(\"longyingjing_v3\")\n",
    "\n",
    "# æŸ¥çœ‹å‰§æœ¬è¯¦æƒ…\n",
    "for i, line in enumerate(state.script_lines):\n",
    "    print(f\"[{i}] {line.stage}: {line.text}\")\n",
    "    print(f\"    key_info: {line.key_info}\\n\")\n",
    "```\n",
    "\n",
    "### æ ¸å¿ƒæ”¹è¿›éªŒè¯\n",
    "\n",
    "è¿è¡Œæµ‹è¯•åï¼Œæ³¨æ„è§‚å¯Ÿï¼š\n",
    "\n",
    "âœ… **è½¦è½±è¾˜è¯è§£å†³** â†’ æ¯å¥å°è¯æ¨è¿›æ–°ä¿¡æ¯ï¼Œæœ‰èµ·æ‰¿è½¬åˆ  \n",
    "âœ… **å¼¹å¹•æ‰¿æ¥** â†’ é«˜ç›¸å…³é—®é¢˜è¢«ä¼˜å…ˆå›åº”  \n",
    "âœ… **è®°å¿†å¯è§†åŒ–** â†’ æ¯3æ­¥æ˜¾ç¤ºè®°å¿†çŠ¶æ€  \n",
    "âœ… **æ‰¿è¯ºè¿½è¸ª** â†’ è¯´äº†\"ç­‰ä¼šå‘Šè¯‰ä½ \"ä¼šè¢«è®°å½•  \n",
    "âœ… **ç­”æ¡ˆæŸ¥æ‰¾** â†’ æ ¹æ® key_info åŒ¹é…é—®é¢˜å’Œç­”æ¡ˆä½ç½®\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Pattern Analyzer - ä»çœŸå®æ•°æ®å­¦ä¹ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternAnalyzer:\n",
    "    \"\"\"ä»æ ‡æ³¨æ•°æ®ä¸­æå–æ¨¡å¼\"\"\"\n",
    "    \n",
    "    def __init__(self, annotated_clips: List[Dict]):\n",
    "        self.clips = annotated_clips\n",
    "        self.all_segments = []\n",
    "        for clip in annotated_clips:\n",
    "            self.all_segments.extend(clip.get(\"segments\", []))\n",
    "    \n",
    "    def _normalize_field(self, value, default=\"self\"):\n",
    "        \"\"\"å¤„ç†å­—æ®µå€¼ï¼Œå¦‚æœæ˜¯åˆ—è¡¨åˆ™å–ç¬¬ä¸€ä¸ªå…ƒç´ \"\"\"\n",
    "        if isinstance(value, list):\n",
    "            return value[0] if value else default\n",
    "        return value if value else default\n",
    "    \n",
    "    def compute_attention_transitions(self) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"è®¡ç®—attentionè½¬ç§»æ¦‚ç‡\"\"\"\n",
    "        trans = defaultdict(lambda: defaultdict(int))\n",
    "        for clip in self.clips:\n",
    "            segs = clip.get(\"segments\", [])\n",
    "            for i in range(len(segs) - 1):\n",
    "                f = self._normalize_field(segs[i].get(\"attention_focus\"), \"self\")\n",
    "                t = self._normalize_field(segs[i+1].get(\"attention_focus\"), \"self\")\n",
    "                trans[f][t] += 1\n",
    "        \n",
    "        prob = {}\n",
    "        for f, tos in trans.items():\n",
    "            total = sum(tos.values())\n",
    "            prob[f] = {t: c/total for t, c in tos.items()}\n",
    "        return prob\n",
    "    \n",
    "    def infer_baseline_costs(self) -> Dict[str, float]:\n",
    "        \"\"\"æ¨æ–­ä¸åŒattentionä¸‹çš„æ‰“æ–­ä»£ä»·\"\"\"\n",
    "        focus_stats = defaultdict(lambda: {\"total\": 0, \"ignored\": 0})\n",
    "        \n",
    "        for seg in self.all_segments:\n",
    "            focus = self._normalize_field(seg.get(\"attention_focus\"), \"self\")\n",
    "            trigger = self._normalize_field(seg.get(\"trigger\"), \"self\")\n",
    "            act = self._normalize_field(seg.get(\"speech_act\"), \"narrate\")\n",
    "            \n",
    "            if trigger == \"danmaku\":\n",
    "                focus_stats[focus][\"total\"] += 1\n",
    "                if act != \"respond\":\n",
    "                    focus_stats[focus][\"ignored\"] += 1\n",
    "        \n",
    "        costs = {}\n",
    "        for focus, stats in focus_stats.items():\n",
    "            if stats[\"total\"] > 0:\n",
    "                costs[focus] = stats[\"ignored\"] / stats[\"total\"]\n",
    "            else:\n",
    "                costs[focus] = 0.5\n",
    "        return costs\n",
    "    \n",
    "    def extract_skeletons(self) -> List[Tuple[str, int]]:\n",
    "        \"\"\"æå–å™äº‹éª¨æ¶\"\"\"\n",
    "        skeletons = [c.get(\"skeleton\", \"\") for c in self.clips if c.get(\"skeleton\")]\n",
    "        return Counter(skeletons).most_common(10)\n",
    "    \n",
    "    def extract_catchphrases(self, language: str = None) -> List[Tuple[str, int]]:\n",
    "        \"\"\"æå–å£ç™–\"\"\"\n",
    "        cps = []\n",
    "        for c in self.clips:\n",
    "            if language and c.get(\"language\") != language:\n",
    "                continue\n",
    "            cps.extend(c.get(\"catchphrases\", []))\n",
    "        return Counter(cps).most_common(20)\n",
    "    \n",
    "    def extract_hooks(self, language: str = None) -> List[str]:\n",
    "        \"\"\"æå–å¼€åœºç¤ºä¾‹\"\"\"\n",
    "        hooks = []\n",
    "        for c in self.clips:\n",
    "            if language and c.get(\"language\") != language:\n",
    "                continue\n",
    "            segs = c.get(\"segments\", [])\n",
    "            if segs:\n",
    "                hooks.append(segs[0].get(\"text\", \"\")[:100])\n",
    "        return hooks[:10]\n",
    "    \n",
    "    def get_report(self) -> str:\n",
    "        \"\"\"ç”Ÿæˆåˆ†ææŠ¥å‘Š\"\"\"\n",
    "        lines = [\n",
    "            \"=\"*50,\n",
    "            \"ğŸ“Š Pattern Analysis Report\",\n",
    "            \"=\"*50,\n",
    "            f\"Total clips: {len(self.clips)}, Total segments: {len(self.all_segments)}\",\n",
    "        ]\n",
    "        \n",
    "        lines.append(\"\\n### Attention Transitions\")\n",
    "        for f, tos in self.compute_attention_transitions().items():\n",
    "            top = sorted(tos.items(), key=lambda x: -x[1])[:3]\n",
    "            lines.append(f\"- `{f}` â†’ \" + \", \".join(f\"`{t}`:{p:.0%}\" for t, p in top))\n",
    "        \n",
    "        lines.append(\"\\n### Inferred Interruption Costs\")\n",
    "        for focus, cost in self.infer_baseline_costs().items():\n",
    "            bar = \"â–ˆ\" * int(cost * 10) + \"â–‘\" * (10 - int(cost * 10))\n",
    "            lines.append(f\"- `{focus}`: {bar} {cost:.2f}\")\n",
    "        \n",
    "        lines.append(\"\\n### Top Catchphrases\")\n",
    "        cps = self.extract_catchphrases()[:10]\n",
    "        lines.append(\", \".join(f'\"{c}\"({n})' for c, n in cps))\n",
    "        \n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: åŠ è½½æ ‡æ³¨æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ ‡æ³¨æ•°æ®\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"annotated_clips.json\"\n",
    "\n",
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    annotated_clips = json.load(f)\n",
    "\n",
    "print(f\"âœ… åŠ è½½äº† {len(annotated_clips)} ä¸ªclips\")\n",
    "\n",
    "# åˆ›å»ºåˆ†æå™¨\n",
    "analyzer = PatternAnalyzer(annotated_clips)\n",
    "\n",
    "# æ˜¾ç¤ºæŠ¥å‘Š\n",
    "display(Markdown(analyzer.get_report()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹ç¤ºä¾‹æ•°æ®\n",
    "print(\"\\nğŸ“ å¼€åœº Hook ç¤ºä¾‹ (ä¸­æ–‡):\")\n",
    "for i, hook in enumerate(analyzer.extract_hooks(\"zh\")[:3], 1):\n",
    "    print(f\"  {i}. {hook[:60]}...\")\n",
    "\n",
    "print(\"\\nğŸ“ å™äº‹éª¨æ¶ç¤ºä¾‹:\")\n",
    "for skel, count in analyzer.extract_skeletons()[:5]:\n",
    "    print(f\"  [{count}æ¬¡] {skel[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: TTS Client - é€šä¹‰åƒé—®è¯­éŸ³åˆæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTSClient:\n",
    "    \"\"\"é€šä¹‰åƒé—® CosyVoice TTS å®¢æˆ·ç«¯\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.enabled = False\n",
    "        self.synthesizer_class = None\n",
    "        self.audio_format = None\n",
    "        \n",
    "        api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "        if api_key:\n",
    "            try:\n",
    "                import dashscope\n",
    "                from dashscope.audio.tts_v2 import SpeechSynthesizer, AudioFormat\n",
    "                \n",
    "                dashscope.api_key = api_key\n",
    "                self.synthesizer_class = SpeechSynthesizer\n",
    "                self.audio_format = AudioFormat.MP3_22050HZ_MONO_256KBPS\n",
    "                self.model = os.getenv(\"TTS_MODEL\", \"cosyvoice-v3-flash\")\n",
    "                self.voice = os.getenv(\"TTS_VOICE\", \"longanyang\")\n",
    "                self.enabled = True\n",
    "                print(f\"âœ… TTS å·²å¯ç”¨: model={self.model}, voice={self.voice}\")\n",
    "            except ImportError:\n",
    "                print(\"âš ï¸ dashscope æœªå®‰è£…\")\n",
    "        else:\n",
    "            print(\"âš ï¸ æœªè®¾ç½® DASHSCOPE_API_KEYï¼ŒTTS å·²ç¦ç”¨\")\n",
    "    \n",
    "    def synthesize(self, text: str) -> Optional[bytes]:\n",
    "        \"\"\"åˆæˆè¯­éŸ³ï¼Œè¿”å›éŸ³é¢‘æ•°æ®\"\"\"\n",
    "        if not self.enabled:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            synthesizer = self.synthesizer_class(\n",
    "                model=self.model,\n",
    "                voice=self.voice,\n",
    "                format=self.audio_format\n",
    "            )\n",
    "            return synthesizer.call(text)\n",
    "        except Exception as e:\n",
    "            print(f\"[TTS] é”™è¯¯: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def change_voice(self, voice: str):\n",
    "        \"\"\"åˆ‡æ¢éŸ³è‰²\"\"\"\n",
    "        self.voice = voice\n",
    "        print(f\"ğŸ”Š éŸ³è‰²å·²åˆ‡æ¢ä¸º: {voice}\")\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ– TTS\n",
    "tts = TTSClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯• TTS\n",
    "if tts.enabled:\n",
    "    print(\"ğŸ¤ æµ‹è¯• TTS...\")\n",
    "    test_audio = tts.synthesize(\"ä½ å¥½ï¼Œæˆ‘æ˜¯echuu AIä¸»æ’­ï¼Œä»Šå¤©æ¥ç»™å¤§å®¶è®²ä¸ªæœ‰è¶£çš„æ•…äº‹ï¼\")\n",
    "    if test_audio:\n",
    "        print(f\"âœ… ç”ŸæˆéŸ³é¢‘: {len(test_audio)} bytes\")\n",
    "        display(Audio(test_audio, autoplay=False))\n",
    "else:\n",
    "    print(\"âš ï¸ TTS æœªå¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: LLM Client - Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMClient:\n",
    "    \"\"\"Claude LLM å®¢æˆ·ç«¯\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = None\n",
    "        self.model = os.getenv(\"DEFAULT_MODEL\", \"claude-3-haiku-20240307\")\n",
    "        \n",
    "        api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "        if api_key:\n",
    "            try:\n",
    "                import anthropic\n",
    "                self.client = anthropic.Anthropic(api_key=api_key)\n",
    "                print(f\"âœ… LLM å·²åˆå§‹åŒ–: {self.model}\")\n",
    "            except ImportError:\n",
    "                print(\"âš ï¸ anthropic æœªå®‰è£…\")\n",
    "        else:\n",
    "            print(\"âš ï¸ æœªè®¾ç½® ANTHROPIC_API_KEYï¼Œä½¿ç”¨ Mock æ¨¡å¼\")\n",
    "    \n",
    "    def call(self, prompt: str, system: str = None, max_tokens: int = 1000) -> str:\n",
    "        \"\"\"è°ƒç”¨ LLM\"\"\"\n",
    "        if self.client:\n",
    "            try:\n",
    "                kwargs = {\n",
    "                    \"model\": self.model,\n",
    "                    \"max_tokens\": max_tokens,\n",
    "                    \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "                }\n",
    "                if system:\n",
    "                    kwargs[\"system\"] = system\n",
    "                \n",
    "                response = self.client.messages.create(**kwargs)\n",
    "                return response.content[0].text\n",
    "            except Exception as e:\n",
    "                print(f\"[LLM] é”™è¯¯: {e}\")\n",
    "        \n",
    "        return self._mock_response(prompt)\n",
    "    \n",
    "    def _mock_response(self, prompt: str) -> str:\n",
    "        \"\"\"Mock å“åº”\"\"\"\n",
    "        import random\n",
    "        \n",
    "        if \"JSONæ•°ç»„\" in prompt or \"script\" in prompt.lower():\n",
    "            return '''[\n",
    "{\"stage\": \"Hook\", \"goal\": \"ç”¨æ‚¬å¿µå¼€åœº\", \"attention\": \"audience\", \"speech_act\": \"elicit\", \"duration\": 20, \"cost\": 0.3, \"hint\": \"æé—®å¼€åœº\"},\n",
    "{\"stage\": \"Build-up\", \"goal\": \"é“ºå«èƒŒæ™¯\", \"attention\": \"self\", \"speech_act\": \"narrate\", \"duration\": 40, \"cost\": 0.6, \"hint\": \"æè¿°æƒ…å†µ\"},\n",
    "{\"stage\": \"Climax\", \"goal\": \"å…³é”®è½¬æŠ˜\", \"attention\": \"self\", \"speech_act\": \"narrate\", \"duration\": 40, \"cost\": 0.9, \"hint\": \"æƒ…æ„Ÿçˆ†å‘\"},\n",
    "{\"stage\": \"Resolution\", \"goal\": \"æ€»ç»“æ„Ÿæ‚Ÿ\", \"attention\": \"audience\", \"speech_act\": \"opine\", \"duration\": 20, \"cost\": 0.4, \"hint\": \"åˆ†äº«å¿ƒå¾—\"}\n",
    "]'''\n",
    "        else:\n",
    "            return json.dumps({\n",
    "                \"inner_monologue\": random.choice([\"è®©æˆ‘æƒ³æƒ³...\", \"æœ‰æ„æ€...\", \"ç»§ç»­...\", \"å—¯...\"]),\n",
    "                \"decision\": \"continue\",\n",
    "                \"speech\": random.choice([\"è¯´èµ·è¿™ä¸ªäº‹å„¿å•Š...\", \"ä½ ä»¬çŸ¥é“å—...\", \"æˆ‘è·Ÿä½ ä»¬è®²...\"]),\n",
    "                \"emotion\": \"neutral\"\n",
    "            }, ensure_ascii=False)\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ– LLM\n",
    "llm = LLMClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Script Generator - å‰§æœ¬ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScriptGenerator:\n",
    "    \"\"\"å‰§æœ¬ç”Ÿæˆå™¨\"\"\"\n",
    "    \n",
    "    SYSTEM_PROMPT = \"\"\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„VTuberå‰§æœ¬ç¼–å‰§ã€‚æ ¹æ®è§’è‰²è®¾å®šå’Œè¯é¢˜ï¼Œè®¾è®¡2åˆ†é’Ÿçš„è¡¨æ¼”å‰§æœ¬éª¨æ¶ã€‚\n",
    "\n",
    "å™äº‹ç»“æ„ï¼š\n",
    "- Hook: ç”¨é—®é¢˜/æ‚¬å¿µ/å…±é¸£ç‚¹å¼€åœº\n",
    "- Build-up: é“ºå«èƒŒæ™¯ã€ç§¯ç´¯æƒ…ç»ª\n",
    "- Climax: æƒ…æ„Ÿçˆ†å‘ç‚¹ã€å…³é”®ä¿¡æ¯\n",
    "- Resolution: æ€»ç»“å‡åã€å’Œè§‚ä¼—è¿æ¥\n",
    "\n",
    "interruption_costï¼ˆè¢«å¼¹å¹•æ‰“æ–­çš„ä»£ä»·ï¼‰ï¼š\n",
    "- 0.0-0.3: å¯ä»¥éšæ—¶æ‰“æ–­ï¼ˆé—²èŠã€å¼€åœºï¼‰\n",
    "- 0.4-0.6: æœ€å¥½ä¸æ‰“æ–­ï¼ˆé“ºå«é˜¶æ®µï¼‰\n",
    "- 0.7-0.9: å°½é‡ä¸æ‰“æ–­ï¼ˆé«˜æ½®é˜¶æ®µï¼‰\n",
    "- 0.9+: ç»å¯¹ä¸èƒ½æ‰“æ–­ï¼ˆæƒ…æ„Ÿçˆ†å‘ï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: LLMClient, analyzer: PatternAnalyzer = None):\n",
    "        self.llm = llm\n",
    "        self.analyzer = analyzer\n",
    "    \n",
    "    def generate(self, name: str, persona: str, background: str, \n",
    "                 topic: str, language: str = \"zh\") -> List[NarrativeNode]:\n",
    "        \"\"\"ç”Ÿæˆå‰§æœ¬\"\"\"\n",
    "        \n",
    "        # è·å–å‚è€ƒæ•°æ®\n",
    "        example_skeletons = \"\"\n",
    "        catchphrases = \"\"\n",
    "        \n",
    "        if self.analyzer:\n",
    "            skels = self.analyzer.extract_skeletons()[:3]\n",
    "            example_skeletons = \"\\n\".join(f\"- {s}\" for s, _ in skels)\n",
    "            \n",
    "            cps = self.analyzer.extract_catchphrases(language)[:5]\n",
    "            catchphrases = \", \".join(f'\"{c}\"' for c, _ in cps)\n",
    "        \n",
    "        prompt = f\"\"\"è¯·ä¸ºä»¥ä¸‹VTuberè®¾è®¡ä¸€ä¸ª2åˆ†é’Ÿçš„ç›´æ’­å‰§æœ¬éª¨æ¶ï¼š\n",
    "\n",
    "## è§’è‰²ä¿¡æ¯\n",
    "- åå­—: {name}\n",
    "- äººè®¾: {persona}\n",
    "- èƒŒæ™¯: {background}\n",
    "- ä»Šæ—¥è¯é¢˜: {topic}\n",
    "\n",
    "## å‚è€ƒå™äº‹éª¨æ¶\n",
    "{example_skeletons or \"ï¼ˆæ— ï¼‰\"}\n",
    "\n",
    "## å¯ç”¨å£ç™–\n",
    "{catchphrases or \"ï¼ˆæ— ï¼‰\"}\n",
    "\n",
    "## è¾“å‡ºè¦æ±‚\n",
    "è¾“å‡ºä¸€ä¸ªJSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š\n",
    "- stage: é˜¶æ®µ (Hook/Build-up/Climax/Resolution)\n",
    "- goal: ç›®æ ‡\n",
    "- attention: æ³¨æ„åŠ› (self/audience/specific)\n",
    "- speech_act: è¨€è¯­è¡Œä¸º (narrate/opine/respond/elicit)\n",
    "- duration: æ—¶é•¿ï¼ˆç§’ï¼‰\n",
    "- cost: æ‰“æ–­ä»£ä»· (0.0-1.0)\n",
    "- hint: å†…å®¹æç¤º\n",
    "\n",
    "è®¾è®¡4-6ä¸ªèŠ‚ç‚¹ï¼Œæ€»æ—¶é•¿çº¦120ç§’ã€‚åªè¾“å‡ºJSONã€‚\"\"\"\n",
    "        \n",
    "        response = self.llm.call(prompt, system=self.SYSTEM_PROMPT)\n",
    "        \n",
    "        try:\n",
    "            if \"```\" in response:\n",
    "                json_str = response.split(\"```\")[1]\n",
    "                if json_str.startswith(\"json\"):\n",
    "                    json_str = json_str[4:]\n",
    "            else:\n",
    "                json_str = response\n",
    "            \n",
    "            nodes_data = json.loads(json_str.strip())\n",
    "            \n",
    "            return [\n",
    "                NarrativeNode(\n",
    "                    stage=n.get(\"stage\", \"Unknown\"),\n",
    "                    goal=n.get(\"goal\", \"\"),\n",
    "                    target_attention=n.get(\"attention\", \"self\"),\n",
    "                    target_speech_act=n.get(\"speech_act\", \"narrate\"),\n",
    "                    duration_sec=n.get(\"duration\", 30),\n",
    "                    interruption_cost=n.get(\"cost\", 0.5),\n",
    "                    content_hint=n.get(\"hint\", \"\")\n",
    "                )\n",
    "                for n in nodes_data\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            print(f\"[Script] è§£æå¤±è´¥: {e}\")\n",
    "            return self._fallback_script(topic)\n",
    "    \n",
    "    def _fallback_script(self, topic: str) -> List[NarrativeNode]:\n",
    "        \"\"\"åå¤‡å‰§æœ¬\"\"\"\n",
    "        return [\n",
    "            NarrativeNode(\"Hook\", f\"å¼•å‡º{topic}\", \"audience\", \"elicit\", 20, 0.3),\n",
    "            NarrativeNode(\"Build-up\", \"é“ºå«èƒŒæ™¯\", \"self\", \"narrate\", 40, 0.6),\n",
    "            NarrativeNode(\"Climax\", \"æ ¸å¿ƒå†…å®¹\", \"self\", \"narrate\", 40, 0.9),\n",
    "            NarrativeNode(\"Resolution\", \"æ€»ç»“å‡å\", \"audience\", \"opine\", 20, 0.4),\n",
    "        ]\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–\n",
    "script_gen = ScriptGenerator(llm, analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Cognitive Performer - è®¤çŸ¥è¡¨æ¼”è€…ï¼ˆæ ¸å¿ƒï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CognitivePerformer:\n",
    "    \"\"\"è®¤çŸ¥è¡¨æ¼”è€… - å®æ—¶å†³ç­–å’Œç”Ÿæˆ\"\"\"\n",
    "    \n",
    "    SYSTEM_PROMPT = \"\"\"ä½ æ˜¯ä¸€ä¸ªVTuberçš„\"å†…å¿ƒ\"ã€‚æ¯ä¸ªæ—¶åˆ»éœ€è¦ï¼š\n",
    "1. æ„ŸçŸ¥å½“å‰çŠ¶æ€ï¼ˆå‰§æœ¬è¿›åº¦ã€å¼¹å¹•ã€æ—¶é—´ï¼‰\n",
    "2. åšå‡ºå†³ç­–ï¼ˆç»§ç»­å‰§æœ¬/å›åº”å¼¹å¹•/å³å…´/æ²‰é»˜ï¼‰\n",
    "3. è¾“å‡ºå†…å¿ƒç‹¬ç™½ï¼ˆè¿™ä¼šæ˜¾ç¤ºç»™è§‚ä¼—çœ‹ï¼Œæ˜¯æ ¸å¿ƒç‰¹è‰²ï¼‰\n",
    "4. ç”Ÿæˆå°è¯\n",
    "\n",
    "å…³é”®ï¼šå†…å¿ƒç‹¬ç™½è¦å±•ç¤ºä½ çš„\"æ€è€ƒè¿‡ç¨‹\"ï¼Œè®©è§‚ä¼—æ„Ÿå—åˆ°AIçš„agencyã€‚\n",
    "- ä¸æ˜¯å‡è£…åƒäººï¼Œè€Œæ˜¯è®©è§‚ä¼—çœ‹åˆ°ä½ åœ¨\"æ€è€ƒ\"å’Œ\"é€‰æ‹©\"\n",
    "- \"é€‰æ‹©ä¸å›åº”\"ä¹Ÿæ˜¯ä¸€ç§è¡¨è¾¾\n",
    "- å†…å¿ƒç‹¬ç™½è¦ç®€çŸ­ã€çœŸå®ã€æœ‰personality\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: LLMClient, tts: TTSClient, analyzer: PatternAnalyzer = None):\n",
    "        self.llm = llm\n",
    "        self.tts = tts\n",
    "        self.analyzer = analyzer\n",
    "    \n",
    "    def step(self, state: PerformanceState, new_danmaku: List[Danmaku] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        æ‰§è¡Œä¸€æ¬¡è®¤çŸ¥å¾ªç¯\n",
    "        \n",
    "        æ ¸å¿ƒå…¬å¼: decision_value = urgency - cost\n",
    "        - æ­£æ•° â†’ å€¾å‘å›åº”å¼¹å¹•\n",
    "        - è´Ÿæ•° â†’ å€¾å‘ç»§ç»­å‰§æœ¬\n",
    "        \"\"\"\n",
    "        \n",
    "        if new_danmaku:\n",
    "            state.danmaku_queue.extend(new_danmaku)\n",
    "        \n",
    "        # æ£€æŸ¥ç»“æŸ\n",
    "        if state.current_node_idx >= len(state.script):\n",
    "            return self._generate_ending(state)\n",
    "        \n",
    "        current_node = state.script[state.current_node_idx]\n",
    "        elapsed_ratio = state.node_elapsed_sec / current_node.duration_sec if current_node.duration_sec > 0 else 1.0\n",
    "        current_cost = current_node.get_current_cost(elapsed_ratio)\n",
    "        \n",
    "        # è¯„ä¼°å¼¹å¹•\n",
    "        max_urgency = 0.0\n",
    "        most_urgent = None\n",
    "        for d in state.danmaku_queue:\n",
    "            if d.urgency > max_urgency:\n",
    "                max_urgency = d.urgency\n",
    "                most_urgent = d\n",
    "        \n",
    "        # æ„å»º prompt\n",
    "        recent_danmaku = [d.text for d in state.danmaku_queue[-5:]]\n",
    "        catchphrases_hint = \", \".join(state.catchphrases[:3]) if state.catchphrases else \"æ— \"\n",
    "        \n",
    "        prompt = f\"\"\"## å½“å‰çŠ¶æ€\n",
    "\n",
    "### è§’è‰²\n",
    "åå­—: {state.name}\n",
    "äººè®¾: {state.persona}\n",
    "å£ç™–å‚è€ƒ: {catchphrases_hint}\n",
    "\n",
    "### å‰§æœ¬è¿›åº¦\n",
    "å½“å‰é˜¶æ®µ: {current_node.stage}\n",
    "é˜¶æ®µç›®æ ‡: {current_node.goal}\n",
    "é˜¶æ®µè¿›åº¦: {elapsed_ratio:.0%}\n",
    "å†…å®¹æç¤º: {current_node.content_hint}\n",
    "è¯é¢˜: {state.topic}\n",
    "\n",
    "### å™äº‹ä»£ä»·\n",
    "å½“å‰cost: {current_cost:.2f} (0=éšæ„æ‰“æ–­, 1=ç»å¯¹ä¸èƒ½æ‰“æ–­)\n",
    "\n",
    "### å¼¹å¹•æƒ…å†µ\n",
    "æœ€è¿‘å¼¹å¹•: {recent_danmaku or \"ï¼ˆæ— ï¼‰\"}\n",
    "æœ€é«˜ç´§æ€¥åº¦: {max_urgency:.2f}\n",
    "è¿ç»­å¿½ç•¥æ•°: {state.ignored_count}\n",
    "\n",
    "### å†³ç­–å‚è€ƒ\n",
    "urgency - cost = {max_urgency - current_cost:.2f}\n",
    "æ­£æ•°å€¾å‘å›åº”ï¼Œè´Ÿæ•°å€¾å‘ç»§ç»­\n",
    "è¿ç»­å¿½ç•¥3æ¡ä»¥ä¸Šåº”è€ƒè™‘è¡¥æ•‘\n",
    "\n",
    "## è¾“å‡º\n",
    "è¾“å‡ºJSON: {{\"inner_monologue\": \"...\", \"decision\": \"continue/respond\", \"speech\": \"...\", \"emotion\": \"...\"}}\n",
    "- inner_monologue: å†…å¿ƒç‹¬ç™½ï¼ˆä¼šæ˜¾ç¤ºç»™è§‚ä¼—ï¼‰\n",
    "- speech: å°è¯ï¼ˆä¼šè½¬æˆè¯­éŸ³ï¼‰\n",
    "- emotion: æƒ…ç»ª (neutral/excited/sad/focused/engaged)\n",
    "\n",
    "åªè¾“å‡ºJSONã€‚\"\"\"\n",
    "        \n",
    "        response = self.llm.call(prompt, system=self.SYSTEM_PROMPT, max_tokens=500)\n",
    "        \n",
    "        # è§£æ\n",
    "        try:\n",
    "            if \"```\" in response:\n",
    "                json_str = response.split(\"```\")[1]\n",
    "                if json_str.startswith(\"json\"):\n",
    "                    json_str = json_str[4:]\n",
    "            else:\n",
    "                json_str = response\n",
    "            result = json.loads(json_str.strip())\n",
    "        except:\n",
    "            result = {\n",
    "                \"inner_monologue\": f\"ç»§ç»­è®²{current_node.stage}...\",\n",
    "                \"decision\": \"continue\",\n",
    "                \"speech\": f\"è¯´åˆ°{state.topic}...\",\n",
    "                \"emotion\": \"neutral\"\n",
    "            }\n",
    "        \n",
    "        # æ›´æ–°çŠ¶æ€\n",
    "        decision = result.get(\"decision\", \"continue\")\n",
    "        step_duration = 10\n",
    "        state.node_elapsed_sec += step_duration\n",
    "        state.total_elapsed_sec += step_duration\n",
    "        \n",
    "        if state.node_elapsed_sec >= current_node.duration_sec:\n",
    "            state.current_node_idx += 1\n",
    "            state.node_elapsed_sec = 0\n",
    "        \n",
    "        if decision == \"respond\" and most_urgent:\n",
    "            state.danmaku_queue = [d for d in state.danmaku_queue if d != most_urgent]\n",
    "            state.ignored_count = 0\n",
    "            result[\"target_danmaku\"] = most_urgent.text\n",
    "        elif decision == \"continue\" and state.danmaku_queue:\n",
    "            state.ignored_count += 1\n",
    "        \n",
    "        # ç”Ÿæˆè¯­éŸ³\n",
    "        speech = result.get(\"speech\", \"\")\n",
    "        audio = None\n",
    "        if speech and self.tts.enabled:\n",
    "            audio = self.tts.synthesize(speech)\n",
    "        \n",
    "        result[\"audio\"] = audio\n",
    "        result[\"node\"] = current_node.stage\n",
    "        result[\"time\"] = f\"{state.total_elapsed_sec:.0f}s\"\n",
    "        result[\"cost\"] = current_cost\n",
    "        result[\"urgency\"] = max_urgency\n",
    "        result[\"delta\"] = max_urgency - current_cost\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _generate_ending(self, state: PerformanceState) -> Dict:\n",
    "        \"\"\"ç”Ÿæˆç»“å°¾\"\"\"\n",
    "        speech = f\"å¥½å•¦ï¼Œä»Šå¤©å…³äº{state.topic}å°±èŠåˆ°è¿™é‡Œï¼Œä¸‹æ¬¡è§ï¼\"\n",
    "        audio = self.tts.synthesize(speech) if self.tts.enabled else None\n",
    "        \n",
    "        return {\n",
    "            \"inner_monologue\": \"è¯¥æ”¶å°¾äº†~\",\n",
    "            \"decision\": \"end\",\n",
    "            \"speech\": speech,\n",
    "            \"emotion\": \"satisfied\",\n",
    "            \"node\": \"END\",\n",
    "            \"time\": f\"{state.total_elapsed_sec:.0f}s\",\n",
    "            \"audio\": audio\n",
    "        }\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–\n",
    "performer = CognitivePerformer(llm, tts, analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: echuu Engine - å®Œæ•´å¼•æ“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EchuuEngine:\n",
    "    \"\"\"echuu æ ¸å¿ƒå¼•æ“\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: LLMClient, tts: TTSClient, analyzer: PatternAnalyzer):\n",
    "        self.llm = llm\n",
    "        self.tts = tts\n",
    "        self.analyzer = analyzer\n",
    "        self.script_gen = ScriptGenerator(llm, analyzer)\n",
    "        self.performer = CognitivePerformer(llm, tts, analyzer)\n",
    "    \n",
    "    def create_performance(self, name: str, persona: str, background: str,\n",
    "                          topic: str, language: str = \"zh\") -> PerformanceState:\n",
    "        \"\"\"åˆ›å»ºè¡¨æ¼”\"\"\"\n",
    "        print(f\"\\nğŸ¬ æ­£åœ¨ç”Ÿæˆå‰§æœ¬...\")\n",
    "        script = self.script_gen.generate(name, persona, background, topic, language)\n",
    "        \n",
    "        # æå–å‚è€ƒæ•°æ®\n",
    "        catchphrases = [cp for cp, _ in self.analyzer.extract_catchphrases(language)[:5]]\n",
    "        hooks = self.analyzer.extract_hooks(language)[:3]\n",
    "        \n",
    "        return PerformanceState(\n",
    "            name=name,\n",
    "            persona=persona,\n",
    "            background=background,\n",
    "            topic=topic,\n",
    "            script=script,\n",
    "            catchphrases=catchphrases,\n",
    "            example_hooks=hooks\n",
    "        )\n",
    "    \n",
    "    def run(self, state: PerformanceState, danmaku_sim: List[Dict] = None,\n",
    "            max_steps: int = 12, play_audio: bool = True) -> List[Dict]:\n",
    "        \"\"\"è¿è¡Œè¡¨æ¼”\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        danmaku_by_step = defaultdict(list)\n",
    "        if danmaku_sim:\n",
    "            for d in danmaku_sim:\n",
    "                step = d.get(\"step\", 0)\n",
    "                danmaku_by_step[step].append(Danmaku.from_text(d.get(\"text\", \"\")))\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ğŸ­ {state.name} - {state.topic}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ å‰§æœ¬éª¨æ¶:\")\n",
    "        for i, node in enumerate(state.script):\n",
    "            cost_bar = \"â–ˆ\" * int(node.interruption_cost * 5) + \"â–‘\" * (5 - int(node.interruption_cost * 5))\n",
    "            print(f\"  [{i+1}] {node.stage} {cost_bar} cost={node.interruption_cost:.1f}\")\n",
    "            print(f\"      â†’ {node.goal}\")\n",
    "        \n",
    "        print(f\"\\nğŸ¬ å¼€å§‹è¡¨æ¼”...\\n\")\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            new_danmaku = danmaku_by_step.get(step, [])\n",
    "            result = self.performer.step(state, new_danmaku)\n",
    "            results.append(result)\n",
    "            \n",
    "            # æ˜¾ç¤º\n",
    "            time_str = result.get('time', '?')\n",
    "            node_str = result.get('node', '?')\n",
    "            decision = result.get('decision', 'continue').upper()\n",
    "            \n",
    "            dec_icon = {\"RESPOND\": \"ğŸ’¬\", \"CONTINUE\": \"ğŸ“–\", \"END\": \"ğŸ­\"}.get(decision, \"ğŸ­\")\n",
    "            \n",
    "            print(f\"[{time_str}] {node_str} {dec_icon}\")\n",
    "            print(f\"  ğŸ’­ {result.get('inner_monologue', '')}\")\n",
    "            print(f\"  ğŸ“¢ {result.get('speech', '(æ²‰é»˜)')}\")\n",
    "            \n",
    "            if 'delta' in result:\n",
    "                delta = result['delta']\n",
    "                delta_str = f\"â†‘{delta:.2f}\" if delta > 0 else f\"â†“{abs(delta):.2f}\"\n",
    "                print(f\"  ğŸ“Š urgency={result.get('urgency', 0):.2f} - cost={result.get('cost', 0):.2f} = {delta_str}\")\n",
    "            \n",
    "            if result.get('target_danmaku'):\n",
    "                print(f\"  ğŸ’¬ å›åº”: {result['target_danmaku']}\")\n",
    "            \n",
    "            # æ’­æ”¾éŸ³é¢‘\n",
    "            if play_audio and result.get('audio'):\n",
    "                print(f\"  ğŸ”Š æ’­æ”¾è¯­éŸ³...\")\n",
    "                display(Audio(result['audio'], autoplay=True))\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            if result.get('decision') == \"end\":\n",
    "                break\n",
    "        \n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"âœ… è¡¨æ¼”ç»“æŸï¼æ€»æ—¶é•¿: {state.total_elapsed_sec:.0f}ç§’\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–å¼•æ“\n",
    "engine = EchuuEngine(llm, tts, analyzer)\n",
    "print(\"\\nâœ… echuu Engine åˆå§‹åŒ–å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: è¿è¡Œå®Œæ•´è¡¨æ¼”ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ç”¨ä¾‹: åŸºäºçœŸå®åˆ‡ç‰‡çš„è¯é¢˜\n",
    "test_case = {\n",
    "    \"name\": \"å…­èº\",\n",
    "    \"persona\": \"25å²ä¸»æ’­ï¼Œæ´»æ³¼è‡ªå˜²ï¼Œå–œæ¬¢åˆ†äº«ç”Ÿæ´»ç»å†ï¼Œå£ç™–ï¼šæˆ‘è§‰å¾—ã€å¯¹å§ã€å°±æ˜¯è¯´\",\n",
    "    \"background\": \"åšè¿‡å¾ˆå¤šå·¥ä½œï¼Œç°åœ¨æ˜¯å…¨èŒä¸»æ’­ï¼Œç•™å­¦æ—¥æœ¬å¤šå¹´\",\n",
    "    \"topic\": \"ç•™å­¦æ—¶å·åƒå®¤å‹è…°æœçš„æ•…äº‹\",\n",
    "    \"danmaku\": [\n",
    "        {\"step\": 1, \"text\": \"å“ˆå“ˆå“ˆ\"},\n",
    "        {\"step\": 2, \"text\": \"æˆ‘ä¹Ÿæœ‰ç±»ä¼¼ç»å†\"},\n",
    "        {\"step\": 4, \"text\": \"[SC Â¥50] åæ¥å®¤å‹ç”Ÿæ°”äº†å—\"},\n",
    "        {\"step\": 6, \"text\": \"ç¬‘æ­»\"},\n",
    "        {\"step\": 8, \"text\": \"å¤ªçœŸå®äº†\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# åˆ›å»ºè¡¨æ¼”\n",
    "state = engine.create_performance(\n",
    "    name=test_case[\"name\"],\n",
    "    persona=test_case[\"persona\"],\n",
    "    background=test_case[\"background\"],\n",
    "    topic=test_case[\"topic\"],\n",
    "    language=\"zh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œè¡¨æ¼”ï¼ˆå¸¦æ¨¡æ‹Ÿå¼¹å¹•å’Œè¯­éŸ³ï¼‰\n",
    "# è®¾ç½® play_audio=True è‡ªåŠ¨æ’­æ”¾è¯­éŸ³ï¼ŒFalse åªç”Ÿæˆä¸æ’­æ”¾\n",
    "results = engine.run(\n",
    "    state, \n",
    "    danmaku_sim=test_case[\"danmaku\"], \n",
    "    max_steps=10,\n",
    "    play_audio=True  # è®¾ä¸º False å¯ä»¥ç¦ç”¨è‡ªåŠ¨æ’­æ”¾\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11: å†³ç­–è¿‡ç¨‹å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å†³ç­–è¿‡ç¨‹\n",
    "print(\"\\nğŸ“Š å†³ç­–è¿‡ç¨‹å¯è§†åŒ–:\")\n",
    "print(\"\\næ—¶é—´ | é˜¶æ®µ | urgency | cost | Î” | å†³ç­–\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for r in results:\n",
    "    if r.get('decision') == 'end':\n",
    "        continue\n",
    "    \n",
    "    time = r.get('time', '?')\n",
    "    node = r.get('node', '?')[:10].ljust(10)\n",
    "    urgency = r.get('urgency', 0)\n",
    "    cost = r.get('cost', 0)\n",
    "    delta = r.get('delta', urgency - cost)\n",
    "    decision = r.get('decision', 'continue')\n",
    "    \n",
    "    urg_bar = \"â–ˆ\" * int(urgency * 5) + \"â–‘\" * (5 - int(urgency * 5))\n",
    "    cost_bar = \"â–ˆ\" * int(cost * 5) + \"â–‘\" * (5 - int(cost * 5))\n",
    "    \n",
    "    dec_icon = \"ğŸ’¬\" if decision == \"respond\" else \"ğŸ“–\"\n",
    "    \n",
    "    print(f\"{time:>5} | {node} | {urg_bar} {urgency:.1f} | {cost_bar} {cost:.1f} | {delta:+.2f} | {dec_icon} {decision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 12: è‡ªå®šä¹‰æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¨ è‡ªå®šä¹‰ä½ çš„è§’è‰²å’Œè¯é¢˜ï¼\n",
    "\n",
    "my_character = {\n",
    "    \"name\": \"å°çŒ«å’ª\",  # ğŸ‘ˆ ä¿®æ”¹åå­—\n",
    "    \"persona\": \"è½¯èŒå¯çˆ±çš„çŒ«å¨˜ä¸»æ’­ï¼Œè¯´è¯å¸¦å–µ~ï¼Œå–œæ¬¢æ’’å¨‡\",  # ğŸ‘ˆ ä¿®æ”¹äººè®¾\n",
    "    \"background\": \"ä»çŒ«å’ªæ˜Ÿçƒæ¥çš„ç•™å­¦ç”Ÿ\",  # ğŸ‘ˆ ä¿®æ”¹èƒŒæ™¯\n",
    "    \"topic\": \"ç¬¬ä¸€æ¬¡åƒäººç±»çš„çŒ«ç²®ï¼ˆè–¯ç‰‡ï¼‰çš„ä½“éªŒ\",  # ğŸ‘ˆ ä¿®æ”¹è¯é¢˜\n",
    "}\n",
    "\n",
    "my_danmaku = [\n",
    "    {\"step\": 1, \"text\": \"å¥½å¯çˆ±å–µ~\"},\n",
    "    {\"step\": 3, \"text\": \"è–¯ç‰‡å¥½åƒå—\"},\n",
    "    {\"step\": 5, \"text\": \"[SC Â¥100] ç»™ä½ ä¹°æ›´å¤šé›¶é£Ÿï¼\"},\n",
    "]\n",
    "\n",
    "# è¿è¡Œ\n",
    "my_state = engine.create_performance(**my_character, language=\"zh\")\n",
    "my_results = engine.run(my_state, danmaku_sim=my_danmaku, max_steps=8, play_audio=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 13: åˆ‡æ¢éŸ³è‰²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯ç”¨éŸ³è‰²åˆ—è¡¨\n",
    "print(\"ğŸ”Š å¯ç”¨éŸ³è‰²:\")\n",
    "print(\"  - longanyang    (é¾™å°å®‰ï¼Œç”·å£°ï¼Œè‡ªç„¶)\")\n",
    "print(\"  - longyingjing_v3 (é¾™ç›ˆé™ï¼Œå¥³å£°ï¼Œæ¸©æŸ”)\")\n",
    "print(\"  - longxiaochun_v2 (é¾™æ™“æ˜¥ï¼Œå¥³å£°ï¼Œæ´»æ³¼)\")\n",
    "print(\"  - longlaotie_v2   (é¾™è€é“ï¼Œç”·å£°ï¼Œæ²‰ç¨³)\")\n",
    "print(\"\\næ›´å¤šéŸ³è‰²: https://help.aliyun.com/zh/model-studio/cosyvoice-voice-list\")\n",
    "\n",
    "# åˆ‡æ¢éŸ³è‰²ç¤ºä¾‹\n",
    "# tts.change_voice(\"longyingjing_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ä¸åŒéŸ³è‰²\n",
    "if tts.enabled:\n",
    "    test_text = \"å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ä½ ä»¬çš„AIä¸»æ’­ï¼Œä»Šå¤©æ¥ç»™å¤§å®¶è®²ä¸ªæœ‰è¶£çš„æ•…äº‹ï¼\"\n",
    "    \n",
    "    for voice in [\"longanyang\", \"longyingjing_v3\"]:\n",
    "        tts.change_voice(voice)\n",
    "        audio = tts.synthesize(test_text)\n",
    "        if audio:\n",
    "            print(f\"\\nğŸ¤ {voice}:\")\n",
    "            display(Audio(audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## æ€»ç»“\n",
    "\n",
    "### æ ¸å¿ƒæœºåˆ¶\n",
    "\n",
    "1. **Interruption Cost** - ä»çœŸå®æ•°æ®å­¦ä¹ \"è¢«æ‰“æ–­ä»£ä»·\"\n",
    "   - `self` æ³¨æ„åŠ›æ—¶ cost è¾ƒé«˜ï¼ˆä¸æƒ³è¢«æ‰“æ–­è®²è‡ªå·±çš„äº‹ï¼‰\n",
    "   - `audience` æ³¨æ„åŠ›æ—¶ cost è¾ƒä½ï¼ˆæœ¬æ¥å°±åœ¨äº’åŠ¨ï¼‰\n",
    "   - cost éšèŠ‚ç‚¹è¿›åº¦è¡°å‡ï¼ˆå¿«è®²å®Œæ—¶å¯ä»¥è½¬åœºï¼‰\n",
    "\n",
    "2. **å†³ç­–å…¬å¼**\n",
    "   ```\n",
    "   decision_value = urgency - cost\n",
    "   æ­£æ•° â†’ å›åº”å¼¹å¹•\n",
    "   è´Ÿæ•° â†’ ç»§ç»­å‰§æœ¬\n",
    "   ```\n",
    "\n",
    "3. **Inner Monologue** - Killer Feature\n",
    "   - è®©è§‚ä¼—çœ‹åˆ°AIçš„\"æ€è€ƒè¿‡ç¨‹\"\n",
    "   - \"é€‰æ‹©ä¸å›åº”\"ä¹Ÿæ˜¯ä¸€ç§è¡¨è¾¾\n",
    "\n",
    "4. **å®æ—¶è¯­éŸ³** - CosyVoice TTS\n",
    "   - ä½å»¶è¿Ÿæµå¼åˆæˆ\n",
    "   - å¤šç§éŸ³è‰²å¯é€‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
