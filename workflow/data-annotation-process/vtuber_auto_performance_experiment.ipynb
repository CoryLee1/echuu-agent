{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VTuber Auto-Performance: 从真实表演逆向工程生成系统\n",
    "\n",
    "## 实验目标\n",
    "\n",
    "**核心假设**: 真人主播的\"人味\"可以被结构化提取，提取出的模式可以迁移到AI主播上。\n",
    "\n",
    "**MVP定义**: 生成2分钟可循环的表演叙事单元（抛梗→叙事→转折→破防），可直接切片为短视频。\n",
    "\n",
    "---\n",
    "\n",
    "## 创新点\n",
    "\n",
    "1. **Attention Focus作为一等公民**: 首次将主播的\"注意力指向\"作为可控生成参数\n",
    "2. **Performance→Prompt逆向工程**: 从真实表演反推Prompt，而非拍脑袋设计\n",
    "3. **面向切片的结构设计**: 生成内容本身按\"可切片\"结构设计，而非后处理找高光\n",
    "\n",
    "---\n",
    "\n",
    "## 实验流程\n",
    "\n",
    "```\n",
    "Phase 1: 数据标注 → Phase 2: 模式提炼 → Phase 3: 生成验证\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 1: 数据处理与标注\n",
    "\n",
    "## 1.1 标注Schema定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 核心标注Schema\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional, Literal\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "# ============================================\n",
    "# 核心维度1: 注意力指向 (Attention Focus)\n",
    "# 主播此刻在和谁对话/关注什么\n",
    "# ============================================\n",
    "class AttentionFocus(str, Enum):\n",
    "    SELF = \"self\"           # 自言自语/内心独白/讲自己的事\n",
    "    AUDIENCE = \"audience\"   # 直接对观众说话（你们、大家）\n",
    "    SPECIFIC = \"specific\"   # 回应特定观众（读SC、点名）\n",
    "    CONTENT = \"content\"     # 专注于内容（逗猫、看画面、读东西）\n",
    "    META = \"meta\"           # 谈论直播本身（今天播多久、设备问题）\n",
    "\n",
    "# ============================================\n",
    "# 核心维度2: 话语行为 (Speech Act)\n",
    "# 简化版Dialogue Act，只保留直播场景最relevant的\n",
    "# ============================================\n",
    "class SpeechAct(str, Enum):\n",
    "    NARRATE = \"narrate\"         # 叙事：讲故事、描述经历\n",
    "    OPINE = \"opine\"             # 表态：发表观点、评价\n",
    "    RESPOND = \"respond\"         # 回应：回答问题、接梗\n",
    "    ELICIT = \"elicit\"           # 引出：提问、抛梗、邀请互动\n",
    "    PIVOT = \"pivot\"             # 转折：话题转换、承上启下\n",
    "    BACKCHANNEL = \"backchannel\" # 填充：语气词、思考、过渡\n",
    "\n",
    "# ============================================\n",
    "# 核心维度3: 触发源 (Trigger)\n",
    "# 这段话是被什么触发的\n",
    "# ============================================\n",
    "class Trigger(str, Enum):\n",
    "    SC = \"sc\"               # SC/打赏触发\n",
    "    DANMAKU = \"danmaku\"     # 弹幕触发\n",
    "    SELF_INIT = \"self\"      # 自发（无外部触发）\n",
    "    CONTENT = \"content\"     # 内容触发（猫动了、画面变化）\n",
    "    PRIOR = \"prior\"         # 承接上文\n",
    "\n",
    "# ============================================\n",
    "# 数据结构定义\n",
    "# ============================================\n",
    "@dataclass\n",
    "class Segment:\n",
    "    \"\"\"最小标注单元：一个语义完整的话语片段\"\"\"\n",
    "    id: str                          # segment唯一ID\n",
    "    start_time: float                # 开始时间（秒）\n",
    "    end_time: float                  # 结束时间（秒）\n",
    "    text: str                        # 转录文本\n",
    "    \n",
    "    # 三个核心维度\n",
    "    attention_focus: AttentionFocus  # 注意力指向\n",
    "    speech_act: SpeechAct            # 话语行为\n",
    "    trigger: Trigger                 # 触发源\n",
    "    \n",
    "    # 可选：风格标记\n",
    "    catchphrase: Optional[str] = None      # 口癖（如果出现）\n",
    "    emotion_shift: bool = False            # 是否有明显情绪变化\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"id\": self.id,\n",
    "            \"start_time\": self.start_time,\n",
    "            \"end_time\": self.end_time,\n",
    "            \"text\": self.text,\n",
    "            \"attention_focus\": self.attention_focus.value,\n",
    "            \"speech_act\": self.speech_act.value,\n",
    "            \"trigger\": self.trigger.value,\n",
    "            \"catchphrase\": self.catchphrase,\n",
    "            \"emotion_shift\": self.emotion_shift\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class Clip:\n",
    "    \"\"\"一个完整的切片，包含多个segment\"\"\"\n",
    "    id: str                          # clip唯一ID\n",
    "    source: str                      # 来源（主播名/平台）\n",
    "    language: str                    # 语言 (zh/en)\n",
    "    duration_sec: float              # 总时长\n",
    "    \n",
    "    # 元数据\n",
    "    title: Optional[str] = None      # 切片标题/主题\n",
    "    quality_score: Optional[int] = None  # 质量评分 1-5\n",
    "    \n",
    "    # 内容\n",
    "    segments: List[Segment] = field(default_factory=list)\n",
    "    \n",
    "    # 提取的模式\n",
    "    skeleton: Optional[str] = None   # 叙事骨架类型\n",
    "    catchphrases: List[str] = field(default_factory=list)  # 口癖列表\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"id\": self.id,\n",
    "            \"source\": self.source,\n",
    "            \"language\": self.language,\n",
    "            \"duration_sec\": self.duration_sec,\n",
    "            \"title\": self.title,\n",
    "            \"quality_score\": self.quality_score,\n",
    "            \"segments\": [s.to_dict() for s in self.segments],\n",
    "            \"skeleton\": self.skeleton,\n",
    "            \"catchphrases\": self.catchphrases\n",
    "        }\n",
    "\n",
    "print(\"✓ Schema定义完成\")\n",
    "print(f\"  - AttentionFocus: {[e.value for e in AttentionFocus]}\")\n",
    "print(f\"  - SpeechAct: {[e.value for e in SpeechAct]}\")\n",
    "print(f\"  - Trigger: {[e.value for e in Trigger]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 原始数据格式规范\n",
    "\n",
    "你需要准备的Markdown格式如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示期望的输入格式\n",
    "EXPECTED_INPUT_FORMAT = '''\n",
    "# 原始切片数据格式规范\n",
    "\n",
    "请将每个切片整理为以下Markdown格式：\n",
    "\n",
    "---\n",
    "\n",
    "## clip_001\n",
    "\n",
    "- **source**: 某主播名\n",
    "- **language**: zh\n",
    "- **duration**: 120  (秒)\n",
    "- **title**: 起名与责任转嫁\n",
    "\n",
    "### transcript\n",
    "\n",
    "```\n",
    "0:00 谢谢xx的SC，也可以先从宝宝起名开始\n",
    "0:08 不行不行不行，给活物起名是我的第一线\n",
    "0:12 有很多人啊，他做选择是什么，他就想赖别人...\n",
    "...\n",
    "```\n",
    "\n",
    "### notes (可选)\n",
    "\n",
    "- 这段是回复SC引发的深度展开\n",
    "- 口癖：\"我跟你们说\"、\"对不对\"\n",
    "- 有明显的情绪升级\n",
    "\n",
    "---\n",
    "\n",
    "## clip_002\n",
    "\n",
    "...\n",
    "'''\n",
    "\n",
    "print(EXPECTED_INPUT_FORMAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 数据解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Tuple\n",
    "\n",
    "def parse_timestamp(ts: str) -> float:\n",
    "    \"\"\"解析时间戳，支持 M:SS 和 MM:SS 格式\"\"\"\n",
    "    parts = ts.strip().split(':')\n",
    "    if len(parts) == 2:\n",
    "        return int(parts[0]) * 60 + float(parts[1])\n",
    "    elif len(parts) == 3:\n",
    "        return int(parts[0]) * 3600 + int(parts[1]) * 60 + float(parts[2])\n",
    "    return 0.0\n",
    "\n",
    "def parse_transcript_line(line: str) -> Tuple[float, str]:\n",
    "    \"\"\"解析带时间戳的转录行\"\"\"\n",
    "    # 匹配 \"0:00 文本\" 或 \"00:00 文本\" 格式\n",
    "    match = re.match(r'^(\\d{1,2}:\\d{2})\\s+(.+)$', line.strip())\n",
    "    if match:\n",
    "        return parse_timestamp(match.group(1)), match.group(2)\n",
    "    return None, line\n",
    "\n",
    "def parse_raw_clips_markdown(md_content: str) -> List[dict]:\n",
    "    \"\"\"\n",
    "    解析原始切片Markdown文件\n",
    "    返回结构化的clip列表（未标注版本）\n",
    "    \"\"\"\n",
    "    clips = []\n",
    "    current_clip = None\n",
    "    current_section = None\n",
    "    transcript_lines = []\n",
    "    notes_lines = []\n",
    "    \n",
    "    for line in md_content.split('\\n'):\n",
    "        line = line.strip()\n",
    "        \n",
    "        # 新clip开始\n",
    "        if line.startswith('## clip_'):\n",
    "            # 保存之前的clip\n",
    "            if current_clip:\n",
    "                current_clip['transcript_lines'] = transcript_lines\n",
    "                current_clip['notes'] = '\\n'.join(notes_lines)\n",
    "                clips.append(current_clip)\n",
    "            \n",
    "            clip_id = line.replace('## ', '').strip()\n",
    "            current_clip = {'id': clip_id}\n",
    "            transcript_lines = []\n",
    "            notes_lines = []\n",
    "            current_section = None\n",
    "            \n",
    "        # 元数据\n",
    "        elif line.startswith('- **source**:'):\n",
    "            current_clip['source'] = line.split(':', 1)[1].strip()\n",
    "        elif line.startswith('- **language**:'):\n",
    "            current_clip['language'] = line.split(':', 1)[1].strip()\n",
    "        elif line.startswith('- **duration**:'):\n",
    "            current_clip['duration_sec'] = float(line.split(':', 1)[1].strip().split()[0])\n",
    "        elif line.startswith('- **title**:'):\n",
    "            current_clip['title'] = line.split(':', 1)[1].strip()\n",
    "            \n",
    "        # Section标记\n",
    "        elif line == '### transcript':\n",
    "            current_section = 'transcript'\n",
    "        elif line == '### notes' or line.startswith('### notes'):\n",
    "            current_section = 'notes'\n",
    "        elif line == '```':\n",
    "            continue\n",
    "            \n",
    "        # 内容收集\n",
    "        elif current_section == 'transcript' and line:\n",
    "            ts, text = parse_transcript_line(line)\n",
    "            if ts is not None:\n",
    "                transcript_lines.append({'time': ts, 'text': text})\n",
    "        elif current_section == 'notes' and line:\n",
    "            notes_lines.append(line)\n",
    "    \n",
    "    # 保存最后一个clip\n",
    "    if current_clip:\n",
    "        current_clip['transcript_lines'] = transcript_lines\n",
    "        current_clip['notes'] = '\\n'.join(notes_lines)\n",
    "        clips.append(current_clip)\n",
    "    \n",
    "    return clips\n",
    "\n",
    "print(\"✓ 数据解析器定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 LLM自动预标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM预标注Prompt模板\n",
    "AUTO_ANNOTATION_PROMPT = '''\n",
    "你是一个专业的直播内容分析师。请对以下直播切片进行segment级别的标注。\n",
    "\n",
    "## 标注维度\n",
    "\n",
    "### 1. attention_focus（注意力指向）\n",
    "- `self`: 自言自语/内心独白/讲自己的事\n",
    "- `audience`: 直接对观众说话（你们、大家）\n",
    "- `specific`: 回应特定观众（读SC、点名）\n",
    "- `content`: 专注于内容（逗猫、看画面）\n",
    "- `meta`: 谈论直播本身\n",
    "\n",
    "### 2. speech_act（话语行为）\n",
    "- `narrate`: 叙事，讲故事、描述经历\n",
    "- `opine`: 表态，发表观点、评价\n",
    "- `respond`: 回应，回答问题、接梗\n",
    "- `elicit`: 引出，提问、抛梗、邀请互动\n",
    "- `pivot`: 转折，话题转换、承上启下\n",
    "- `backchannel`: 填充，语气词、思考、过渡\n",
    "\n",
    "### 3. trigger（触发源）\n",
    "- `sc`: SC/打赏触发\n",
    "- `danmaku`: 弹幕触发\n",
    "- `self`: 自发（无外部触发）\n",
    "- `content`: 内容触发（画面变化）\n",
    "- `prior`: 承接上文\n",
    "\n",
    "## 切分原则\n",
    "\n",
    "1. 每个segment应该是一个语义完整的单元（通常5-30秒）\n",
    "2. 当attention_focus或speech_act发生变化时，应该切分新segment\n",
    "3. 保持segment数量合理（一个2分钟切片通常5-10个segment）\n",
    "\n",
    "## 输入\n",
    "\n",
    "```\n",
    "{transcript}\n",
    "```\n",
    "\n",
    "## 输出格式\n",
    "\n",
    "请输出JSON格式：\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"segments\": [\n",
    "    {{\n",
    "      \"id\": \"seg_01\",\n",
    "      \"start_time\": 0.0,\n",
    "      \"end_time\": 8.0,\n",
    "      \"text\": \"segment的文本内容\",\n",
    "      \"attention_focus\": \"specific\",\n",
    "      \"speech_act\": \"respond\",\n",
    "      \"trigger\": \"sc\",\n",
    "      \"catchphrase\": null,\n",
    "      \"emotion_shift\": false\n",
    "    }},\n",
    "    ...\n",
    "  ],\n",
    "  \"skeleton\": \"触发→拒绝→说理→升华\",\n",
    "  \"catchphrases\": [\"我跟你们说\", \"对不对\"]\n",
    "}}\n",
    "```\n",
    "'''\n",
    "\n",
    "def format_transcript_for_llm(transcript_lines: List[dict]) -> str:\n",
    "    \"\"\"格式化转录文本供LLM处理\"\"\"\n",
    "    lines = []\n",
    "    for item in transcript_lines:\n",
    "        minutes = int(item['time'] // 60)\n",
    "        seconds = int(item['time'] % 60)\n",
    "        lines.append(f\"{minutes}:{seconds:02d} {item['text']}\")\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def create_annotation_prompt(clip: dict) -> str:\n",
    "    \"\"\"为单个clip创建标注prompt\"\"\"\n",
    "    transcript = format_transcript_for_llm(clip.get('transcript_lines', []))\n",
    "    return AUTO_ANNOTATION_PROMPT.format(transcript=transcript)\n",
    "\n",
    "print(\"✓ LLM预标注模板定义完成\")\n",
    "print(\"\\n示例Prompt预览（前500字符）：\")\n",
    "print(AUTO_ANNOTATION_PROMPT[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟LLM调用（实际使用时替换为真实API）\n",
    "import os\n",
    "\n",
    "def call_llm_for_annotation(prompt: str, api_key: str = None) -> dict:\n",
    "    \"\"\"\n",
    "    调用LLM进行自动标注\n",
    "    \n",
    "    实际使用时，替换为你的API调用：\n",
    "    - Anthropic Claude API\n",
    "    - OpenAI API\n",
    "    - 阿里云通义千问\n",
    "    等\n",
    "    \"\"\"\n",
    "    # TODO: 替换为实际API调用\n",
    "    # 示例：使用Anthropic API\n",
    "    '''\n",
    "    import anthropic\n",
    "    client = anthropic.Anthropic(api_key=api_key)\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=4096,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return json.loads(response.content[0].text)\n",
    "    '''\n",
    "    \n",
    "    # 占位返回\n",
    "    print(\"[注意] 这是模拟返回，实际使用时需要配置API\")\n",
    "    return {\n",
    "        \"segments\": [],\n",
    "        \"skeleton\": \"待标注\",\n",
    "        \"catchphrases\": []\n",
    "    }\n",
    "\n",
    "print(\"✓ LLM调用函数定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 2: 模式提炼与统计分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "class PatternAnalyzer:\n",
    "    \"\"\"从标注数据中提炼模式\"\"\"\n",
    "    \n",
    "    def __init__(self, clips: List[Clip]):\n",
    "        self.clips = clips\n",
    "        self.all_segments = []\n",
    "        for clip in clips:\n",
    "            self.all_segments.extend(clip.segments)\n",
    "    \n",
    "    def compute_attention_transition_matrix(self) -> dict:\n",
    "        \"\"\"\n",
    "        计算attention_focus的状态转移矩阵\n",
    "        返回: {from_state: {to_state: count}}\n",
    "        \"\"\"\n",
    "        transitions = defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        for clip in self.clips:\n",
    "            for i in range(len(clip.segments) - 1):\n",
    "                from_state = clip.segments[i].attention_focus.value\n",
    "                to_state = clip.segments[i + 1].attention_focus.value\n",
    "                transitions[from_state][to_state] += 1\n",
    "        \n",
    "        # 转换为概率\n",
    "        prob_matrix = {}\n",
    "        for from_state, to_states in transitions.items():\n",
    "            total = sum(to_states.values())\n",
    "            prob_matrix[from_state] = {\n",
    "                to_state: count / total \n",
    "                for to_state, count in to_states.items()\n",
    "            }\n",
    "        \n",
    "        return prob_matrix\n",
    "    \n",
    "    def compute_trigger_speech_act_distribution(self) -> dict:\n",
    "        \"\"\"\n",
    "        计算不同trigger下speech_act的条件分布\n",
    "        返回: {trigger: {speech_act: probability}}\n",
    "        \"\"\"\n",
    "        dist = defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        for seg in self.all_segments:\n",
    "            dist[seg.trigger.value][seg.speech_act.value] += 1\n",
    "        \n",
    "        # 转换为概率\n",
    "        prob_dist = {}\n",
    "        for trigger, speech_acts in dist.items():\n",
    "            total = sum(speech_acts.values())\n",
    "            prob_dist[trigger] = {\n",
    "                sa: count / total \n",
    "                for sa, count in speech_acts.items()\n",
    "            }\n",
    "        \n",
    "        return prob_dist\n",
    "    \n",
    "    def extract_skeleton_patterns(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        提取常见的叙事骨架模式\n",
    "        返回: 按频率排序的skeleton列表\n",
    "        \"\"\"\n",
    "        skeletons = [clip.skeleton for clip in self.clips if clip.skeleton]\n",
    "        return [s for s, _ in Counter(skeletons).most_common()]\n",
    "    \n",
    "    def extract_segment_type_sequences(self) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "        提取每个clip的segment类型序列\n",
    "        返回: [[\"specific_respond\", \"self_narrate\", ...], ...]\n",
    "        \"\"\"\n",
    "        sequences = []\n",
    "        for clip in self.clips:\n",
    "            seq = [\n",
    "                f\"{seg.attention_focus.value}_{seg.speech_act.value}\"\n",
    "                for seg in clip.segments\n",
    "            ]\n",
    "            sequences.append(seq)\n",
    "        return sequences\n",
    "    \n",
    "    def compute_statistics(self) -> dict:\n",
    "        \"\"\"计算整体统计信息\"\"\"\n",
    "        attention_counts = Counter(seg.attention_focus.value for seg in self.all_segments)\n",
    "        speech_act_counts = Counter(seg.speech_act.value for seg in self.all_segments)\n",
    "        trigger_counts = Counter(seg.trigger.value for seg in self.all_segments)\n",
    "        \n",
    "        return {\n",
    "            \"total_clips\": len(self.clips),\n",
    "            \"total_segments\": len(self.all_segments),\n",
    "            \"avg_segments_per_clip\": len(self.all_segments) / len(self.clips) if self.clips else 0,\n",
    "            \"attention_distribution\": dict(attention_counts),\n",
    "            \"speech_act_distribution\": dict(speech_act_counts),\n",
    "            \"trigger_distribution\": dict(trigger_counts)\n",
    "        }\n",
    "    \n",
    "    def generate_report(self) -> str:\n",
    "        \"\"\"生成分析报告\"\"\"\n",
    "        stats = self.compute_statistics()\n",
    "        trans_matrix = self.compute_attention_transition_matrix()\n",
    "        trigger_dist = self.compute_trigger_speech_act_distribution()\n",
    "        skeletons = self.extract_skeleton_patterns()\n",
    "        \n",
    "        report = f\"\"\"\n",
    "# 模式分析报告\n",
    "\n",
    "## 基础统计\n",
    "- 总切片数: {stats['total_clips']}\n",
    "- 总segment数: {stats['total_segments']}\n",
    "- 平均每clip的segment数: {stats['avg_segments_per_clip']:.1f}\n",
    "\n",
    "## Attention Focus分布\n",
    "{json.dumps(stats['attention_distribution'], indent=2, ensure_ascii=False)}\n",
    "\n",
    "## Speech Act分布\n",
    "{json.dumps(stats['speech_act_distribution'], indent=2, ensure_ascii=False)}\n",
    "\n",
    "## Trigger分布\n",
    "{json.dumps(stats['trigger_distribution'], indent=2, ensure_ascii=False)}\n",
    "\n",
    "## Attention状态转移矩阵\n",
    "{json.dumps(trans_matrix, indent=2, ensure_ascii=False)}\n",
    "\n",
    "## 常见叙事骨架\n",
    "{chr(10).join(f'- {s}' for s in skeletons[:10])}\n",
    "\n",
    "## Trigger→SpeechAct条件分布\n",
    "{json.dumps(trigger_dist, indent=2, ensure_ascii=False)}\n",
    "        \"\"\"\n",
    "        return report\n",
    "\n",
    "print(\"✓ PatternAnalyzer定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 3: MultiAgent生成系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Prompt模板\n",
    "\n",
    "DIRECTOR_AGENT_PROMPT = '''\n",
    "你是一个VTuber直播的导演Agent。你的任务是规划2分钟表演单元的结构。\n",
    "\n",
    "## 输入\n",
    "- 人设: {persona}\n",
    "- 背景: {background}\n",
    "- 主题: {topic}\n",
    "- 触发事件: {trigger_event}\n",
    "\n",
    "## 输出要求\n",
    "规划5-8个segment的序列，每个segment包含:\n",
    "- attention_focus: self/audience/specific/content/meta\n",
    "- speech_act: narrate/opine/respond/elicit/pivot/backchannel\n",
    "- duration_hint: 预估时长（秒）\n",
    "- content_hint: 这个segment应该讲什么的简要提示\n",
    "\n",
    "## 结构原则（基于真实主播数据统计）\n",
    "{structure_rules}\n",
    "\n",
    "## 输出格式\n",
    "```json\n",
    "{{\n",
    "  \"skeleton\": \"触发→展开→转折→释放\",\n",
    "  \"segments\": [\n",
    "    {{\n",
    "      \"attention_focus\": \"specific\",\n",
    "      \"speech_act\": \"respond\",\n",
    "      \"duration_hint\": 10,\n",
    "      \"content_hint\": \"读SC并简短回应\"\n",
    "    }},\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "'''\n",
    "\n",
    "NARRATOR_AGENT_PROMPT = '''\n",
    "你是一个VTuber直播的内容生成Agent。你的任务是根据导演的规划生成具体台词。\n",
    "\n",
    "## 人设\n",
    "{persona}\n",
    "\n",
    "## 当前segment规划\n",
    "- attention_focus: {attention_focus}\n",
    "- speech_act: {speech_act}\n",
    "- content_hint: {content_hint}\n",
    "- 预估时长: {duration_hint}秒\n",
    "\n",
    "## 上下文\n",
    "- 之前的segment: {previous_segments}\n",
    "- 触发事件: {trigger_event}\n",
    "\n",
    "## 参考风格（Few-shot Examples）\n",
    "{style_examples}\n",
    "\n",
    "## 输出要求\n",
    "生成这个segment的具体台词，要求:\n",
    "1. 符合attention_focus指向（对谁说话）\n",
    "2. 符合speech_act类型（在做什么）\n",
    "3. 符合人设和口语风格\n",
    "4. 时长约{duration_hint}秒（约{word_count}字）\n",
    "\n",
    "直接输出台词文本，不要加任何标记。\n",
    "'''\n",
    "\n",
    "STYLE_AGENT_PROMPT = '''\n",
    "你是一个风格润色Agent。你的任务是让生成的台词更有\"人味\"。\n",
    "\n",
    "## 原始台词\n",
    "{raw_text}\n",
    "\n",
    "## 人设口癖\n",
    "{catchphrases}\n",
    "\n",
    "## 润色规则\n",
    "1. 适当加入口癖（但不要过度）\n",
    "2. 加入语气词和停顿标记\n",
    "3. 调整句子长度，短句为主\n",
    "4. 保持口语化，避免书面语\n",
    "\n",
    "## 输出\n",
    "直接输出润色后的台词。\n",
    "'''\n",
    "\n",
    "CONSISTENCY_CHECKER_PROMPT = '''\n",
    "你是一个人设一致性检查Agent。检查生成的内容是否与人设矛盾。\n",
    "\n",
    "## 人设\n",
    "{persona}\n",
    "\n",
    "## 生成的内容\n",
    "{generated_content}\n",
    "\n",
    "## 检查项\n",
    "1. 是否有与人设矛盾的陈述？\n",
    "2. 是否有不合理的知识假设？\n",
    "3. 语气是否一致？\n",
    "\n",
    "## 输出格式\n",
    "```json\n",
    "{{\n",
    "  \"is_consistent\": true/false,\n",
    "  \"issues\": [\"问题描述\", ...],\n",
    "  \"suggestions\": [\"修改建议\", ...]\n",
    "}}\n",
    "```\n",
    "'''\n",
    "\n",
    "print(\"✓ Agent Prompt模板定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PerformanceUnit:\n",
    "    \"\"\"生成的2分钟表演单元\"\"\"\n",
    "    persona: str\n",
    "    topic: str\n",
    "    skeleton: str\n",
    "    segments: List[dict]  # 每个segment包含台词\n",
    "    total_duration: float\n",
    "    consistency_check: dict\n",
    "\n",
    "class VTuberPerformanceGenerator:\n",
    "    \"\"\"\n",
    "    VTuber自动表演生成系统\n",
    "    \n",
    "    Pipeline:\n",
    "    1. Director Agent: 规划结构\n",
    "    2. Narrator Agent: 生成台词\n",
    "    3. Style Agent: 风格润色\n",
    "    4. Consistency Checker: 一致性检查\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 pattern_analyzer: PatternAnalyzer = None,\n",
    "                 api_key: str = None):\n",
    "        self.pattern_analyzer = pattern_analyzer\n",
    "        self.api_key = api_key\n",
    "        \n",
    "        # 从分析器提取规则（如果有）\n",
    "        self.structure_rules = self._extract_structure_rules()\n",
    "        self.style_examples = self._extract_style_examples()\n",
    "    \n",
    "    def _extract_structure_rules(self) -> str:\n",
    "        \"\"\"从标注数据提取结构规则\"\"\"\n",
    "        if not self.pattern_analyzer:\n",
    "            return \"（使用默认规则）\"\n",
    "        \n",
    "        trans_matrix = self.pattern_analyzer.compute_attention_transition_matrix()\n",
    "        rules = []\n",
    "        \n",
    "        for from_state, to_states in trans_matrix.items():\n",
    "            top_transitions = sorted(to_states.items(), key=lambda x: -x[1])[:2]\n",
    "            for to_state, prob in top_transitions:\n",
    "                if prob > 0.2:\n",
    "                    rules.append(f\"- {from_state}后常接{to_state}（{prob:.0%}概率）\")\n",
    "        \n",
    "        return '\\n'.join(rules)\n",
    "    \n",
    "    def _extract_style_examples(self) -> str:\n",
    "        \"\"\"从标注数据提取风格示例\"\"\"\n",
    "        if not self.pattern_analyzer:\n",
    "            return \"（无示例）\"\n",
    "        \n",
    "        examples = []\n",
    "        for clip in self.pattern_analyzer.clips[:3]:\n",
    "            for seg in clip.segments[:2]:\n",
    "                examples.append(f\"[{seg.attention_focus.value}_{seg.speech_act.value}] {seg.text[:100]}...\")\n",
    "        \n",
    "        return '\\n'.join(examples)\n",
    "    \n",
    "    def generate(self, \n",
    "                 persona: str,\n",
    "                 background: str,\n",
    "                 topic: str,\n",
    "                 trigger_event: str = None,\n",
    "                 catchphrases: List[str] = None) -> PerformanceUnit:\n",
    "        \"\"\"\n",
    "        生成一个2分钟表演单元\n",
    "        \n",
    "        Args:\n",
    "            persona: 人设描述\n",
    "            background: 背景设定\n",
    "            topic: 直播主题\n",
    "            trigger_event: 触发事件（如SC内容）\n",
    "            catchphrases: 口癖列表\n",
    "        \n",
    "        Returns:\n",
    "            PerformanceUnit: 生成的表演单元\n",
    "        \"\"\"\n",
    "        \n",
    "        # Step 1: Director规划结构\n",
    "        print(\"[1/4] Director Agent: 规划结构...\")\n",
    "        structure = self._call_director_agent(\n",
    "            persona=persona,\n",
    "            background=background,\n",
    "            topic=topic,\n",
    "            trigger_event=trigger_event\n",
    "        )\n",
    "        \n",
    "        # Step 2: Narrator生成台词\n",
    "        print(\"[2/4] Narrator Agent: 生成台词...\")\n",
    "        segments_with_text = []\n",
    "        previous_texts = []\n",
    "        \n",
    "        for i, seg_plan in enumerate(structure.get('segments', [])):\n",
    "            text = self._call_narrator_agent(\n",
    "                persona=persona,\n",
    "                segment_plan=seg_plan,\n",
    "                previous_segments=previous_texts,\n",
    "                trigger_event=trigger_event\n",
    "            )\n",
    "            \n",
    "            # Step 3: Style润色\n",
    "            print(f\"[3/4] Style Agent: 润色segment {i+1}...\")\n",
    "            styled_text = self._call_style_agent(\n",
    "                raw_text=text,\n",
    "                catchphrases=catchphrases or []\n",
    "            )\n",
    "            \n",
    "            seg_plan['text'] = styled_text\n",
    "            segments_with_text.append(seg_plan)\n",
    "            previous_texts.append(styled_text)\n",
    "        \n",
    "        # Step 4: 一致性检查\n",
    "        print(\"[4/4] Consistency Checker: 检查一致性...\")\n",
    "        full_content = '\\n'.join([s['text'] for s in segments_with_text])\n",
    "        consistency_check = self._call_consistency_checker(\n",
    "            persona=persona,\n",
    "            generated_content=full_content\n",
    "        )\n",
    "        \n",
    "        # 估算总时长\n",
    "        total_duration = sum(s.get('duration_hint', 15) for s in segments_with_text)\n",
    "        \n",
    "        return PerformanceUnit(\n",
    "            persona=persona,\n",
    "            topic=topic,\n",
    "            skeleton=structure.get('skeleton', ''),\n",
    "            segments=segments_with_text,\n",
    "            total_duration=total_duration,\n",
    "            consistency_check=consistency_check\n",
    "        )\n",
    "    \n",
    "    def _call_director_agent(self, persona, background, topic, trigger_event) -> dict:\n",
    "        \"\"\"调用Director Agent\"\"\"\n",
    "        prompt = DIRECTOR_AGENT_PROMPT.format(\n",
    "            persona=persona,\n",
    "            background=background,\n",
    "            topic=topic,\n",
    "            trigger_event=trigger_event or \"无特定触发\",\n",
    "            structure_rules=self.structure_rules\n",
    "        )\n",
    "        # TODO: 替换为实际LLM调用\n",
    "        return {\n",
    "            \"skeleton\": \"触发→展开→转折→释放\",\n",
    "            \"segments\": [\n",
    "                {\"attention_focus\": \"specific\", \"speech_act\": \"respond\", \"duration_hint\": 10, \"content_hint\": \"回应触发\"},\n",
    "                {\"attention_focus\": \"self\", \"speech_act\": \"narrate\", \"duration_hint\": 30, \"content_hint\": \"展开叙述\"},\n",
    "                {\"attention_focus\": \"audience\", \"speech_act\": \"opine\", \"duration_hint\": 20, \"content_hint\": \"发表观点\"},\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def _call_narrator_agent(self, persona, segment_plan, previous_segments, trigger_event) -> str:\n",
    "        \"\"\"调用Narrator Agent\"\"\"\n",
    "        # TODO: 替换为实际LLM调用\n",
    "        return f\"[示例台词 - {segment_plan['content_hint']}]\"\n",
    "    \n",
    "    def _call_style_agent(self, raw_text, catchphrases) -> str:\n",
    "        \"\"\"调用Style Agent\"\"\"\n",
    "        # TODO: 替换为实际LLM调用\n",
    "        return raw_text\n",
    "    \n",
    "    def _call_consistency_checker(self, persona, generated_content) -> dict:\n",
    "        \"\"\"调用Consistency Checker\"\"\"\n",
    "        # TODO: 替换为实际LLM调用\n",
    "        return {\"is_consistent\": True, \"issues\": [], \"suggestions\": []}\n",
    "\n",
    "print(\"✓ VTuberPerformanceGenerator定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 4: 评估与迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EvaluationResult:\n",
    "    \"\"\"评估结果\"\"\"\n",
    "    clip_id: str\n",
    "    \n",
    "    # 结构评估\n",
    "    structure_validity: float      # 结构是否符合统计分布 (0-1)\n",
    "    attention_flow_score: float    # 注意力切换自然度 (0-1)\n",
    "    \n",
    "    # 质量评估\n",
    "    human_likeness: Optional[float] = None  # 人味得分 (人工评分 1-5)\n",
    "    clipability_score: Optional[float] = None  # 可切片性 (0-1)\n",
    "    \n",
    "    # 一致性\n",
    "    persona_consistency: bool = True\n",
    "    \n",
    "    # 备注\n",
    "    notes: str = \"\"\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\"评估器\"\"\"\n",
    "    \n",
    "    def __init__(self, pattern_analyzer: PatternAnalyzer = None):\n",
    "        self.pattern_analyzer = pattern_analyzer\n",
    "    \n",
    "    def evaluate_structure(self, performance: PerformanceUnit) -> float:\n",
    "        \"\"\"\n",
    "        评估生成结构是否符合真实数据分布\n",
    "        \"\"\"\n",
    "        if not self.pattern_analyzer:\n",
    "            return 0.5  # 无参考数据时返回中性分数\n",
    "        \n",
    "        # 检查segment数量是否合理\n",
    "        stats = self.pattern_analyzer.compute_statistics()\n",
    "        avg_segs = stats['avg_segments_per_clip']\n",
    "        actual_segs = len(performance.segments)\n",
    "        \n",
    "        # segment数量评分\n",
    "        seg_count_score = max(0, 1 - abs(actual_segs - avg_segs) / avg_segs)\n",
    "        \n",
    "        # 状态转移评分\n",
    "        trans_matrix = self.pattern_analyzer.compute_attention_transition_matrix()\n",
    "        transition_scores = []\n",
    "        \n",
    "        for i in range(len(performance.segments) - 1):\n",
    "            from_state = performance.segments[i].get('attention_focus', '')\n",
    "            to_state = performance.segments[i + 1].get('attention_focus', '')\n",
    "            \n",
    "            if from_state in trans_matrix and to_state in trans_matrix.get(from_state, {}):\n",
    "                prob = trans_matrix[from_state][to_state]\n",
    "                transition_scores.append(prob)\n",
    "            else:\n",
    "                transition_scores.append(0.1)  # 未见过的转换给低分\n",
    "        \n",
    "        trans_score = sum(transition_scores) / len(transition_scores) if transition_scores else 0.5\n",
    "        \n",
    "        return (seg_count_score + trans_score) / 2\n",
    "    \n",
    "    def evaluate_attention_flow(self, performance: PerformanceUnit) -> float:\n",
    "        \"\"\"\n",
    "        评估注意力切换的自然度\n",
    "        - 不能连续太多相同的attention_focus\n",
    "        - 切换不能太频繁\n",
    "        \"\"\"\n",
    "        focuses = [s.get('attention_focus', '') for s in performance.segments]\n",
    "        \n",
    "        if len(focuses) < 2:\n",
    "            return 1.0\n",
    "        \n",
    "        # 计算切换次数\n",
    "        switches = sum(1 for i in range(len(focuses) - 1) if focuses[i] != focuses[i + 1])\n",
    "        switch_rate = switches / (len(focuses) - 1)\n",
    "        \n",
    "        # 理想切换率在0.3-0.7之间\n",
    "        if 0.3 <= switch_rate <= 0.7:\n",
    "            return 1.0\n",
    "        elif switch_rate < 0.3:\n",
    "            return switch_rate / 0.3\n",
    "        else:\n",
    "            return (1 - switch_rate) / 0.3\n",
    "    \n",
    "    def check_clipability(self, performance: PerformanceUnit) -> Tuple[float, List[dict]]:\n",
    "        \"\"\"\n",
    "        检查可切片性：能否从中提取出独立的短视频片段\n",
    "        \n",
    "        Returns:\n",
    "            score: 可切片性得分 (0-1)\n",
    "            potential_clips: 潜在可切片的segment组合\n",
    "        \"\"\"\n",
    "        potential_clips = []\n",
    "        \n",
    "        # 寻找有完整叙事弧的segment组合\n",
    "        # 好的切片通常包含: 开头(respond/elicit) + 中间(narrate) + 结尾(opine/pivot)\n",
    "        \n",
    "        for i in range(len(performance.segments)):\n",
    "            for j in range(i + 2, min(i + 5, len(performance.segments) + 1)):\n",
    "                sub_segments = performance.segments[i:j]\n",
    "                \n",
    "                # 检查是否有完整弧线\n",
    "                speech_acts = [s.get('speech_act', '') for s in sub_segments]\n",
    "                \n",
    "                has_opening = speech_acts[0] in ['respond', 'elicit', 'pivot']\n",
    "                has_body = any(sa == 'narrate' for sa in speech_acts[1:-1]) if len(speech_acts) > 2 else True\n",
    "                has_closing = speech_acts[-1] in ['opine', 'respond', 'pivot']\n",
    "                \n",
    "                if has_opening and has_body and has_closing:\n",
    "                    duration = sum(s.get('duration_hint', 15) for s in sub_segments)\n",
    "                    if 15 <= duration <= 60:  # 15-60秒适合短视频\n",
    "                        potential_clips.append({\n",
    "                            \"start_idx\": i,\n",
    "                            \"end_idx\": j,\n",
    "                            \"duration\": duration,\n",
    "                            \"segments\": sub_segments\n",
    "                        })\n",
    "        \n",
    "        # 得分 = 潜在切片数 / 最大可能切片数\n",
    "        max_possible = len(performance.segments) - 1\n",
    "        score = min(1.0, len(potential_clips) / max_possible) if max_possible > 0 else 0\n",
    "        \n",
    "        return score, potential_clips\n",
    "    \n",
    "    def full_evaluate(self, performance: PerformanceUnit) -> EvaluationResult:\n",
    "        \"\"\"完整评估\"\"\"\n",
    "        structure_score = self.evaluate_structure(performance)\n",
    "        attention_score = self.evaluate_attention_flow(performance)\n",
    "        clipability_score, potential_clips = self.check_clipability(performance)\n",
    "        \n",
    "        return EvaluationResult(\n",
    "            clip_id=f\"gen_{hash(performance.topic) % 10000}\",\n",
    "            structure_validity=structure_score,\n",
    "            attention_flow_score=attention_score,\n",
    "            clipability_score=clipability_score,\n",
    "            persona_consistency=performance.consistency_check.get('is_consistent', True),\n",
    "            notes=f\"发现{len(potential_clips)}个潜在可切片段\"\n",
    "        )\n",
    "\n",
    "print(\"✓ Evaluator定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 完整Pipeline运行示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_pipeline(raw_clips_md_path: str = None, api_key: str = None):\n",
    "    \"\"\"\n",
    "    运行完整Pipeline\n",
    "    \n",
    "    Args:\n",
    "        raw_clips_md_path: 原始切片Markdown文件路径\n",
    "        api_key: LLM API密钥\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"VTuber Auto-Performance 实验Pipeline\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ============================================\n",
    "    # Phase 1: 数据处理\n",
    "    # ============================================\n",
    "    print(\"\\n[Phase 1] 数据处理与标注\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    if raw_clips_md_path:\n",
    "        with open(raw_clips_md_path, 'r', encoding='utf-8') as f:\n",
    "            raw_md = f.read()\n",
    "        raw_clips = parse_raw_clips_markdown(raw_md)\n",
    "        print(f\"✓ 解析到 {len(raw_clips)} 个原始切片\")\n",
    "    else:\n",
    "        print(\"⚠ 未提供原始数据文件，使用示例数据\")\n",
    "        raw_clips = []\n",
    "    \n",
    "    # 这里应该进行LLM标注，暂用模拟数据\n",
    "    annotated_clips = []  # TODO: 实际标注后填充\n",
    "    \n",
    "    # ============================================\n",
    "    # Phase 2: 模式分析\n",
    "    # ============================================\n",
    "    print(\"\\n[Phase 2] 模式分析\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    if annotated_clips:\n",
    "        analyzer = PatternAnalyzer(annotated_clips)\n",
    "        report = analyzer.generate_report()\n",
    "        print(report)\n",
    "    else:\n",
    "        print(\"⚠ 无标注数据，跳过模式分析\")\n",
    "        analyzer = None\n",
    "    \n",
    "    # ============================================\n",
    "    # Phase 3: 生成测试\n",
    "    # ============================================\n",
    "    print(\"\\n[Phase 3] 生成测试\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    generator = VTuberPerformanceGenerator(\n",
    "        pattern_analyzer=analyzer,\n",
    "        api_key=api_key\n",
    "    )\n",
    "    \n",
    "    # 测试生成\n",
    "    test_persona = \"\"\"\n",
    "    你是一个25岁的游戏主播，性格活泼但偶尔会突然深沉。\n",
    "    喜欢讲自己的糗事，经常自嘲。\n",
    "    口癖：\"我跟你们说\"、\"天哪\"、\"对不对\"\n",
    "    \"\"\"\n",
    "    \n",
    "    test_background = \"日常杂谈直播，没有特定游戏\"\n",
    "    test_topic = \"观众问能不能帮忙给宠物起名字\"\n",
    "    test_trigger = \"SC: 主播主播，能不能帮我给我的小猫起个名字？\"\n",
    "    \n",
    "    print(f\"生成测试...\")\n",
    "    print(f\"  人设: {test_persona[:50]}...\")\n",
    "    print(f\"  主题: {test_topic}\")\n",
    "    print(f\"  触发: {test_trigger}\")\n",
    "    \n",
    "    performance = generator.generate(\n",
    "        persona=test_persona,\n",
    "        background=test_background,\n",
    "        topic=test_topic,\n",
    "        trigger_event=test_trigger,\n",
    "        catchphrases=[\"我跟你们说\", \"天哪\", \"对不对\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n生成结果:\")\n",
    "    print(f\"  骨架: {performance.skeleton}\")\n",
    "    print(f\"  段落数: {len(performance.segments)}\")\n",
    "    print(f\"  预估时长: {performance.total_duration}秒\")\n",
    "    \n",
    "    # ============================================\n",
    "    # Phase 4: 评估\n",
    "    # ============================================\n",
    "    print(\"\\n[Phase 4] 评估\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    evaluator = Evaluator(pattern_analyzer=analyzer)\n",
    "    eval_result = evaluator.full_evaluate(performance)\n",
    "    \n",
    "    print(f\"评估结果:\")\n",
    "    print(f\"  结构有效性: {eval_result.structure_validity:.2f}\")\n",
    "    print(f\"  注意力流畅度: {eval_result.attention_flow_score:.2f}\")\n",
    "    print(f\"  可切片性: {eval_result.clipability_score:.2f}\")\n",
    "    print(f\"  人设一致性: {'✓' if eval_result.persona_consistency else '✗'}\")\n",
    "    print(f\"  备注: {eval_result.notes}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Pipeline完成\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return {\n",
    "        \"raw_clips\": raw_clips,\n",
    "        \"annotated_clips\": annotated_clips,\n",
    "        \"analyzer\": analyzer,\n",
    "        \"generator\": generator,\n",
    "        \"performance\": performance,\n",
    "        \"evaluation\": eval_result\n",
    "    }\n",
    "\n",
    "# 运行示例（无数据版本）\n",
    "# results = run_full_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 数据文件模板\n",
    "\n",
    "请按以下格式准备你的切片数据，保存为 `raw_clips.md`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEMPLATE = '''\n",
    "# VTuber切片原始数据\n",
    "\n",
    "## clip_001\n",
    "\n",
    "- **source**: 主播A\n",
    "- **language**: zh\n",
    "- **duration**: 120\n",
    "- **title**: 起名与责任转嫁\n",
    "\n",
    "### transcript\n",
    "\n",
    "```\n",
    "0:00 谢谢xx的SC，也可以先从宝宝起名开始\n",
    "0:08 不行不行不行，给活物起名是我的第一线\n",
    "0:15 有很多人啊，他做选择是什么，他就想赖别人\n",
    "...\n",
    "```\n",
    "\n",
    "### notes\n",
    "\n",
    "- 回复SC引发的深度展开\n",
    "- 口癖：\"我跟你们说\"、\"对不对\"\n",
    "\n",
    "---\n",
    "\n",
    "## clip_002\n",
    "\n",
    "- **source**: StreamerB\n",
    "- **language**: en\n",
    "- **duration**: 90\n",
    "- **title**: Why I never give pet naming advice\n",
    "\n",
    "### transcript\n",
    "\n",
    "```\n",
    "0:00 Oh my god chat, someone just asked me to name their cat\n",
    "0:05 No no no, that\\'s where I draw the line\n",
    "...\n",
    "```\n",
    "\n",
    "### notes\n",
    "\n",
    "- Similar topic to clip_001 but in English\n",
    "- Catchphrases: \"oh my god\", \"chat\"\n",
    "\n",
    "---\n",
    "\n",
    "(继续添加更多切片...)\n",
    "'''\n",
    "\n",
    "# 保存模板文件\n",
    "with open('/home/claude/raw_clips_template.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(DATA_TEMPLATE)\n",
    "\n",
    "print(\"✓ 数据模板已保存到 raw_clips_template.md\")\n",
    "print(\"\\n请按此格式准备20个切片（中英混合），然后运行Pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 下一步行动清单\n",
    "\n",
    "## 你需要做的：\n",
    "\n",
    "1. **准备数据** (预计1-2天)\n",
    "   - 收集20个高质量主播切片（中英各10个左右）\n",
    "   - 按 `raw_clips_template.md` 格式整理\n",
    "   - 每个切片1-3分钟，要有完整的叙事弧\n",
    "\n",
    "2. **配置API** (10分钟)\n",
    "   - 获取Claude/GPT API密钥\n",
    "   - 替换notebook中的 `call_llm_for_annotation` 函数\n",
    "\n",
    "3. **运行标注** (预计2-3小时)\n",
    "   - 运行LLM预标注\n",
    "   - 人工校正标注结果\n",
    "\n",
    "4. **迭代优化** (持续)\n",
    "   - 分析模式报告\n",
    "   - 调整Agent Prompt\n",
    "   - 生成→评估→改进\n",
    "\n",
    "## 评估指标目标：\n",
    "\n",
    "| 指标 | 目标值 |\n",
    "|------|--------|\n",
    "| 结构有效性 | >0.7 |\n",
    "| 注意力流畅度 | >0.6 |\n",
    "| 可切片性 | >0.5 (每2分钟至少1个可切片段) |\n",
    "| 人味得分 | >3.5/5 (人工盲评) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
