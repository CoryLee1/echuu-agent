{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ•°æ®æ ‡æ³¨ â†’ echuuè‡ªåŠ¨ç›´æ’­ å®Œæ•´Pipeline\n",
    "\n",
    "## ç›®æ ‡\n",
    "1. å¤„ç†åŸå§‹æ•°æ® `vtuber_raw_clips_for_notebook_full_30_cleaned.jsonl`\n",
    "2. ç”Ÿæˆ `annotated_clips.json` ä¾›echuu notebookä½¿ç”¨\n",
    "3. æ”¯æŒå¿«é€Ÿæ¨¡å¼ï¼ˆæ— éœ€LLMï¼‰å’Œç²¾ç»†æ¨¡å¼ï¼ˆLLMæ ‡æ³¨ï¼‰\n",
    "\n",
    "## æ•°æ®æµ\n",
    "```\n",
    "åŸå§‹JSONL â†’ [æ ‡æ³¨Pipeline] â†’ annotated_clips.json â†’ [echuu Engine] â†’ è‡ªåŠ¨ç›´æ’­\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from collections import Counter, defaultdict\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "# è·¯å¾„é…ç½®\n",
    "DATA_DIR = Path(\"../../data\")\n",
    "RAW_DATA_PATH = DATA_DIR / \"vtuber_raw_clips_for_notebook_full_30_cleaned.jsonl\"\n",
    "OUTPUT_PATH = DATA_DIR / \"annotated_clips.json\"\n",
    "\n",
    "print(f\"åŸå§‹æ•°æ®: {RAW_DATA_PATH}\")\n",
    "print(f\"è¾“å‡ºè·¯å¾„: {OUTPUT_PATH}\")\n",
    "print(f\"æ•°æ®ç›®å½•å­˜åœ¨: {DATA_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: åŠ è½½å¹¶æ£€æŸ¥åŸå§‹æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_clips(path: str) -> List[Dict]:\n",
    "    \"\"\"åŠ è½½JSONLæ ¼å¼çš„åŸå§‹æ•°æ®\"\"\"\n",
    "    clips = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                clips.append(json.loads(line))\n",
    "    return clips\n",
    "\n",
    "# åŠ è½½æ•°æ®\n",
    "raw_clips = load_raw_clips(RAW_DATA_PATH)\n",
    "print(f\"âœ… åŠ è½½äº† {len(raw_clips)} ä¸ªclips\")\n",
    "\n",
    "# ç»Ÿè®¡\n",
    "zh_count = sum(1 for c in raw_clips if c.get(\"language\") == \"zh\")\n",
    "en_count = sum(1 for c in raw_clips if c.get(\"language\") == \"en\")\n",
    "print(f\"  - ä¸­æ–‡: {zh_count}\")\n",
    "print(f\"  - è‹±æ–‡: {en_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹æ•°æ®ç»“æ„\n",
    "sample = raw_clips[0]\n",
    "print(\"ğŸ“‹ æ•°æ®ç»“æ„:\")\n",
    "print(f\"  - clip_id: {sample.get('clip_id')}\")\n",
    "print(f\"  - source: {sample.get('source')}\")\n",
    "print(f\"  - language: {sample.get('language')}\")\n",
    "print(f\"  - duration: {sample.get('duration')}ç§’\")\n",
    "print(f\"  - title: {sample.get('title')}\")\n",
    "print(f\"  - notes: {list(sample.get('notes', {}).keys())}\")\n",
    "print(f\"  - transcript: {len(sample.get('transcript', []))} æ¡\")\n",
    "\n",
    "print(\"\\nğŸ“ Notesè¯¦æƒ…:\")\n",
    "for k, v in sample.get('notes', {}).items():\n",
    "    print(f\"  - {k}: {v[:60]}...\" if len(str(v)) > 60 else f\"  - {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: è¾…åŠ©å‡½æ•°å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_catchphrases(habit_str: str) -> List[str]:\n",
    "    \"\"\"ä»notes.habitå­—ç¬¦ä¸²ä¸­æå–å£ç™–åˆ—è¡¨\"\"\"\n",
    "    if not habit_str:\n",
    "        return []\n",
    "    # åŒ¹é…å¼•å·å†…çš„å†…å®¹ï¼ˆæ”¯æŒå¤šç§å¼•å·ï¼‰\n",
    "    pattern = r'[\"\\'""ã€Œ]([^\"\\'""ã€]+)[\"\\'""ã€]'\n",
    "    matches = re.findall(pattern, habit_str)\n",
    "    # æ¸…ç†å¹¶å»é‡\n",
    "    catchphrases = []\n",
    "    for m in matches:\n",
    "        clean = m.strip()\n",
    "        if clean and clean not in catchphrases:\n",
    "            catchphrases.append(clean)\n",
    "    return catchphrases\n",
    "\n",
    "\n",
    "def extract_skeleton(structure_str: str) -> str:\n",
    "    \"\"\"æå–å™äº‹éª¨æ¶\"\"\"\n",
    "    if not structure_str:\n",
    "        return \"\"\n",
    "    return structure_str.replace(\"->\", \"â†’\")\n",
    "\n",
    "\n",
    "def infer_trigger_from_notes(notes: Dict) -> str:\n",
    "    \"\"\"ä»notesæ¨æ–­ä¸»è¦è§¦å‘ç±»å‹\"\"\"\n",
    "    trigger_text = notes.get(\"trigger\", \"\").lower()\n",
    "    \n",
    "    if any(kw in trigger_text for kw in [\"sc\", \"æ‰“èµ\", \"ç¤¼ç‰©\", \"superchat\"]):\n",
    "        return \"sc\"\n",
    "    elif any(kw in trigger_text for kw in [\"å¼¹å¹•\", \"è§‚ä¼—\", \"é—®é¢˜\", \"æé—®\", \"chat\", \"comment\"]):\n",
    "        return \"danmaku\"\n",
    "    elif any(kw in trigger_text for kw in [\"å® ç‰©\", \"çŒ«\", \"ç‹—\", \"ç”»é¢\", \"å†…å®¹\"]):\n",
    "        return \"content\"\n",
    "    elif any(kw in trigger_text for kw in [\"è”åŠ¨\", \"èŠ‚ç›®\"]):\n",
    "        return \"self\"\n",
    "    else:\n",
    "        return \"self\"\n",
    "\n",
    "\n",
    "def infer_segment_type(text: str, language: str) -> Tuple[str, str]:\n",
    "    \"\"\"å¯å‘å¼æ¨æ–­segmentçš„attention_focuså’Œspeech_act\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # ä¸­æ–‡å…³é”®è¯\n",
    "    if language == \"zh\":\n",
    "        # attention_focus\n",
    "        if any(kw in text for kw in [\"ä½ ä»¬\", \"å¤§å®¶\", \"è§‚ä¼—\", \"æœ‹å‹ä»¬\"]):\n",
    "            attention = \"audience\"\n",
    "        elif any(kw in text for kw in [\"è°¢è°¢\", \"æ„Ÿè°¢\", \"SC\", \"æ‰“èµ\"]):\n",
    "            attention = \"specific\"\n",
    "        elif any(kw in text for kw in [\"çŒ«\", \"ç‹—\", \"å® ç‰©\"]):\n",
    "            attention = \"content\"\n",
    "        elif any(kw in text for kw in [\"ç›´æ’­\", \"ä»Šå¤©æ’­\", \"å¼€æ’­\"]):\n",
    "            attention = \"meta\"\n",
    "        else:\n",
    "            attention = \"self\"\n",
    "        \n",
    "        # speech_act\n",
    "        if any(kw in text for kw in [\"æˆ‘è®°å¾—\", \"é‚£æ—¶å€™\", \"å½“æ—¶\", \"ä»¥å‰\", \"æœ‰ä¸€æ¬¡\"]):\n",
    "            speech_act = \"narrate\"\n",
    "        elif any(kw in text for kw in [\"æˆ‘è§‰å¾—\", \"æˆ‘è®¤ä¸º\", \"åº”è¯¥\", \"å»ºè®®\"]):\n",
    "            speech_act = \"opine\"\n",
    "        elif \"ï¼Ÿ\" in text and len(text) < 50:\n",
    "            speech_act = \"elicit\"\n",
    "        elif any(kw in text for kw in [\"å¯¹\", \"æ˜¯çš„\", \"æ²¡é”™\"]):\n",
    "            speech_act = \"respond\"\n",
    "        else:\n",
    "            speech_act = \"narrate\"\n",
    "    else:\n",
    "        # è‹±æ–‡å…³é”®è¯\n",
    "        if any(kw in text_lower for kw in [\"you guys\", \"chat\", \"everyone\", \"y'all\"]):\n",
    "            attention = \"audience\"\n",
    "        elif any(kw in text_lower for kw in [\"thank\", \"thanks\", \"appreciate\"]):\n",
    "            attention = \"specific\"\n",
    "        else:\n",
    "            attention = \"self\"\n",
    "        \n",
    "        if any(kw in text_lower for kw in [\"i remember\", \"back then\", \"when i was\"]):\n",
    "            speech_act = \"narrate\"\n",
    "        elif any(kw in text_lower for kw in [\"i think\", \"i believe\", \"i feel like\"]):\n",
    "            speech_act = \"opine\"\n",
    "        elif \"?\" in text and len(text) < 100:\n",
    "            speech_act = \"elicit\"\n",
    "        else:\n",
    "            speech_act = \"narrate\"\n",
    "    \n",
    "    return attention, speech_act\n",
    "\n",
    "\n",
    "def find_catchphrase(text: str, catchphrases: List[str]) -> Optional[str]:\n",
    "    \"\"\"æŸ¥æ‰¾æ–‡æœ¬ä¸­å‡ºç°çš„å£ç™–\"\"\"\n",
    "    for cp in catchphrases:\n",
    "        if cp in text:\n",
    "            return cp\n",
    "    return None\n",
    "\n",
    "print(\"âœ… è¾…åŠ©å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•å£ç™–æå–\n",
    "test_habits = [\n",
    "    '\"å¯¹å§\"ã€\"æˆ‘è§‰å¾—\"',\n",
    "    '\"you know\"ã€\"like\"ã€\"I don\\'t know\"',\n",
    "    '\"æˆ‘è·Ÿä½ ä»¬è¯´\"ã€\"å¤©å“ª\"',\n",
    "]\n",
    "\n",
    "print(\"æµ‹è¯•å£ç™–æå–:\")\n",
    "for h in test_habits:\n",
    "    print(f\"  {h} â†’ {extract_catchphrases(h)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: å¿«é€Ÿè½¬æ¢ï¼ˆæ— éœ€LLMï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_convert_clip(clip: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    å¿«é€Ÿè½¬æ¢å•ä¸ªclipï¼ˆä¸è°ƒç”¨LLMï¼‰\n",
    "    ä½¿ç”¨å¯å‘å¼è§„åˆ™è¿›è¡Œsegmentåˆ‡åˆ†\n",
    "    \"\"\"\n",
    "    notes = clip.get(\"notes\", {})\n",
    "    catchphrases = extract_catchphrases(notes.get(\"habit\", \"\"))\n",
    "    skeleton = extract_skeleton(notes.get(\"structure\", \"\"))\n",
    "    main_trigger = infer_trigger_from_notes(notes)\n",
    "    language = clip.get(\"language\", \"zh\")\n",
    "    \n",
    "    # å¯å‘å¼segmentåˆ‡åˆ†\n",
    "    transcript = clip.get(\"transcript\", [])\n",
    "    segments = []\n",
    "    \n",
    "    # æŒ‰æ—¶é—´é—´éš”åˆ‡åˆ†ï¼ˆæ¯30ç§’å·¦å³ä¸€ä¸ªsegmentï¼‰\n",
    "    current_seg_texts = []\n",
    "    current_seg_start = 0\n",
    "    last_time = 0\n",
    "    \n",
    "    for item in transcript:\n",
    "        t = item.get(\"t\")\n",
    "        if t is None:\n",
    "            t = last_time\n",
    "        text = item.get(\"text\", \"\")\n",
    "        \n",
    "        # å¦‚æœæ—¶é—´è·¨åº¦è¶…è¿‡30ç§’æˆ–æ–‡æœ¬å¾ˆé•¿ï¼Œåˆ›å»ºæ–°segment\n",
    "        if (t - current_seg_start > 30 or len(\" \".join(current_seg_texts)) > 300) and current_seg_texts:\n",
    "            seg_text = \" \".join(current_seg_texts)\n",
    "            attention, speech_act = infer_segment_type(seg_text, language)\n",
    "            \n",
    "            segments.append({\n",
    "                \"id\": f\"seg_{len(segments)+1:02d}\",\n",
    "                \"start_time\": current_seg_start,\n",
    "                \"end_time\": t,\n",
    "                \"text\": seg_text,\n",
    "                \"attention_focus\": attention,\n",
    "                \"speech_act\": speech_act,\n",
    "                \"trigger\": main_trigger if len(segments) == 0 else \"prior\",\n",
    "                \"catchphrase\": find_catchphrase(seg_text, catchphrases),\n",
    "                \"emotion_shift\": False\n",
    "            })\n",
    "            \n",
    "            current_seg_texts = [text]\n",
    "            current_seg_start = t\n",
    "        else:\n",
    "            current_seg_texts.append(text)\n",
    "        \n",
    "        last_time = t\n",
    "    \n",
    "    # å¤„ç†æœ€åä¸€ä¸ªsegment\n",
    "    if current_seg_texts:\n",
    "        seg_text = \" \".join(current_seg_texts)\n",
    "        attention, speech_act = infer_segment_type(seg_text, language)\n",
    "        \n",
    "        segments.append({\n",
    "            \"id\": f\"seg_{len(segments)+1:02d}\",\n",
    "            \"start_time\": current_seg_start,\n",
    "            \"end_time\": clip.get(\"duration\", last_time),\n",
    "            \"text\": seg_text,\n",
    "            \"attention_focus\": attention,\n",
    "            \"speech_act\": speech_act,\n",
    "            \"trigger\": main_trigger if len(segments) == 0 else \"prior\",\n",
    "            \"catchphrase\": find_catchphrase(seg_text, catchphrases),\n",
    "            \"emotion_shift\": False\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"clip_id\": clip.get(\"clip_id\", \"\"),\n",
    "        \"source\": clip.get(\"source\", \"\"),\n",
    "        \"language\": language,\n",
    "        \"duration\": clip.get(\"duration\", 0),\n",
    "        \"title\": clip.get(\"title\", \"\"),\n",
    "        \"skeleton\": skeleton,\n",
    "        \"catchphrases\": catchphrases,\n",
    "        \"segments\": segments,\n",
    "        \"notes\": notes\n",
    "    }\n",
    "\n",
    "print(\"âœ… å¿«é€Ÿè½¬æ¢å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•å•ä¸ªclipè½¬æ¢\n",
    "test_clip = raw_clips[4]  # æµ·è‹”è…°æœå·åƒè®°\n",
    "converted = quick_convert_clip(test_clip)\n",
    "\n",
    "print(f\"ğŸ“‹ è½¬æ¢ç»“æœ: {converted['title']}\")\n",
    "print(f\"  - skeleton: {converted['skeleton']}\")\n",
    "print(f\"  - catchphrases: {converted['catchphrases']}\")\n",
    "print(f\"  - segmentsæ•°é‡: {len(converted['segments'])}\")\n",
    "\n",
    "print(\"\\nğŸ“ Segmentsé¢„è§ˆ:\")\n",
    "for seg in converted['segments'][:3]:\n",
    "    print(f\"  [{seg['id']}] {seg['start_time']:.0f}s-{seg['end_time']:.0f}s\")\n",
    "    print(f\"    focus={seg['attention_focus']}, act={seg['speech_act']}, trigger={seg['trigger']}\")\n",
    "    print(f\"    text: {seg['text'][:60]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: æ‰¹é‡è½¬æ¢å¹¶ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_quick_conversion(raw_clips: List[Dict], output_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    è¿è¡Œå¿«é€Ÿæ‰¹é‡è½¬æ¢\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”„ å¼€å§‹è½¬æ¢ {len(raw_clips)} ä¸ªclips...\")\n",
    "    \n",
    "    annotated = []\n",
    "    for i, clip in enumerate(raw_clips):\n",
    "        converted = quick_convert_clip(clip)\n",
    "        annotated.append(converted)\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"  å·²å¤„ç†: {i+1}/{len(raw_clips)}\")\n",
    "    \n",
    "    # ä¿å­˜\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(annotated, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # ç»Ÿè®¡\n",
    "    total_segments = sum(len(c[\"segments\"]) for c in annotated)\n",
    "    avg_segments = total_segments / len(annotated)\n",
    "    \n",
    "    print(f\"\\nâœ… è½¬æ¢å®Œæˆ!\")\n",
    "    print(f\"  - æ€»clips: {len(annotated)}\")\n",
    "    print(f\"  - æ€»segments: {total_segments}\")\n",
    "    print(f\"  - å¹³å‡segments/clip: {avg_segments:.1f}\")\n",
    "    print(f\"  - ä¿å­˜åˆ°: {output_path}\")\n",
    "    \n",
    "    return annotated\n",
    "\n",
    "# è¿è¡Œè½¬æ¢\n",
    "annotated_clips = run_quick_conversion(raw_clips, str(OUTPUT_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: æ•°æ®è´¨é‡æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»Ÿè®¡åˆ†å¸ƒ\n",
    "all_segments = []\n",
    "for clip in annotated_clips:\n",
    "    all_segments.extend(clip[\"segments\"])\n",
    "\n",
    "print(f\"ğŸ“Š æ•°æ®ç»Ÿè®¡ (å…±{len(all_segments)}ä¸ªsegments)\")\n",
    "\n",
    "# Attentionåˆ†å¸ƒ\n",
    "attention_dist = Counter(s[\"attention_focus\"] for s in all_segments)\n",
    "print(\"\\nAttention Focusåˆ†å¸ƒ:\")\n",
    "for k, v in sorted(attention_dist.items(), key=lambda x: -x[1]):\n",
    "    pct = v / len(all_segments) * 100\n",
    "    bar = \"â–ˆ\" * int(pct / 5) + \"â–‘\" * (20 - int(pct / 5))\n",
    "    print(f\"  {k:12} {bar} {pct:.1f}% ({v})\")\n",
    "\n",
    "# Speech Actåˆ†å¸ƒ\n",
    "speech_dist = Counter(s[\"speech_act\"] for s in all_segments)\n",
    "print(\"\\nSpeech Actåˆ†å¸ƒ:\")\n",
    "for k, v in sorted(speech_dist.items(), key=lambda x: -x[1]):\n",
    "    pct = v / len(all_segments) * 100\n",
    "    bar = \"â–ˆ\" * int(pct / 5) + \"â–‘\" * (20 - int(pct / 5))\n",
    "    print(f\"  {k:12} {bar} {pct:.1f}% ({v})\")\n",
    "\n",
    "# Triggeråˆ†å¸ƒ\n",
    "trigger_dist = Counter(s[\"trigger\"] for s in all_segments)\n",
    "print(\"\\nTriggeråˆ†å¸ƒ:\")\n",
    "for k, v in sorted(trigger_dist.items(), key=lambda x: -x[1]):\n",
    "    pct = v / len(all_segments) * 100\n",
    "    bar = \"â–ˆ\" * int(pct / 5) + \"â–‘\" * (20 - int(pct / 5))\n",
    "    print(f\"  {k:12} {bar} {pct:.1f}% ({v})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å£ç™–ç»Ÿè®¡\n",
    "all_catchphrases = []\n",
    "for clip in annotated_clips:\n",
    "    all_catchphrases.extend(clip.get(\"catchphrases\", []))\n",
    "\n",
    "cp_counter = Counter(all_catchphrases)\n",
    "print(\"ğŸ¤ å¸¸è§å£ç™– Top 15:\")\n",
    "for cp, count in cp_counter.most_common(15):\n",
    "    print(f\"  [{count}] \\\"{cp}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å™äº‹éª¨æ¶ç»Ÿè®¡\n",
    "skeletons = [clip[\"skeleton\"] for clip in annotated_clips if clip.get(\"skeleton\")]\n",
    "print(\"ğŸ“ å™äº‹éª¨æ¶ç¤ºä¾‹:\")\n",
    "for skel in skeletons[:10]:\n",
    "    print(f\"  â†’ {skel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: ä¸echuu notebooké›†æˆæµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡æ‹Ÿechuu notebookçš„PatternAnalyzerä½¿ç”¨æ–¹å¼\n",
    "class PatternAnalyzer:\n",
    "    \"\"\"ä»æ ‡æ³¨æ•°æ®ä¸­æå–æ¨¡å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, annotated_clips: List[Dict]):\n",
    "        self.clips = annotated_clips\n",
    "        self.all_segments = []\n",
    "        for clip in annotated_clips:\n",
    "            self.all_segments.extend(clip.get(\"segments\", []))\n",
    "    \n",
    "    def compute_attention_transitions(self) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"è®¡ç®—attentionè½¬ç§»æ¦‚ç‡\"\"\"\n",
    "        trans = defaultdict(lambda: defaultdict(int))\n",
    "        for clip in self.clips:\n",
    "            segs = clip.get(\"segments\", [])\n",
    "            for i in range(len(segs) - 1):\n",
    "                f = segs[i].get(\"attention_focus\", \"self\")\n",
    "                t = segs[i+1].get(\"attention_focus\", \"self\")\n",
    "                trans[f][t] += 1\n",
    "        \n",
    "        prob = {}\n",
    "        for f, tos in trans.items():\n",
    "            total = sum(tos.values())\n",
    "            prob[f] = {t: c/total for t, c in tos.items()}\n",
    "        return prob\n",
    "    \n",
    "    def extract_catchphrases(self, language: str = None) -> List[Tuple[str, int]]:\n",
    "        \"\"\"æå–å£ç™–\"\"\"\n",
    "        cps = []\n",
    "        for c in self.clips:\n",
    "            if language and c.get(\"language\") != language:\n",
    "                continue\n",
    "            cps.extend(c.get(\"catchphrases\", []))\n",
    "        return Counter(cps).most_common(20)\n",
    "    \n",
    "    def extract_hooks(self, language: str = None) -> List[str]:\n",
    "        \"\"\"æå–å¼€åœºç¤ºä¾‹\"\"\"\n",
    "        hooks = []\n",
    "        for c in self.clips:\n",
    "            if language and c.get(\"language\") != language:\n",
    "                continue\n",
    "            segs = c.get(\"segments\", [])\n",
    "            if segs:\n",
    "                hooks.append(segs[0].get(\"text\", \"\")[:100])\n",
    "        return hooks[:10]\n",
    "\n",
    "# æµ‹è¯•\n",
    "analyzer = PatternAnalyzer(annotated_clips)\n",
    "print(\"âœ… PatternAnalyzeråˆå§‹åŒ–æˆåŠŸ\")\n",
    "print(f\"  - clips: {len(analyzer.clips)}\")\n",
    "print(f\"  - segments: {len(analyzer.all_segments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•æ¨¡å¼åˆ†æ\n",
    "print(\"ğŸ”„ AttentionçŠ¶æ€è½¬ç§»çŸ©é˜µ:\")\n",
    "trans = analyzer.compute_attention_transitions()\n",
    "for from_state, to_states in trans.items():\n",
    "    top = sorted(to_states.items(), key=lambda x: -x[1])[:3]\n",
    "    print(f\"  {from_state:10} â†’ \" + \", \".join(f\"{t}:{p:.0%}\" for t, p in top))\n",
    "\n",
    "print(\"\\nğŸ¤ ä¸­æ–‡å£ç™– Top 10:\")\n",
    "for cp, count in analyzer.extract_catchphrases(\"zh\")[:10]:\n",
    "    print(f\"  [{count}] \\\"{cp}\\\"\")\n",
    "\n",
    "print(\"\\nğŸ“ ä¸­æ–‡å¼€åœºHookç¤ºä¾‹:\")\n",
    "for i, hook in enumerate(analyzer.extract_hooks(\"zh\")[:3], 1):\n",
    "    print(f\"  {i}. {hook[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: LLMç²¾ç»†æ ‡æ³¨ï¼ˆå¯é€‰ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMæ ‡æ³¨Promptæ¨¡æ¿\n",
    "LLM_ANNOTATION_PROMPT = '''ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç›´æ’­å†…å®¹åˆ†æå¸ˆã€‚è¯·å¯¹ä»¥ä¸‹ç›´æ’­åˆ‡ç‰‡è¿›è¡Œsegmentçº§åˆ«çš„æ ‡æ³¨ã€‚\n",
    "\n",
    "## åˆ‡ç‰‡ä¿¡æ¯\n",
    "- æ ‡é¢˜: {title}\n",
    "- è¯­è¨€: {language}\n",
    "- æ—¶é•¿: {duration}ç§’\n",
    "- å™äº‹ç»“æ„: {skeleton}\n",
    "- å£ç™–: {catchphrases}\n",
    "\n",
    "## è½¬å½•æ–‡æœ¬\n",
    "```\n",
    "{transcript}\n",
    "```\n",
    "\n",
    "## æ ‡æ³¨ç»´åº¦\n",
    "\n",
    "### attention_focusï¼ˆæ³¨æ„åŠ›æŒ‡å‘ï¼‰\n",
    "- `self`: è‡ªè¨€è‡ªè¯­/è®²è‡ªå·±çš„äº‹\n",
    "- `audience`: ç›´æ¥å¯¹è§‚ä¼—è¯´è¯ï¼ˆä½ ä»¬ã€å¤§å®¶ï¼‰\n",
    "- `specific`: å›åº”ç‰¹å®šè§‚ä¼—ï¼ˆè¯»SCã€ç‚¹åï¼‰\n",
    "- `content`: ä¸“æ³¨äºå†…å®¹ï¼ˆé€—çŒ«ã€çœ‹ç”»é¢ï¼‰\n",
    "- `meta`: è°ˆè®ºç›´æ’­æœ¬èº«\n",
    "\n",
    "### speech_actï¼ˆè¯è¯­è¡Œä¸ºï¼‰\n",
    "- `narrate`: å™äº‹ï¼Œè®²æ•…äº‹\n",
    "- `opine`: è¡¨æ€ï¼Œå‘è¡¨è§‚ç‚¹\n",
    "- `respond`: å›åº”ï¼Œå›ç­”é—®é¢˜\n",
    "- `elicit`: å¼•å‡ºï¼Œæé—®ã€æŠ›æ¢—\n",
    "- `pivot`: è½¬æŠ˜ï¼Œè¯é¢˜è½¬æ¢\n",
    "- `backchannel`: å¡«å……ï¼Œè¯­æ°”è¯\n",
    "\n",
    "### triggerï¼ˆè§¦å‘æºï¼‰\n",
    "- `sc`: SC/æ‰“èµè§¦å‘\n",
    "- `danmaku`: å¼¹å¹•è§¦å‘\n",
    "- `self`: è‡ªå‘\n",
    "- `content`: å†…å®¹è§¦å‘\n",
    "- `prior`: æ‰¿æ¥ä¸Šæ–‡\n",
    "\n",
    "## è¾“å‡ºæ ¼å¼\n",
    "è¾“å‡ºJSON:\n",
    "```json\n",
    "{{\n",
    "  \"segments\": [\n",
    "    {{\n",
    "      \"id\": \"seg_01\",\n",
    "      \"start_time\": 0,\n",
    "      \"end_time\": 15,\n",
    "      \"text\": \"segmentæ–‡æœ¬\",\n",
    "      \"attention_focus\": \"specific\",\n",
    "      \"speech_act\": \"respond\",\n",
    "      \"trigger\": \"sc\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "'''\n",
    "\n",
    "print(\"âœ… LLMæ ‡æ³¨Promptæ¨¡æ¿å®šä¹‰å®Œæˆ\")\n",
    "print(\"\\nå¦‚éœ€ä½¿ç”¨LLMç²¾ç»†æ ‡æ³¨ï¼Œè¯·é…ç½®API Keyå¹¶è¿è¡Œä¸‹é¢çš„ä»£ç å—\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMæ ‡æ³¨ï¼ˆéœ€è¦é…ç½®API Keyï¼‰\n",
    "# å–æ¶ˆæ³¨é‡Šä»¥ä¸‹ä»£ç å¹¶é…ç½®API Key\n",
    "\n",
    "'''\n",
    "import os\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "import anthropic\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "def llm_annotate_clip(clip: Dict) -> Dict:\n",
    "    # å‡†å¤‡transcript\n",
    "    transcript_lines = []\n",
    "    for item in clip.get(\"transcript\", []):\n",
    "        t = item.get(\"t\", 0)\n",
    "        if t is not None:\n",
    "            minutes = int(t // 60)\n",
    "            seconds = int(t % 60)\n",
    "            transcript_lines.append(f\"{minutes}:{seconds:02d} {item.get('text', '')}\")\n",
    "    \n",
    "    notes = clip.get(\"notes\", {})\n",
    "    prompt = LLM_ANNOTATION_PROMPT.format(\n",
    "        title=clip.get(\"title\", \"\"),\n",
    "        language=clip.get(\"language\", \"zh\"),\n",
    "        duration=clip.get(\"duration\", 0),\n",
    "        skeleton=extract_skeleton(notes.get(\"structure\", \"\")),\n",
    "        catchphrases=extract_catchphrases(notes.get(\"habit\", \"\")),\n",
    "        transcript=\"\\n\".join(transcript_lines)\n",
    "    )\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=4096,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    # è§£æå“åº”\n",
    "    content = response.content[0].text\n",
    "    if \"```json\" in content:\n",
    "        json_str = content.split(\"```json\")[1].split(\"```\")[0]\n",
    "    else:\n",
    "        json_str = content\n",
    "    \n",
    "    result = json.loads(json_str.strip())\n",
    "    \n",
    "    return {\n",
    "        \"clip_id\": clip.get(\"clip_id\", \"\"),\n",
    "        \"source\": clip.get(\"source\", \"\"),\n",
    "        \"language\": clip.get(\"language\", \"zh\"),\n",
    "        \"duration\": clip.get(\"duration\", 0),\n",
    "        \"title\": clip.get(\"title\", \"\"),\n",
    "        \"skeleton\": extract_skeleton(notes.get(\"structure\", \"\")),\n",
    "        \"catchphrases\": extract_catchphrases(notes.get(\"habit\", \"\")),\n",
    "        \"segments\": result.get(\"segments\", []),\n",
    "        \"notes\": notes\n",
    "    }\n",
    "\n",
    "# æµ‹è¯•å•ä¸ªclip\n",
    "test_result = llm_annotate_clip(raw_clips[0])\n",
    "print(f\"LLMæ ‡æ³¨ç»“æœ: {len(test_result['segments'])} segments\")\n",
    "'''\n",
    "\n",
    "print(\"âš ï¸ LLMæ ‡æ³¨ä»£ç å·²æ³¨é‡Šï¼Œéœ€è¦æ—¶è¯·å–æ¶ˆæ³¨é‡Šå¹¶é…ç½®API Key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: æ€»ç»“ä¸ä¸‹ä¸€æ­¥\n",
    "\n",
    "### å·²å®Œæˆ\n",
    "1. âœ… åŠ è½½åŸå§‹JSONLæ•°æ®ï¼ˆ30ä¸ªclipsï¼‰\n",
    "2. âœ… å¿«é€Ÿè½¬æ¢ä¸ºannotatedæ ¼å¼\n",
    "3. âœ… ä¿å­˜åˆ° `annotated_clips.json`\n",
    "4. âœ… éªŒè¯æ•°æ®å¯è¢«PatternAnalyzerä½¿ç”¨\n",
    "\n",
    "### æ•°æ®è´¨é‡\n",
    "- å¿«é€Ÿæ¨¡å¼ï¼šå¯å‘å¼è§„åˆ™æ ‡æ³¨ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•\n",
    "- å¦‚éœ€æ›´ç²¾ç¡®çš„æ ‡æ³¨ï¼Œå»ºè®®ä½¿ç”¨LLMæ ‡æ³¨\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "1. è¿è¡Œ `echuu_notebook (1).ipynb` ä½¿ç”¨ç”Ÿæˆçš„æ•°æ®\n",
    "2. æ ¹æ®éœ€è¦è°ƒæ•´segmentåˆ‡åˆ†è§„åˆ™\n",
    "3. å¯é€‰ï¼šäººå·¥æ ¡æ­£éƒ¨åˆ†æ ‡æ³¨ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ‰ æ•°æ®æ ‡æ³¨Pipelineå®Œæˆ!\")\n",
    "print(f\"\\nè¾“å‡ºæ–‡ä»¶: {OUTPUT_PATH}\")\n",
    "print(f\"\\nä¸‹ä¸€æ­¥: è¿è¡Œ echuu_notebook ä½¿ç”¨ç”Ÿæˆçš„æ•°æ®\")\n",
    "print(\"  1. ç¡®ä¿ annotated_clips.json åœ¨æ­£ç¡®ä½ç½®\")\n",
    "print(\"  2. åœ¨echuu notebookä¸­åŠ è½½æ•°æ®\")\n",
    "print(\"  3. æµ‹è¯•è‡ªåŠ¨ç›´æ’­ç”Ÿæˆ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
