{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VTuber Auto-Performance: Multi-Agent Edition\n",
    "\n",
    "## 实验目标\n",
    "\n",
    "**核心假设**: 真人主播的\"人味\"可以被结构化提取,迁移到AI主播上。\n",
    "\n",
    "**新增特性**:\n",
    "- Multi-Agent协作架构 (Planner → Performer → Director)\n",
    "- Interruption Cost机制 (让AI学会\"选择性忽略\")\n",
    "- Inner Monologue可视化 (暴露决策过程)\n",
    "\n",
    "## 实验流程\n",
    "\n",
    "```\n",
    "Phase 1: 数据标注 -> Phase 2: 模式提炼 -> Phase 3: Multi-Agent执行 -> Phase 4: 结果分析\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai anthropic langgraph -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Optional, Dict, TypedDict\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "from collections import Counter, defaultdict\n",
    "from openai import OpenAI\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "print(\"✅ 依赖加载完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Schema定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema定义\n",
    "class AttentionFocus(str, Enum):\n",
    "    SELF = \"self\"\n",
    "    AUDIENCE = \"audience\"\n",
    "    SPECIFIC = \"specific\"\n",
    "    CONTENT = \"content\"\n",
    "    META = \"meta\"\n",
    "\n",
    "class SpeechAct(str, Enum):\n",
    "    NARRATE = \"narrate\"\n",
    "    OPINE = \"opine\"\n",
    "    RESPOND = \"respond\"\n",
    "    ELICIT = \"elicit\"\n",
    "    PIVOT = \"pivot\"\n",
    "    BACKCHANNEL = \"backchannel\"\n",
    "\n",
    "class Trigger(str, Enum):\n",
    "    SC = \"sc\"\n",
    "    DANMAKU = \"danmaku\"\n",
    "    SELF_INIT = \"self\"\n",
    "    CONTENT = \"content\"\n",
    "    PRIOR = \"prior\"\n",
    "\n",
    "print(\"✅ Schema定义完成\")\n",
    "print(f\"  AttentionFocus: {[e.value for e in AttentionFocus]}\")\n",
    "print(f\"  SpeechAct: {[e.value for e in SpeechAct]}\")\n",
    "print(f\"  Trigger: {[e.value for e in Trigger]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 核心数据结构: Narrative Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NarrativeNode:\n",
    "    \"\"\"叙事节点 - 包含打断代价的执行单元\"\"\"\n",
    "    stage: str                    # Hook, Build-up, Climax, Resolution\n",
    "    focus: str                    # self, audience, content\n",
    "    goal: str                     # 核心任务描述\n",
    "    interruption_cost: float      # 0.0-1.0: 被打断的代价\n",
    "    speech_act_hint: List[str]    # 推荐的SpeechActs\n",
    "    duration_hint: int            # 建议时长(秒)\n",
    "    \n",
    "    def get_current_cost(self, elapsed_ratio: float) -> float:\n",
    "        \"\"\"节点快结束时,cost自动降低\"\"\"\n",
    "        if elapsed_ratio > 0.8:\n",
    "            return self.interruption_cost * 0.5\n",
    "        return self.interruption_cost\n",
    "\n",
    "print(\"✅ NarrativeNode定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# LLM配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM配置 - 改成你的API Key\n",
    "LLM_CONFIG = {\n",
    "    \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\", \"\"),\n",
    "    \"base_url\": \"https://api.anthropic.com/v1/\",\n",
    "    \"model\": \"claude-sonnet-4-20250514\",\n",
    "}\n",
    "\n",
    "def call_llm(prompt: str, max_tokens: int = 4096, temperature: float = 0.2) -> str:\n",
    "    \"\"\"统一的LLM调用接口\"\"\"\n",
    "    client = OpenAI(\n",
    "        api_key=LLM_CONFIG[\"api_key\"],\n",
    "        base_url=LLM_CONFIG[\"base_url\"],\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=LLM_CONFIG[\"model\"],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def robust_json_parse(text: str) -> dict:\n",
    "    \"\"\"鲁棒的JSON解析\"\"\"\n",
    "    text = re.sub(r'```json\\s*', '', text)\n",
    "    text = re.sub(r'```\\s*$', '', text)\n",
    "    text = text.replace('"', '\"').replace('"', '\"')\n",
    "    text = text.replace(''', \"'\").replace(''', \"'\")\n",
    "    \n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        lines = text.split('\\n')\n",
    "        for i, line in enumerate(lines):\n",
    "            if '\"text\":' in line:\n",
    "                match = re.search(r'\"text\":\\s*\"(.*?)\"(?=\\s*,|\\s*})', line)\n",
    "                if match:\n",
    "                    content = match.group(1)\n",
    "                    fixed = content.replace('\\\\\"', '###ESCAPED###')\n",
    "                    fixed = fixed.replace('\"', '\\\\\"')\n",
    "                    fixed = fixed.replace('###ESCAPED###', '\\\\\"')\n",
    "                    lines[i] = line.replace(content, fixed)\n",
    "        return json.loads('\\n'.join(lines))\n",
    "\n",
    "print(\"✅ LLM配置完成\")\n",
    "print(f\"  Model: {LLM_CONFIG['model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 1: 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_timestamp(ts: str) -> float:\n",
    "    parts = ts.strip().split(':')\n",
    "    if len(parts) == 2:\n",
    "        return int(parts[0]) * 60 + float(parts[1])\n",
    "    elif len(parts) == 3:\n",
    "        return int(parts[0]) * 3600 + int(parts[1]) * 60 + float(parts[2])\n",
    "    return 0.0\n",
    "\n",
    "def parse_raw_clips_markdown(md_content: str) -> List[dict]:\n",
    "    \"\"\"解析markdown格式的raw clips\"\"\"\n",
    "    clips = []\n",
    "    current_clip = None\n",
    "    current_section = None\n",
    "    transcript_lines = []\n",
    "    notes_lines = []\n",
    "    in_code_block = False\n",
    "    \n",
    "    for line in md_content.split('\\n'):\n",
    "        if line.strip() == '```':\n",
    "            in_code_block = not in_code_block\n",
    "            continue\n",
    "        \n",
    "        if line.startswith('## clip_'):\n",
    "            if current_clip:\n",
    "                current_clip['transcript_lines'] = transcript_lines\n",
    "                current_clip['notes'] = '\\n'.join(notes_lines)\n",
    "                clips.append(current_clip)\n",
    "            clip_id = line.replace('## ', '').strip()\n",
    "            current_clip = {'id': clip_id, 'source': '', 'language': 'zh', \n",
    "                          'duration_sec': 120, 'title': ''}\n",
    "            transcript_lines = []\n",
    "            notes_lines = []\n",
    "            current_section = None\n",
    "            continue\n",
    "        \n",
    "        if not current_clip:\n",
    "            continue\n",
    "        \n",
    "        if line.startswith('- **source**:'):\n",
    "            current_clip['source'] = line.split(':', 1)[1].strip()\n",
    "        elif line.startswith('- **language**:'):\n",
    "            current_clip['language'] = line.split(':', 1)[1].strip()\n",
    "        elif line.startswith('- **duration**:'):\n",
    "            try:\n",
    "                current_clip['duration_sec'] = int(line.split(':', 1)[1].strip())\n",
    "            except:\n",
    "                pass\n",
    "        elif line.startswith('- **title**:'):\n",
    "            current_clip['title'] = line.split(':', 1)[1].strip()\n",
    "        elif line.startswith('### transcript'):\n",
    "            current_section = 'transcript'\n",
    "        elif line.startswith('### notes'):\n",
    "            current_section = 'notes'\n",
    "        elif current_section == 'transcript' and in_code_block and line.strip():\n",
    "            match = re.match(r'^(\\d{1,2}:\\d{2})\\s+(.+)$', line.strip())\n",
    "            if match:\n",
    "                transcript_lines.append({\n",
    "                    'time': parse_timestamp(match.group(1)), \n",
    "                    'text': match.group(2)\n",
    "                })\n",
    "            elif transcript_lines:\n",
    "                transcript_lines[-1]['text'] += ' ' + line.strip()\n",
    "        elif current_section == 'notes' and line.strip() and not line.startswith('#'):\n",
    "            notes_lines.append(line.strip())\n",
    "    \n",
    "    if current_clip:\n",
    "        current_clip['transcript_lines'] = transcript_lines\n",
    "        current_clip['notes'] = '\\n'.join(notes_lines)\n",
    "        clips.append(current_clip)\n",
    "    \n",
    "    return clips\n",
    "\n",
    "print(\"✅ 数据解析器定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 2: Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternAnalyzer:\n",
    "    def __init__(self, clips: list):\n",
    "        self.clips = clips\n",
    "        self.all_segments = []\n",
    "        for clip in clips:\n",
    "            segs = clip.get('segments', []) if isinstance(clip, dict) else clip.segments\n",
    "            self.all_segments.extend(segs)\n",
    "    \n",
    "    def compute_attention_transition_matrix(self) -> dict:\n",
    "        transitions = defaultdict(lambda: defaultdict(int))\n",
    "        for clip in self.clips:\n",
    "            segs = clip.get('segments', []) if isinstance(clip, dict) else clip.segments\n",
    "            for i in range(len(segs) - 1):\n",
    "                f = segs[i].get('attention_focus', 'self') if isinstance(segs[i], dict) else segs[i].attention_focus.value\n",
    "                t = segs[i+1].get('attention_focus', 'self') if isinstance(segs[i+1], dict) else segs[i+1].attention_focus.value\n",
    "                transitions[f][t] += 1\n",
    "        \n",
    "        prob = {}\n",
    "        for f, tos in transitions.items():\n",
    "            total = sum(tos.values())\n",
    "            prob[f] = {t: c/total for t, c in tos.items()}\n",
    "        return prob\n",
    "    \n",
    "    def compute_trigger_speech_act_distribution(self) -> dict:\n",
    "        dist = defaultdict(lambda: defaultdict(int))\n",
    "        for seg in self.all_segments:\n",
    "            tr = seg.get('trigger', 'self') if isinstance(seg, dict) else seg.trigger.value\n",
    "            sa = seg.get('speech_act', 'narrate') if isinstance(seg, dict) else seg.speech_act.value\n",
    "            dist[tr][sa] += 1\n",
    "        \n",
    "        prob = {}\n",
    "        for tr, acts in dist.items():\n",
    "            total = sum(acts.values())\n",
    "            prob[tr] = {a: c/total for a, c in acts.items()}\n",
    "        return prob\n",
    "    \n",
    "    def extract_catchphrases(self):\n",
    "        cps = []\n",
    "        for c in self.clips:\n",
    "            cp = c.get('catchphrases', []) if isinstance(c, dict) else c.catchphrases\n",
    "            if cp:\n",
    "                cps.extend(cp)\n",
    "        return Counter(cps).most_common(20)\n",
    "    \n",
    "    def infer_baseline_costs(self) -> dict:\n",
    "        \"\"\"从标注数据推断baseline cost值\"\"\"\n",
    "        ignore_rates = defaultdict(lambda: {'ignored': 0, 'total': 0})\n",
    "        \n",
    "        for seg in self.all_segments:\n",
    "            focus = seg.get('attention_focus', 'self')\n",
    "            trigger = seg.get('trigger', 'self')\n",
    "            \n",
    "            if trigger == 'danmaku':\n",
    "                ignore_rates[focus]['total'] += 1\n",
    "                if seg.get('speech_act') != 'respond':\n",
    "                    ignore_rates[focus]['ignored'] += 1\n",
    "        \n",
    "        baseline_costs = {}\n",
    "        for focus, stats in ignore_rates.items():\n",
    "            if stats['total'] > 0:\n",
    "                baseline_costs[focus] = stats['ignored'] / stats['total']\n",
    "            else:\n",
    "                baseline_costs[focus] = 0.5\n",
    "        \n",
    "        return baseline_costs\n",
    "\n",
    "print(\"✅ PatternAnalyzer定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 3: Multi-Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceState(TypedDict):\n",
    "    \"\"\"Multi-Agent共享状态\"\"\"\n",
    "    oc_setting: str\n",
    "    topic: str\n",
    "    skeleton: List[NarrativeNode]\n",
    "    current_node_index: int\n",
    "    danmaku_stream: List[dict]\n",
    "    performance_log: List[dict]\n",
    "    inner_monologues: List[str]\n",
    "    elapsed_time: float\n",
    "    baseline_costs: dict\n",
    "\n",
    "print(\"✅ State定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NarrativePlanner:\n",
    "    \"\"\"Agent 1: 叙事策划师\"\"\"\n",
    "    \n",
    "    def __init__(self, analyzer: PatternAnalyzer):\n",
    "        self.analyzer = analyzer\n",
    "        self.baseline_costs = analyzer.infer_baseline_costs() if analyzer else {}\n",
    "        \n",
    "        # 硬编码3个模板骨架\n",
    "        self.templates = {\n",
    "            \"confessional\": [\n",
    "                NarrativeNode(\"Hook\", \"audience\", \"建立悬念/不寻常的开头\", 0.3, [\"elicit\", \"narrate\"], 20),\n",
    "                NarrativeNode(\"Build-up\", \"self\", \"铺垫细节/背景故事\", 0.6, [\"narrate\"], 40),\n",
    "                NarrativeNode(\"Climax\", \"self\", \"核心情绪爆发/秘密揭露\", 0.95, [\"narrate\", \"pivot\"], 30),\n",
    "                NarrativeNode(\"Resolution\", \"audience\", \"升华/寻求共鸣\", 0.4, [\"opine\", \"elicit\"], 30)\n",
    "            ],\n",
    "            \"debate\": [\n",
    "                NarrativeNode(\"Hook\", \"audience\", \"抛出争议话题\", 0.2, [\"elicit\", \"opine\"], 15),\n",
    "                NarrativeNode(\"Build-up\", \"content\", \"展示不同观点\", 0.3, [\"narrate\", \"opine\"], 35),\n",
    "                NarrativeNode(\"Climax\", \"audience\", \"与观众激烈互动\", 0.2, [\"respond\", \"opine\"], 50),\n",
    "                NarrativeNode(\"Resolution\", \"self\", \"总结立场\", 0.5, [\"opine\"], 20)\n",
    "            ],\n",
    "            \"insight\": [\n",
    "                NarrativeNode(\"Hook\", \"content\", \"提出有趣问题\", 0.4, [\"elicit\"], 15),\n",
    "                NarrativeNode(\"Build-up\", \"content\", \"理论/知识铺垫\", 0.7, [\"narrate\"], 50),\n",
    "                NarrativeNode(\"Climax\", \"self\", \"个人见解/经验\", 0.6, [\"opine\", \"narrate\"], 35),\n",
    "                NarrativeNode(\"Resolution\", \"audience\", \"实用建议\", 0.3, [\"opine\", \"elicit\"], 20)\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def plan(self, state: PerformanceState) -> PerformanceState:\n",
    "        \"\"\"生成带cost的skeleton\"\"\"\n",
    "        oc = state['oc_setting']\n",
    "        topic = state['topic']\n",
    "        \n",
    "        # 1. 选择模板\n",
    "        template_key = \"confessional\"\n",
    "        if any(w in topic.lower() for w in ['辩论', 'debate', '争议', '观点']):\n",
    "            template_key = \"debate\"\n",
    "        elif any(w in topic.lower() for w in ['分享', '技巧', '知识', 'insight']):\n",
    "            template_key = \"insight\"\n",
    "        \n",
    "        skeleton = [NarrativeNode(\n",
    "            n.stage, n.focus, n.goal, n.interruption_cost, \n",
    "            n.speech_act_hint, n.duration_hint\n",
    "        ) for n in self.templates[template_key]]\n",
    "        \n",
    "        # 2. 个性化调整cost\n",
    "        adjustment_prompt = f\"\"\"分析这个VTuber的性格特征:\n",
    "{oc}\n",
    "\n",
    "他们在讨论\"{topic}\"这个话题时,到了故事高潮阶段,会多大程度上忽略弹幕继续讲述?\n",
    "\n",
    "请给出0.0-1.0的数值:\n",
    "- 0.0 = 完全不介意被打断,很随性\n",
    "- 0.5 = 会权衡,但可以被吸引走\n",
    "- 1.0 = 绝对要讲完,谁都别想打断\n",
    "\n",
    "只输出数字,不要解释。\"\"\"\n",
    "        \n",
    "        try:\n",
    "            adjustment = float(call_llm(adjustment_prompt, max_tokens=10, temperature=0.1).strip())\n",
    "            adjustment = max(0.0, min(1.0, adjustment))\n",
    "            \n",
    "            for node in skeleton:\n",
    "                if node.stage == \"Climax\":\n",
    "                    node.interruption_cost = adjustment\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 3. 为每个节点生成具体目标\n",
    "        for node in skeleton:\n",
    "            goal_prompt = f\"\"\"VTuber设定: {oc}\n",
    "话题: {topic}\n",
    "阶段: {node.stage}\n",
    "\n",
    "为这个阶段生成一个简短的叙事目标(20字内),例如:\n",
    "- \"用自嘲开场吸引注意\"\n",
    "- \"讲述童年创伤经历\"\n",
    "- \"引导观众分享经验\"\n",
    "\n",
    "只输出目标,不要解释:\"\"\"\n",
    "            \n",
    "            try:\n",
    "                node.goal = call_llm(goal_prompt, max_tokens=50, temperature=0.7).strip()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        state['skeleton'] = skeleton\n",
    "        state['baseline_costs'] = self.baseline_costs\n",
    "        state['current_node_index'] = 0\n",
    "        return state\n",
    "\n",
    "print(\"✅ NarrativePlanner定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformerAgent:\n",
    "    \"\"\"Agent 2: 表演执行官\"\"\"\n",
    "    \n",
    "    def decide(self, state: PerformanceState) -> PerformanceState:\n",
    "        \"\"\"实时决策: 继续剧本 vs 回应弹幕\"\"\"\n",
    "        if state['current_node_index'] >= len(state['skeleton']):\n",
    "            return state\n",
    "        \n",
    "        node = state['skeleton'][state['current_node_index']]\n",
    "        recent_danmaku = state['danmaku_stream'][-5:] if state['danmaku_stream'] else []\n",
    "        \n",
    "        # 1. 评估弹幕紧急度\n",
    "        urgency = self._evaluate_urgency(recent_danmaku)\n",
    "        \n",
    "        # 2. 计算当前cost\n",
    "        elapsed_in_node = state['elapsed_time'] - sum(\n",
    "            state['skeleton'][i].duration_hint \n",
    "            for i in range(state['current_node_index'])\n",
    "        )\n",
    "        elapsed_ratio = elapsed_in_node / max(node.duration_hint, 1)\n",
    "        current_cost = node.get_current_cost(elapsed_ratio)\n",
    "        \n",
    "        # 3. Agency决策公式\n",
    "        decision_value = urgency - current_cost\n",
    "        \n",
    "        # 4. 生成台词\n",
    "        if decision_value > 0.3:\n",
    "            decision_type = \"RESPOND\"\n",
    "            speech = self._generate_response(node, recent_danmaku, state)\n",
    "        else:\n",
    "            decision_type = \"CONTINUE\"\n",
    "            speech = self._generate_script_speech(node, state)\n",
    "        \n",
    "        # 5. 记录\n",
    "        state['performance_log'].append({\n",
    "            \"time\": state['elapsed_time'],\n",
    "            \"node\": node.stage,\n",
    "            \"decision\": decision_type,\n",
    "            \"speech\": speech,\n",
    "            \"urgency\": urgency,\n",
    "            \"cost\": current_cost,\n",
    "            \"decision_value\": decision_value\n",
    "        })\n",
    "        \n",
    "        # 6. 更新时间和节点\n",
    "        state['elapsed_time'] += 10\n",
    "        if state['elapsed_time'] >= sum(n.duration_hint for n in state['skeleton'][:state['current_node_index']+1]):\n",
    "            state['current_node_index'] += 1\n",
    "        \n",
    "        return state\n",