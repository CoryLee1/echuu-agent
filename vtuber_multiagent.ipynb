{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VTuber Auto-Performance: Multi-Agent Edition\n",
    "\n",
    "## å®éªŒç›®æ ‡\n",
    "\n",
    "**æ ¸å¿ƒå‡è®¾**: çœŸäººä¸»æ’­çš„\"äººå‘³\"å¯ä»¥è¢«ç»“æ„åŒ–æå–,è¿ç§»åˆ°AIä¸»æ’­ä¸Šã€‚\n",
    "\n",
    "**æ–°å¢ç‰¹æ€§**:\n",
    "- Multi-Agentåä½œæ¶æ„ (Planner â†’ Performer â†’ Director)\n",
    "- Interruption Costæœºåˆ¶ (è®©AIå­¦ä¼š\"é€‰æ‹©æ€§å¿½ç•¥\")\n",
    "- Inner Monologueå¯è§†åŒ– (æš´éœ²å†³ç­–è¿‡ç¨‹)\n",
    "\n",
    "## å®éªŒæµç¨‹\n",
    "\n",
    "```\n",
    "Phase 1: æ•°æ®æ ‡æ³¨ -> Phase 2: æ¨¡å¼æç‚¼ -> Phase 3: Multi-Agentæ‰§è¡Œ -> Phase 4: ç»“æœåˆ†æ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai anthropic langgraph -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Tuple, Optional, Dict, TypedDict\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass, field\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Optional, Dict, TypedDict\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "from collections import Counter, defaultdict\n",
    "from openai import OpenAI\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "print(\"âœ… ä¾èµ–åŠ è½½å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Schemaå®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schemaå®šä¹‰\n",
    "class AttentionFocus(str, Enum):\n",
    "    SELF = \"self\"\n",
    "    AUDIENCE = \"audience\"\n",
    "    SPECIFIC = \"specific\"\n",
    "    CONTENT = \"content\"\n",
    "    META = \"meta\"\n",
    "\n",
    "class SpeechAct(str, Enum):\n",
    "    NARRATE = \"narrate\"\n",
    "    OPINE = \"opine\"\n",
    "    RESPOND = \"respond\"\n",
    "    ELICIT = \"elicit\"\n",
    "    PIVOT = \"pivot\"\n",
    "    BACKCHANNEL = \"backchannel\"\n",
    "\n",
    "class Trigger(str, Enum):\n",
    "    SC = \"sc\"\n",
    "    DANMAKU = \"danmaku\"\n",
    "    SELF_INIT = \"self\"\n",
    "    CONTENT = \"content\"\n",
    "    PRIOR = \"prior\"\n",
    "\n",
    "print(\"âœ… Schemaå®šä¹‰å®Œæˆ\")\n",
    "print(f\"  AttentionFocus: {[e.value for e in AttentionFocus]}\")\n",
    "print(f\"  SpeechAct: {[e.value for e in SpeechAct]}\")\n",
    "print(f\"  Trigger: {[e.value for e in Trigger]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# æ ¸å¿ƒæ•°æ®ç»“æ„: Narrative Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NarrativeNode:\n",
    "    \"\"\"å™äº‹èŠ‚ç‚¹ - åŒ…å«æ‰“æ–­ä»£ä»·çš„æ‰§è¡Œå•å…ƒ\"\"\"\n",
    "    stage: str                    # Hook, Build-up, Climax, Resolution\n",
    "    focus: str                    # self, audience, content\n",
    "    goal: str                     # æ ¸å¿ƒä»»åŠ¡æè¿°\n",
    "    interruption_cost: float      # 0.0-1.0: è¢«æ‰“æ–­çš„ä»£ä»·\n",
    "    speech_act_hint: List[str]    # æ¨èçš„SpeechActs\n",
    "    duration_hint: int            # å»ºè®®æ—¶é•¿(ç§’)\n",
    "    \n",
    "    def get_current_cost(self, elapsed_ratio: float) -> float:\n",
    "        \"\"\"èŠ‚ç‚¹å¿«ç»“æŸæ—¶,costè‡ªåŠ¨é™ä½\"\"\"\n",
    "        if elapsed_ratio > 0.8:\n",
    "            return self.interruption_cost * 0.5\n",
    "        return self.interruption_cost\n",
    "\n",
    "print(\"âœ… NarrativeNodeå®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# LLMé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMé…ç½® - æ”¹æˆä½ çš„API Key\n",
    "LLM_CONFIG = {\n",
    "    \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\", \"\"),\n",
    "    \"base_url\": \"https://api.anthropic.com/v1/\",\n",
    "    \"model\": \"claude-sonnet-4-20250514\",\n",
    "}\n",
    "\n",
    "def call_llm(prompt: str, max_tokens: int = 4096, temperature: float = 0.2) -> str:\n",
    "    \"\"\"ç»Ÿä¸€çš„LLMè°ƒç”¨æ¥å£\"\"\"\n",
    "    client = OpenAI(\n",
    "        api_key=LLM_CONFIG[\"api_key\"],\n",
    "        base_url=LLM_CONFIG[\"base_url\"],\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=LLM_CONFIG[\"model\"],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def robust_json_parse(text: str) -> dict:\n",
    "    \"\"\"é²æ£’çš„JSONè§£æ\"\"\"\n",
    "    text = re.sub(r'```json\\s*', '', text)\n",
    "    text = re.sub(r'```\\s*$', '', text)\n",
    "    text = text.replace('\"', '\"').replace('\"', '\"')\n",
    "    text = text.replace(''', \"'\").replace(''', \"'\")\n",
    "    \n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        lines = text.split('\\n')\n",
    "        for i, line in enumerate(lines):\n",
    "            if '\"text\":' in line:\n",
    "                match = re.search(r'\"text\":\\s*\"(.*?)\"(?=\\s*,|\\s*})', line)\n",
    "                if match:\n",
    "                    content = match.group(1)\n",
    "                    fixed = content.replace('\\\\\"', '###ESCAPED###')\n",
    "                    fixed = fixed.replace('\"', '\\\\\"')\n",
    "                    fixed = fixed.replace('###ESCAPED###', '\\\\\"')\n",
    "                    lines[i] = line.replace(content, fixed)\n",
    "        return json.loads('\\n'.join(lines))\n",
    "\n",
    "print(\"âœ… LLMé…ç½®å®Œæˆ\")\n",
    "print(f\"  Model: {LLM_CONFIG['model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 1: æ•°æ®å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_timestamp(ts: str) -> float:\n",
    "    parts = ts.strip().split(':')\n",
    "    if len(parts) == 2:\n",
    "        return int(parts[0]) * 60 + float(parts[1])\n",
    "    elif len(parts) == 3:\n",
    "        return int(parts[0]) * 3600 + int(parts[1]) * 60 + float(parts[2])\n",
    "    return 0.0\n",
    "\n",
    "def parse_raw_clips_markdown(md_content: str) -> List[dict]:\n",
    "    \"\"\"è§£æmarkdownæ ¼å¼çš„raw clips\"\"\"\n",
    "    clips = []\n",
    "    current_clip = None\n",
    "    current_section = None\n",
    "    transcript_lines = []\n",
    "    notes_lines = []\n",
    "    in_code_block = False\n",
    "    \n",
    "    for line in md_content.split('\\n'):\n",
    "        if line.strip() == '```':\n",
    "            in_code_block = not in_code_block\n",
    "            continue\n",
    "        \n",
    "        if line.startswith('## clip_'):\n",
    "            if current_clip:\n",
    "                current_clip['transcript_lines'] = transcript_lines\n",
    "                current_clip['notes'] = '\\n'.join(notes_lines)\n",
    "                clips.append(current_clip)\n",
    "            clip_id = line.replace('## ', '').strip()\n",
    "            current_clip = {'id': clip_id, 'source': '', 'language': 'zh', \n",
    "                          'duration_sec': 120, 'title': ''}\n",
    "            transcript_lines = []\n",
    "            notes_lines = []\n",
    "            current_section = None\n",
    "            continue\n",
    "        \n",
    "        if not current_clip:\n",
    "            continue\n",
    "        \n",
    "        if line.startswith('- **source**:'):\n",
    "            current_clip['source'] = line.split(':', 1)[1].strip()\n",
    "        elif line.startswith('- **language**:'):\n",
    "            current_clip['language'] = line.split(':', 1)[1].strip()\n",
    "        elif line.startswith('- **duration**:'):\n",
    "            try:\n",
    "                current_clip['duration_sec'] = int(line.split(':', 1)[1].strip())\n",
    "            except:\n",
    "                pass\n",
    "        elif line.startswith('- **title**:'):\n",
    "            current_clip['title'] = line.split(':', 1)[1].strip()\n",
    "        elif line.startswith('### transcript'):\n",
    "            current_section = 'transcript'\n",
    "        elif line.startswith('### notes'):\n",
    "            current_section = 'notes'\n",
    "        elif current_section == 'transcript' and in_code_block and line.strip():\n",
    "            match = re.match(r'^(\\d{1,2}:\\d{2})\\s+(.+)$', line.strip())\n",
    "            if match:\n",
    "                transcript_lines.append({\n",
    "                    'time': parse_timestamp(match.group(1)), \n",
    "                    'text': match.group(2)\n",
    "                })\n",
    "            elif transcript_lines:\n",
    "                transcript_lines[-1]['text'] += ' ' + line.strip()\n",
    "        elif current_section == 'notes' and line.strip() and not line.startswith('#'):\n",
    "            notes_lines.append(line.strip())\n",
    "    \n",
    "    if current_clip:\n",
    "        current_clip['transcript_lines'] = transcript_lines\n",
    "        current_clip['notes'] = '\\n'.join(notes_lines)\n",
    "        clips.append(current_clip)\n",
    "    \n",
    "    return clips\n",
    "\n",
    "print(\"âœ… æ•°æ®è§£æå™¨å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 2: Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternAnalyzer:\n",
    "    def __init__(self, clips: list):\n",
    "        self.clips = clips\n",
    "        self.all_segments = []\n",
    "        for clip in clips:\n",
    "            segs = clip.get('segments', []) if isinstance(clip, dict) else clip.segments\n",
    "            self.all_segments.extend(segs)\n",
    "    \n",
    "    def compute_attention_transition_matrix(self) -> dict:\n",
    "        transitions = defaultdict(lambda: defaultdict(int))\n",
    "        for clip in self.clips:\n",
    "            segs = clip.get('segments', []) if isinstance(clip, dict) else clip.segments\n",
    "            for i in range(len(segs) - 1):\n",
    "                f = segs[i].get('attention_focus', 'self') if isinstance(segs[i], dict) else segs[i].attention_focus.value\n",
    "                t = segs[i+1].get('attention_focus', 'self') if isinstance(segs[i+1], dict) else segs[i+1].attention_focus.value\n",
    "                transitions[f][t] += 1\n",
    "        \n",
    "        prob = {}\n",
    "        for f, tos in transitions.items():\n",
    "            total = sum(tos.values())\n",
    "            prob[f] = {t: c/total for t, c in tos.items()}\n",
    "        return prob\n",
    "    \n",
    "    def compute_trigger_speech_act_distribution(self) -> dict:\n",
    "        dist = defaultdict(lambda: defaultdict(int))\n",
    "        for seg in self.all_segments:\n",
    "            tr = seg.get('trigger', 'self') if isinstance(seg, dict) else seg.trigger.value\n",
    "            sa = seg.get('speech_act', 'narrate') if isinstance(seg, dict) else seg.speech_act.value\n",
    "            dist[tr][sa] += 1\n",
    "        \n",
    "        prob = {}\n",
    "        for tr, acts in dist.items():\n",
    "            total = sum(acts.values())\n",
    "            prob[tr] = {a: c/total for a, c in acts.items()}\n",
    "        return prob\n",
    "    \n",
    "    def extract_catchphrases(self):\n",
    "        cps = []\n",
    "        for c in self.clips:\n",
    "            cp = c.get('catchphrases', []) if isinstance(c, dict) else c.catchphrases\n",
    "            if cp:\n",
    "                cps.extend(cp)\n",
    "        return Counter(cps).most_common(20)\n",
    "    \n",
    "    def infer_baseline_costs(self) -> dict:\n",
    "        \"\"\"ä»æ ‡æ³¨æ•°æ®æ¨æ–­baseline costå€¼\"\"\"\n",
    "        ignore_rates = defaultdict(lambda: {'ignored': 0, 'total': 0})\n",
    "        \n",
    "        for seg in self.all_segments:\n",
    "            focus = seg.get('attention_focus', 'self')\n",
    "            trigger = seg.get('trigger', 'self')\n",
    "            \n",
    "            if trigger == 'danmaku':\n",
    "                ignore_rates[focus]['total'] += 1\n",
    "                if seg.get('speech_act') != 'respond':\n",
    "                    ignore_rates[focus]['ignored'] += 1\n",
    "        \n",
    "        baseline_costs = {}\n",
    "        for focus, stats in ignore_rates.items():\n",
    "            if stats['total'] > 0:\n",
    "                baseline_costs[focus] = stats['ignored'] / stats['total']\n",
    "            else:\n",
    "                baseline_costs[focus] = 0.5\n",
    "        \n",
    "        return baseline_costs\n",
    "\n",
    "print(\"âœ… PatternAnalyzerå®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 3: Multi-Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceState(TypedDict):\n",
    "    \"\"\"Multi-Agentå…±äº«çŠ¶æ€\"\"\"\n",
    "    oc_setting: str\n",
    "    topic: str\n",
    "    skeleton: List[NarrativeNode]\n",
    "    current_node_index: int\n",
    "    danmaku_stream: List[dict]\n",
    "    performance_log: List[dict]\n",
    "    inner_monologues: List[str]\n",
    "    elapsed_time: float\n",
    "    baseline_costs: dict\n",
    "\n",
    "print(\"âœ… PerformanceStateå®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NarrativePlanner:\n",
    "    \"\"\"Agent 1: å™äº‹ç­–åˆ’å¸ˆ\"\"\"\n",
    "    \n",
    "    def __init__(self, analyzer: PatternAnalyzer = None):\n",
    "        self.analyzer = analyzer\n",
    "        self.baseline_costs = analyzer.infer_baseline_costs() if analyzer else {}\n",
    "        \n",
    "        # ç¡¬ç¼–ç 3ä¸ªæ¨¡æ¿éª¨æ¶\n",
    "        self.templates = {\n",
    "            \"confessional\": [\n",
    "                NarrativeNode(\"Hook\", \"audience\", \"å»ºç«‹æ‚¬å¿µ/ä¸å¯»å¸¸çš„å¼€å¤´\", 0.3, [\"elicit\", \"narrate\"], 20),\n",
    "                NarrativeNode(\"Build-up\", \"self\", \"é“ºå«ç»†èŠ‚/èƒŒæ™¯æ•…äº‹\", 0.6, [\"narrate\"], 40),\n",
    "                NarrativeNode(\"Climax\", \"self\", \"æ ¸å¿ƒæƒ…ç»ªçˆ†å‘/ç§˜å¯†æ­éœ²\", 0.95, [\"narrate\", \"pivot\"], 30),\n",
    "                NarrativeNode(\"Resolution\", \"audience\", \"å‡å/å¯»æ±‚å…±é¸£\", 0.4, [\"opine\", \"elicit\"], 30)\n",
    "            ],\n",
    "            \"debate\": [\n",
    "                NarrativeNode(\"Hook\", \"audience\", \"æŠ›å‡ºäº‰è®®è¯é¢˜\", 0.2, [\"elicit\", \"opine\"], 15),\n",
    "                NarrativeNode(\"Build-up\", \"content\", \"å±•ç¤ºä¸åŒè§‚ç‚¹\", 0.3, [\"narrate\", \"opine\"], 35),\n",
    "                NarrativeNode(\"Climax\", \"audience\", \"ä¸è§‚ä¼—æ¿€çƒˆäº’åŠ¨\", 0.2, [\"respond\", \"opine\"], 50),\n",
    "                NarrativeNode(\"Resolution\", \"self\", \"æ€»ç»“ç«‹åœº\", 0.5, [\"opine\"], 20)\n",
    "            ],\n",
    "            \"insight\": [\n",
    "                NarrativeNode(\"Hook\", \"content\", \"æå‡ºæœ‰è¶£é—®é¢˜\", 0.4, [\"elicit\"], 15),\n",
    "                NarrativeNode(\"Build-up\", \"content\", \"ç†è®º/çŸ¥è¯†é“ºå«\", 0.7, [\"narrate\"], 50),\n",
    "                NarrativeNode(\"Climax\", \"self\", \"ä¸ªäººè§è§£/ç»éªŒ\", 0.6, [\"opine\", \"narrate\"], 35),\n",
    "                NarrativeNode(\"Resolution\", \"audience\", \"å®ç”¨å»ºè®®\", 0.3, [\"opine\", \"elicit\"], 20)\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def plan(self, state: PerformanceState) -> PerformanceState:\n",
    "        \"\"\"ç”Ÿæˆå¸¦costçš„skeleton\"\"\"\n",
    "        oc = state['oc_setting']\n",
    "        topic = state['topic']\n",
    "        \n",
    "        # 1. é€‰æ‹©æ¨¡æ¿\n",
    "        template_key = \"confessional\"\n",
    "        if any(w in topic.lower() for w in ['è¾©è®º', 'debate', 'äº‰è®®', 'è§‚ç‚¹']):\n",
    "            template_key = \"debate\"\n",
    "        elif any(w in topic.lower() for w in ['åˆ†äº«', 'æŠ€å·§', 'çŸ¥è¯†', 'insight']):\n",
    "            template_key = \"insight\"\n",
    "        \n",
    "        skeleton = [NarrativeNode(\n",
    "            n.stage, n.focus, n.goal, n.interruption_cost, \n",
    "            n.speech_act_hint, n.duration_hint\n",
    "        ) for n in self.templates[template_key]]\n",
    "        \n",
    "        # 2. ä¸ªæ€§åŒ–è°ƒæ•´cost\n",
    "        adjustment_prompt = f'''åˆ†æè¿™ä¸ªVTuberçš„æ€§æ ¼ç‰¹å¾:\n",
    "{oc}\n",
    "\n",
    "ä»–ä»¬åœ¨è®¨è®º\"{topic}\"è¿™ä¸ªè¯é¢˜æ—¶,åˆ°äº†æ•…äº‹é«˜æ½®é˜¶æ®µ,ä¼šå¤šå¤§ç¨‹åº¦ä¸Šå¿½ç•¥å¼¹å¹•ç»§ç»­è®²è¿°?\n",
    "\n",
    "è¯·ç»™å‡º0.0-1.0çš„æ•°å€¼:\n",
    "- 0.0 = å®Œå…¨ä¸ä»‹æ„è¢«æ‰“æ–­,å¾ˆéšæ€§\n",
    "- 0.5 = ä¼šæƒè¡¡,ä½†å¯ä»¥è¢«å¸å¼•èµ°\n",
    "- 1.0 = ç»å¯¹è¦è®²å®Œ,è°éƒ½åˆ«æƒ³æ‰“æ–­\n",
    "\n",
    "åªè¾“å‡ºæ•°å­—,ä¸è¦è§£é‡Šã€‚'''\n",
    "        \n",
    "        try:\n",
    "            adjustment = float(call_llm(adjustment_prompt, max_tokens=10, temperature=0.1).strip())\n",
    "            adjustment = max(0.0, min(1.0, adjustment))\n",
    "            \n",
    "            for node in skeleton:\n",
    "                if node.stage == \"Climax\":\n",
    "                    node.interruption_cost = adjustment\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 3. ä¸ºæ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆå…·ä½“ç›®æ ‡\n",
    "        for node in skeleton:\n",
    "            goal_prompt = f'''VTuberè®¾å®š: {oc}\n",
    "è¯é¢˜: {topic}\n",
    "é˜¶æ®µ: {node.stage}\n",
    "\n",
    "ä¸ºè¿™ä¸ªé˜¶æ®µç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„å™äº‹ç›®æ ‡(20å­—å†…),ä¾‹å¦‚:\n",
    "- \"ç”¨è‡ªå˜²å¼€åœºå¸å¼•æ³¨æ„\"\n",
    "- \"è®²è¿°ç«¥å¹´åˆ›ä¼¤ç»å†\"\n",
    "- \"å¼•å¯¼è§‚ä¼—åˆ†äº«ç»éªŒ\"\n",
    "\n",
    "åªè¾“å‡ºç›®æ ‡,ä¸è¦è§£é‡Š:'''\n",
    "            \n",
    "            try:\n",
    "                node.goal = call_llm(goal_prompt, max_tokens=50, temperature=0.7).strip()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        state['skeleton'] = skeleton\n",
    "        state['baseline_costs'] = self.baseline_costs\n",
    "        state['current_node_index'] = 0\n",
    "        return state\n",
    "\n",
    "print(\"âœ… NarrativePlannerå®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformerAgent:\n",
    "    \"\"\"Agent 2: è¡¨æ¼”æ‰§è¡Œå®˜\"\"\"\n",
    "    \n",
    "    def decide(self, state: PerformanceState) -> PerformanceState:\n",
    "        \"\"\"å®æ—¶å†³ç­–: ç»§ç»­å‰§æœ¬ vs å›åº”å¼¹å¹•\"\"\"\n",
    "        if state['current_node_index'] >= len(state['skeleton']):\n",
    "            return state\n",
    "        \n",
    "        node = state['skeleton'][state['current_node_index']]\n",
    "        recent_danmaku = state['danmaku_stream'][-5:] if state['danmaku_stream'] else []\n",
    "        \n",
    "        # 1. è¯„ä¼°å¼¹å¹•ç´§æ€¥åº¦\n",
    "        urgency = self._evaluate_urgency(recent_danmaku)\n",
    "        \n",
    "        # 2. è®¡ç®—å½“å‰cost\n",
    "        elapsed_in_node = state['elapsed_time'] - sum(\n",
    "            state['skeleton'][i].duration_hint \n",
    "            for i in range(state['current_node_index'])\n",
    "        )\n",
    "        elapsed_ratio = elapsed_in_node / max(node.duration_hint, 1)\n",
    "        current_cost = node.get_current_cost(elapsed_ratio)\n",
    "        \n",
    "        # 3. Agencyå†³ç­–å…¬å¼\n",
    "        decision_value = urgency - current_cost\n",
    "        \n",
    "        # 4. ç”Ÿæˆå°è¯\n",
    "        if decision_value > 0.3:\n",
    "            decision_type = \"RESPOND\"\n",
    "            speech = self._generate_response(node, recent_danmaku, state)\n",
    "        else:\n",
    "            decision_type = \"CONTINUE\"\n",
    "            speech = self._generate_script_speech(node, state)\n",
    "        \n",
    "        # 5. è®°å½•\n",
    "        state['performance_log'].append({\n",
    "            \"time\": state['elapsed_time'],\n",
    "            \"node\": node.stage,\n",
    "            \"decision\": decision_type,\n",
    "            \"speech\": speech,\n",
    "            \"urgency\": urgency,\n",
    "            \"cost\": current_cost,\n",
    "            \"decision_value\": decision_value\n",
    "        })\n",
    "        \n",
    "        # 6. æ›´æ–°æ—¶é—´å’ŒèŠ‚ç‚¹\n",
    "        state['elapsed_time'] += 10\n",
    "        if state['elapsed_time'] >= sum(n.duration_hint for n in state['skeleton'][:state['current_node_index']+1]):\n",
    "            state['current_node_index'] += 1\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def _evaluate_urgency(self, danmaku_list: List[dict]) -> float:\n",
    "        \"\"\"è¯„ä¼°å¼¹å¹•ç´§æ€¥åº¦\"\"\"\n",
    "        if not danmaku_list:\n",
    "            return 0.0\n",
    "        \n",
    "        urgency = 0.0\n",
    "        for dm in danmaku_list:\n",
    "            dm_type = dm.get('type', 'normal')\n",
    "            if dm_type == 'sc':  # Super Chat\n",
    "                urgency = max(urgency, 0.9)\n",
    "            elif dm_type == 'gift':\n",
    "                urgency = max(urgency, 0.7)\n",
    "            elif '?' in dm.get('text', '') or 'ï¼Ÿ' in dm.get('text', ''):\n",
    "                urgency = max(urgency, 0.5)\n",
    "            else:\n",
    "                urgency = max(urgency, 0.2)\n",
    "        \n",
    "        return urgency\n",
    "    \n",
    "    def _generate_response(self, node: NarrativeNode, danmaku: List[dict], state: PerformanceState) -> str:\n",
    "        \"\"\"ç”Ÿæˆå›åº”å¼¹å¹•çš„å°è¯\"\"\"\n",
    "        dm_texts = [dm.get('text', '') for dm in danmaku[-3:]]\n",
    "        \n",
    "        prompt = f'''ä½ æ˜¯ä¸€ä¸ªVTuber,è®¾å®šå¦‚ä¸‹:\n",
    "{state['oc_setting']}\n",
    "\n",
    "å½“å‰æ­£åœ¨è®¨è®º: {state['topic']}\n",
    "å½“å‰é˜¶æ®µ: {node.stage} - {node.goal}\n",
    "\n",
    "è§‚ä¼—å‘æ¥çš„å¼¹å¹•:\n",
    "{chr(10).join(dm_texts)}\n",
    "\n",
    "è¯·ç”¨å£è¯­åŒ–çš„æ–¹å¼å›åº”è¿™äº›å¼¹å¹•,ä¿æŒè§’è‰²è®¾å®šã€‚å›åº”è¦ç®€çŸ­æœ‰è¶£(30å­—ä»¥å†…)ã€‚\n",
    "åªè¾“å‡ºå°è¯,ä¸è¦åŠ å¼•å·æˆ–å…¶ä»–æ ¼å¼ã€‚'''\n",
    "        \n",
    "        try:\n",
    "            return call_llm(prompt, max_tokens=100, temperature=0.8).strip()\n",
    "        except:\n",
    "            return \"å“å‘€,ç­‰ä¸‹å†è¯´è¿™ä¸ª~\"\n",
    "    \n",
    "    def _generate_script_speech(self, node: NarrativeNode, state: PerformanceState) -> str:\n",
    "        \"\"\"ç”Ÿæˆå‰§æœ¬å°è¯\"\"\"\n",
    "        prompt = f'''ä½ æ˜¯ä¸€ä¸ªVTuber,è®¾å®šå¦‚ä¸‹:\n",
    "{state['oc_setting']}\n",
    "\n",
    "å½“å‰è¯é¢˜: {state['topic']}\n",
    "å½“å‰é˜¶æ®µ: {node.stage}\n",
    "è¿™ä¸ªé˜¶æ®µçš„ç›®æ ‡: {node.goal}\n",
    "æ¨èçš„è¯´è¯æ–¹å¼: {', '.join(node.speech_act_hint)}\n",
    "\n",
    "è¯·ç”Ÿæˆä¸€æ®µç¬¦åˆå½“å‰é˜¶æ®µçš„å°è¯(50-100å­—)ã€‚è¦å£è¯­åŒ–ã€æœ‰æƒ…ç»ªèµ·ä¼ã€ç¬¦åˆè§’è‰²è®¾å®šã€‚\n",
    "åªè¾“å‡ºå°è¯,ä¸è¦åŠ å¼•å·æˆ–å…¶ä»–æ ¼å¼ã€‚'''\n",
    "        \n",
    "        try:\n",
    "            return call_llm(prompt, max_tokens=200, temperature=0.7).strip()\n",
    "        except:\n",
    "            return f\"[{node.stage}é˜¶æ®µå°è¯ç”Ÿæˆå¤±è´¥]\"\n",
    "\n",
    "print(\"âœ… PerformerAgentå®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectorAgent:\n",
    "    \"\"\"Agent 3: å¯¼æ¼” - ç›‘ç£å’Œè°ƒæ•´è¡¨æ¼”\"\"\"\n",
    "    \n",
    "    def evaluate(self, state: PerformanceState) -> PerformanceState:\n",
    "        \"\"\"è¯„ä¼°å½“å‰è¡¨æ¼”çŠ¶æ€å¹¶è®°å½•å†…å¿ƒç‹¬ç™½\"\"\"\n",
    "        if not state['performance_log']:\n",
    "            return state\n",
    "        \n",
    "        recent_log = state['performance_log'][-3:]\n",
    "        \n",
    "        # ç”Ÿæˆå†…å¿ƒç‹¬ç™½\n",
    "        decisions = [log['decision'] for log in recent_log]\n",
    "        avg_urgency = np.mean([log['urgency'] for log in recent_log])\n",
    "        avg_cost = np.mean([log['cost'] for log in recent_log])\n",
    "        \n",
    "        monologue = f'''[å¯¼æ¼”è§†è§’] \n",
    "æœ€è¿‘3æ¬¡å†³ç­–: {decisions}\n",
    "å¹³å‡å¼¹å¹•ç´§æ€¥åº¦: {avg_urgency:.2f}\n",
    "å¹³å‡æ‰“æ–­ä»£ä»·: {avg_cost:.2f}\n",
    "å½“å‰èŠ‚ç‚¹: {state['current_node_index'] + 1}/{len(state['skeleton'])}'''\n",
    "        \n",
    "        state['inner_monologues'].append(monologue)\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def should_continue(self, state: PerformanceState) -> bool:\n",
    "        \"\"\"åˆ¤æ–­æ˜¯å¦ç»§ç»­è¡¨æ¼”\"\"\"\n",
    "        return state['current_node_index'] < len(state['skeleton'])\n",
    "\n",
    "print(\"âœ… DirectorAgentå®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 4: LangGraphå·¥ä½œæµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_graph(planner: NarrativePlanner, performer: PerformerAgent, director: DirectorAgent):\n",
    "    \"\"\"åˆ›å»ºMulti-Agentè¡¨æ¼”å·¥ä½œæµ\"\"\"\n",
    "    \n",
    "    # å®šä¹‰èŠ‚ç‚¹å‡½æ•°\n",
    "    def plan_node(state: PerformanceState) -> PerformanceState:\n",
    "        return planner.plan(state)\n",
    "    \n",
    "    def perform_node(state: PerformanceState) -> PerformanceState:\n",
    "        return performer.decide(state)\n",
    "    \n",
    "    def direct_node(state: PerformanceState) -> PerformanceState:\n",
    "        return director.evaluate(state)\n",
    "    \n",
    "    def should_continue(state: PerformanceState) -> str:\n",
    "        if director.should_continue(state):\n",
    "            return \"perform\"\n",
    "        return \"end\"\n",
    "    \n",
    "    # æ„å»ºå›¾\n",
    "    workflow = StateGraph(PerformanceState)\n",
    "    \n",
    "    workflow.add_node(\"plan\", plan_node)\n",
    "    workflow.add_node(\"perform\", perform_node)\n",
    "    workflow.add_node(\"direct\", direct_node)\n",
    "    \n",
    "    workflow.set_entry_point(\"plan\")\n",
    "    workflow.add_edge(\"plan\", \"perform\")\n",
    "    workflow.add_edge(\"perform\", \"direct\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"direct\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"perform\": \"perform\",\n",
    "            \"end\": END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "print(\"âœ… LangGraphå·¥ä½œæµå®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# æ‰§è¡Œæ¼”ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¤ºä¾‹VTuberè®¾å®š\n",
    "DEMO_OC_SETTING = '''\n",
    "åå­—: å°å¤œ\n",
    "æ€§æ ¼: å…ƒæ°”æ»¡æ»¡ä½†å¶å°”ä¼šçªç„¶emo,å–œæ¬¢è‡ªå˜²,è¯´è¯å¾ˆå¿«\n",
    "å£ç™–: \"è¯¶å˜¿~\", \"è¿™ä¸æ˜¯å¾ˆæ­£å¸¸å—\", \"ç­‰ä¸‹ç­‰ä¸‹\"\n",
    "ç‰¹ç‚¹: å®¹æ˜“è¢«å¼¹å¹•å¸¦è·‘,è®²æ•…äº‹å–œæ¬¢åŠ æˆå‰§åŒ–ç»†èŠ‚\n",
    "'''\n",
    "\n",
    "# ç¤ºä¾‹è¯é¢˜\n",
    "DEMO_TOPIC = \"åˆ†äº«ä¸€æ¬¡ç¤¾æ­»ç»å†\"\n",
    "\n",
    "# æ¨¡æ‹Ÿå¼¹å¹•æµ\n",
    "DEMO_DANMAKU = [\n",
    "    {\"time\": 15, \"text\": \"ä»€ä¹ˆç¤¾æ­»å•Š\", \"type\": \"normal\"},\n",
    "    {\"time\": 25, \"text\": \"æ¥äº†æ¥äº†\", \"type\": \"normal\"},\n",
    "    {\"time\": 35, \"text\": \"å¤ªçœŸå®äº†å“ˆå“ˆå“ˆ\", \"type\": \"normal\"},\n",
    "    {\"time\": 50, \"text\": \"ç„¶åå‘¢ç„¶åå‘¢ï¼Ÿ\", \"type\": \"normal\"},\n",
    "    {\"time\": 65, \"text\": \"ä¸»æ’­åŠ æ²¹\", \"type\": \"gift\"},\n",
    "    {\"time\": 80, \"text\": \"æˆ‘ä¹Ÿæœ‰ç±»ä¼¼ç»å†ï¼\", \"type\": \"sc\"},\n",
    "    {\"time\": 95, \"text\": \"ç¬‘æ­»\", \"type\": \"normal\"},\n",
    "]\n",
    "\n",
    "print(\"âœ… æ¼”ç¤ºæ•°æ®å‡†å¤‡å®Œæˆ\")\n",
    "print(f\"OCè®¾å®š: {DEMO_OC_SETTING[:50]}...\")\n",
    "print(f\"è¯é¢˜: {DEMO_TOPIC}\")\n",
    "print(f\"å¼¹å¹•æ•°: {len(DEMO_DANMAKU)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_performance_demo():\n",
    "    \"\"\"è¿è¡Œè¡¨æ¼”æ¼”ç¤º\"\"\"\n",
    "    print(\"ğŸ¬ å¼€å§‹Multi-Agentè¡¨æ¼”æ¼”ç¤º\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # åˆå§‹åŒ–Agents\n",
    "    planner = NarrativePlanner(analyzer=None)\n",
    "    performer = PerformerAgent()\n",
    "    director = DirectorAgent()\n",
    "    \n",
    "    # åˆ›å»ºå·¥ä½œæµ\n",
    "    graph = create_performance_graph(planner, performer, director)\n",
    "    \n",
    "    # åˆå§‹çŠ¶æ€\n",
    "    initial_state: PerformanceState = {\n",
    "        \"oc_setting\": DEMO_OC_SETTING,\n",
    "        \"topic\": DEMO_TOPIC,\n",
    "        \"skeleton\": [],\n",
    "        \"current_node_index\": 0,\n",
    "        \"danmaku_stream\": [],\n",
    "        \"performance_log\": [],\n",
    "        \"inner_monologues\": [],\n",
    "        \"elapsed_time\": 0.0,\n",
    "        \"baseline_costs\": {}\n",
    "    }\n",
    "    \n",
    "    # è¿è¡Œå·¥ä½œæµ(å¸¦å¼¹å¹•æ³¨å…¥)\n",
    "    danmaku_index = 0\n",
    "    \n",
    "    # å…ˆè¿è¡Œplanning\n",
    "    state = planner.plan(initial_state)\n",
    "    print(\"\\nğŸ“‹ å™äº‹éª¨æ¶ç”Ÿæˆå®Œæˆ:\")\n",
    "    for i, node in enumerate(state['skeleton']):\n",
    "        print(f\"  {i+1}. [{node.stage}] {node.goal} (cost={node.interruption_cost:.2f})\")\n",
    "    print()\n",
    "    \n",
    "    # æ¨¡æ‹Ÿè¡¨æ¼”å¾ªç¯\n",
    "    max_iterations = 15\n",
    "    for iteration in range(max_iterations):\n",
    "        # æ³¨å…¥å½“å‰æ—¶é—´ç‚¹çš„å¼¹å¹•\n",
    "        while danmaku_index < len(DEMO_DANMAKU) and DEMO_DANMAKU[danmaku_index]['time'] <= state['elapsed_time']:\n",
    "            state['danmaku_stream'].append(DEMO_DANMAKU[danmaku_index])\n",
    "            danmaku_index += 1\n",
    "        \n",
    "        # æ‰§è¡Œä¸€è½®è¡¨æ¼”\n",
    "        state = performer.decide(state)\n",
    "        state = director.evaluate(state)\n",
    "        \n",
    "        # è¾“å‡ºæœ€æ–°çš„è¡¨æ¼”\n",
    "        if state['performance_log']:\n",
    "            latest = state['performance_log'][-1]\n",
    "            print(f\"â±ï¸ {latest['time']:.0f}s | [{latest['node']}] {latest['decision']}\")\n",
    "            print(f\"   ğŸ’¬ {latest['speech'][:80]}...\" if len(latest['speech']) > 80 else f\"   ğŸ’¬ {latest['speech']}\")\n",
    "            print(f\"   ğŸ“Š urgency={latest['urgency']:.2f}, cost={latest['cost']:.2f}, decision_value={latest['decision_value']:.2f}\")\n",
    "            print()\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦ç»“æŸ\n",
    "        if not director.should_continue(state):\n",
    "            print(\"\\nğŸ¬ è¡¨æ¼”ç»“æŸ!\")\n",
    "            break\n",
    "    \n",
    "    # è¾“å‡ºå†…å¿ƒç‹¬ç™½\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ§  å¯¼æ¼”å†…å¿ƒç‹¬ç™½:\")\n",
    "    for mono in state['inner_monologues'][-3:]:\n",
    "        print(mono)\n",
    "        print()\n",
    "    \n",
    "    return state\n",
    "\n",
    "# è¿è¡Œæ¼”ç¤º\n",
    "# æ³¨æ„: éœ€è¦é…ç½®æœ‰æ•ˆçš„API Keyæ‰èƒ½è¿è¡Œ\n",
    "# final_state = run_performance_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# å·¥å…·å‡½æ•°: ç»“æœåˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_performance(state: PerformanceState) -> dict:\n",
    "    \"\"\"åˆ†æè¡¨æ¼”ç»“æœ\"\"\"\n",
    "    if not state['performance_log']:\n",
    "        return {\"error\": \"No performance log\"}\n",
    "    \n",
    "    logs = state['performance_log']\n",
    "    \n",
    "    # ç»Ÿè®¡å†³ç­–åˆ†å¸ƒ\n",
    "    decision_counts = Counter(log['decision'] for log in logs)\n",
    "    \n",
    "    # è®¡ç®—å¹³å‡å€¼\n",
    "    avg_urgency = np.mean([log['urgency'] for log in logs])\n",
    "    avg_cost = np.mean([log['cost'] for log in logs])\n",
    "    \n",
    "    # å„é˜¶æ®µæ—¶é•¿\n",
    "    stage_times = defaultdict(list)\n",
    "    for log in logs:\n",
    "        stage_times[log['node']].append(log['time'])\n",
    "    \n",
    "    analysis = {\n",
    "        \"total_duration\": state['elapsed_time'],\n",
    "        \"total_segments\": len(logs),\n",
    "        \"decision_distribution\": dict(decision_counts),\n",
    "        \"respond_rate\": decision_counts.get('RESPOND', 0) / len(logs) if logs else 0,\n",
    "        \"avg_urgency\": avg_urgency,\n",
    "        \"avg_cost\": avg_cost,\n",
    "        \"stages_completed\": len(stage_times),\n",
    "        \"danmaku_processed\": len(state['danmaku_stream'])\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def print_analysis(analysis: dict):\n",
    "    \"\"\"æ‰“å°åˆ†æç»“æœ\"\"\"\n",
    "    print(\"ğŸ“Š è¡¨æ¼”åˆ†ææŠ¥å‘Š\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"æ€»æ—¶é•¿: {analysis['total_duration']:.0f}ç§’\")\n",
    "    print(f\"æ€»ç‰‡æ®µæ•°: {analysis['total_segments']}\")\n",
    "    print(f\"å¼¹å¹•å›åº”ç‡: {analysis['respond_rate']:.1%}\")\n",
    "    print(f\"å¹³å‡å¼¹å¹•ç´§æ€¥åº¦: {analysis['avg_urgency']:.2f}\")\n",
    "    print(f\"å¹³å‡æ‰“æ–­ä»£ä»·: {analysis['avg_cost']:.2f}\")\n",
    "    print(f\"å†³ç­–åˆ†å¸ƒ: {analysis['decision_distribution']}\")\n",
    "\n",
    "print(\"âœ… åˆ†æå·¥å…·å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ä½¿ç”¨è¯´æ˜\n",
    "\n",
    "## å¿«é€Ÿå¼€å§‹\n",
    "\n",
    "1. **é…ç½®API Key**: ä¿®æ”¹ `LLM_CONFIG` ä¸­çš„ `api_key`\n",
    "2. **è‡ªå®šä¹‰OCè®¾å®š**: ä¿®æ”¹ `DEMO_OC_SETTING`\n",
    "3. **è®¾ç½®è¯é¢˜**: ä¿®æ”¹ `DEMO_TOPIC`\n",
    "4. **è¿è¡Œæ¼”ç¤º**: å–æ¶ˆ `run_performance_demo()` çš„æ³¨é‡Š\n",
    "\n",
    "## æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "### Interruption Cost (æ‰“æ–­ä»£ä»·)\n",
    "- 0.0-1.0 èŒƒå›´\n",
    "- é«˜cost = ä¸»æ’­ä¸æƒ³è¢«æ‰“æ–­,ä¼šå¿½ç•¥å¼¹å¹•\n",
    "- ä½cost = ä¸»æ’­æ„¿æ„äº’åŠ¨\n",
    "\n",
    "### å†³ç­–å…¬å¼\n",
    "```\n",
    "decision_value = urgency - current_cost\n",
    "if decision_value > 0.3: RESPOND (å›åº”å¼¹å¹•)\n",
    "else: CONTINUE (ç»§ç»­å‰§æœ¬)\n",
    "```\n",
    "\n",
    "### å™äº‹éª¨æ¶æ¨¡æ¿\n",
    "- **confessional**: å‘Šç™½å‹ (Hookâ†’Build-upâ†’Climaxâ†’Resolution)\n",
    "- **debate**: è¾©è®ºå‹ (é€‚åˆäº‰è®®è¯é¢˜)\n",
    "- **insight**: çŸ¥è¯†åˆ†äº«å‹"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
